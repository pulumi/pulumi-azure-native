// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNative.Synapse
{
    public static class GetBigDataPool
    {
        /// <summary>
        /// Get a Big Data pool.
        /// 
        /// Uses Azure REST API version 2021-06-01.
        /// 
        /// Other available API versions: 2021-04-01-preview, 2021-05-01, 2021-06-01-preview. These can be accessed by generating a local SDK package using the CLI command `pulumi package add azure-native synapse [ApiVersion]`. See the [version guide](../../../version-guide/#accessing-any-api-version-via-local-packages) for details.
        /// </summary>
        public static Task<GetBigDataPoolResult> InvokeAsync(GetBigDataPoolArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.InvokeAsync<GetBigDataPoolResult>("azure-native:synapse:getBigDataPool", args ?? new GetBigDataPoolArgs(), options.WithDefaults());

        /// <summary>
        /// Get a Big Data pool.
        /// 
        /// Uses Azure REST API version 2021-06-01.
        /// 
        /// Other available API versions: 2021-04-01-preview, 2021-05-01, 2021-06-01-preview. These can be accessed by generating a local SDK package using the CLI command `pulumi package add azure-native synapse [ApiVersion]`. See the [version guide](../../../version-guide/#accessing-any-api-version-via-local-packages) for details.
        /// </summary>
        public static Output<GetBigDataPoolResult> Invoke(GetBigDataPoolInvokeArgs args, InvokeOptions? options = null)
            => global::Pulumi.Deployment.Instance.Invoke<GetBigDataPoolResult>("azure-native:synapse:getBigDataPool", args ?? new GetBigDataPoolInvokeArgs(), options.WithDefaults());

        /// <summary>
        /// Get a Big Data pool.
        /// 
        /// Uses Azure REST API version 2021-06-01.
        /// 
        /// Other available API versions: 2021-04-01-preview, 2021-05-01, 2021-06-01-preview. These can be accessed by generating a local SDK package using the CLI command `pulumi package add azure-native synapse [ApiVersion]`. See the [version guide](../../../version-guide/#accessing-any-api-version-via-local-packages) for details.
        /// </summary>
        public static Output<GetBigDataPoolResult> Invoke(GetBigDataPoolInvokeArgs args, InvokeOutputOptions options)
            => global::Pulumi.Deployment.Instance.Invoke<GetBigDataPoolResult>("azure-native:synapse:getBigDataPool", args ?? new GetBigDataPoolInvokeArgs(), options.WithDefaults());
    }


    public sealed class GetBigDataPoolArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Big Data pool name
        /// </summary>
        [Input("bigDataPoolName", required: true)]
        public string BigDataPoolName { get; set; } = null!;

        /// <summary>
        /// The name of the resource group. The name is case insensitive.
        /// </summary>
        [Input("resourceGroupName", required: true)]
        public string ResourceGroupName { get; set; } = null!;

        /// <summary>
        /// The name of the workspace.
        /// </summary>
        [Input("workspaceName", required: true)]
        public string WorkspaceName { get; set; } = null!;

        public GetBigDataPoolArgs()
        {
        }
        public static new GetBigDataPoolArgs Empty => new GetBigDataPoolArgs();
    }

    public sealed class GetBigDataPoolInvokeArgs : global::Pulumi.InvokeArgs
    {
        /// <summary>
        /// Big Data pool name
        /// </summary>
        [Input("bigDataPoolName", required: true)]
        public Input<string> BigDataPoolName { get; set; } = null!;

        /// <summary>
        /// The name of the resource group. The name is case insensitive.
        /// </summary>
        [Input("resourceGroupName", required: true)]
        public Input<string> ResourceGroupName { get; set; } = null!;

        /// <summary>
        /// The name of the workspace.
        /// </summary>
        [Input("workspaceName", required: true)]
        public Input<string> WorkspaceName { get; set; } = null!;

        public GetBigDataPoolInvokeArgs()
        {
        }
        public static new GetBigDataPoolInvokeArgs Empty => new GetBigDataPoolInvokeArgs();
    }


    [OutputType]
    public sealed class GetBigDataPoolResult
    {
        /// <summary>
        /// Auto-pausing properties
        /// </summary>
        public readonly Outputs.AutoPausePropertiesResponse? AutoPause;
        /// <summary>
        /// Auto-scaling properties
        /// </summary>
        public readonly Outputs.AutoScalePropertiesResponse? AutoScale;
        /// <summary>
        /// The Azure API version of the resource.
        /// </summary>
        public readonly string AzureApiVersion;
        /// <summary>
        /// The cache size
        /// </summary>
        public readonly int? CacheSize;
        /// <summary>
        /// The time when the Big Data pool was created.
        /// </summary>
        public readonly string CreationDate;
        /// <summary>
        /// List of custom libraries/packages associated with the spark pool.
        /// </summary>
        public readonly ImmutableArray<Outputs.LibraryInfoResponse> CustomLibraries;
        /// <summary>
        /// The default folder where Spark logs will be written.
        /// </summary>
        public readonly string? DefaultSparkLogFolder;
        /// <summary>
        /// Dynamic Executor Allocation
        /// </summary>
        public readonly Outputs.DynamicExecutorAllocationResponse? DynamicExecutorAllocation;
        /// <summary>
        /// Fully qualified resource ID for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
        /// </summary>
        public readonly string Id;
        /// <summary>
        /// Whether autotune is required or not.
        /// </summary>
        public readonly bool? IsAutotuneEnabled;
        /// <summary>
        /// Whether compute isolation is required or not.
        /// </summary>
        public readonly bool? IsComputeIsolationEnabled;
        /// <summary>
        /// The time when the Big Data pool was updated successfully.
        /// </summary>
        public readonly string LastSucceededTimestamp;
        /// <summary>
        /// Library version requirements
        /// </summary>
        public readonly Outputs.LibraryRequirementsResponse? LibraryRequirements;
        /// <summary>
        /// The geo-location where the resource lives
        /// </summary>
        public readonly string Location;
        /// <summary>
        /// The name of the resource
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// The number of nodes in the Big Data pool.
        /// </summary>
        public readonly int? NodeCount;
        /// <summary>
        /// The level of compute power that each node in the Big Data pool has.
        /// </summary>
        public readonly string? NodeSize;
        /// <summary>
        /// The kind of nodes that the Big Data pool provides.
        /// </summary>
        public readonly string? NodeSizeFamily;
        /// <summary>
        /// The state of the Big Data pool.
        /// </summary>
        public readonly string? ProvisioningState;
        /// <summary>
        /// Whether session level packages enabled.
        /// </summary>
        public readonly bool? SessionLevelPackagesEnabled;
        /// <summary>
        /// Spark configuration file to specify additional properties
        /// </summary>
        public readonly Outputs.SparkConfigPropertiesResponse? SparkConfigProperties;
        /// <summary>
        /// The Spark events folder
        /// </summary>
        public readonly string? SparkEventsFolder;
        /// <summary>
        /// The Apache Spark version.
        /// </summary>
        public readonly string? SparkVersion;
        /// <summary>
        /// Resource tags.
        /// </summary>
        public readonly ImmutableDictionary<string, string>? Tags;
        /// <summary>
        /// The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
        /// </summary>
        public readonly string Type;

        [OutputConstructor]
        private GetBigDataPoolResult(
            Outputs.AutoPausePropertiesResponse? autoPause,

            Outputs.AutoScalePropertiesResponse? autoScale,

            string azureApiVersion,

            int? cacheSize,

            string creationDate,

            ImmutableArray<Outputs.LibraryInfoResponse> customLibraries,

            string? defaultSparkLogFolder,

            Outputs.DynamicExecutorAllocationResponse? dynamicExecutorAllocation,

            string id,

            bool? isAutotuneEnabled,

            bool? isComputeIsolationEnabled,

            string lastSucceededTimestamp,

            Outputs.LibraryRequirementsResponse? libraryRequirements,

            string location,

            string name,

            int? nodeCount,

            string? nodeSize,

            string? nodeSizeFamily,

            string? provisioningState,

            bool? sessionLevelPackagesEnabled,

            Outputs.SparkConfigPropertiesResponse? sparkConfigProperties,

            string? sparkEventsFolder,

            string? sparkVersion,

            ImmutableDictionary<string, string>? tags,

            string type)
        {
            AutoPause = autoPause;
            AutoScale = autoScale;
            AzureApiVersion = azureApiVersion;
            CacheSize = cacheSize;
            CreationDate = creationDate;
            CustomLibraries = customLibraries;
            DefaultSparkLogFolder = defaultSparkLogFolder;
            DynamicExecutorAllocation = dynamicExecutorAllocation;
            Id = id;
            IsAutotuneEnabled = isAutotuneEnabled;
            IsComputeIsolationEnabled = isComputeIsolationEnabled;
            LastSucceededTimestamp = lastSucceededTimestamp;
            LibraryRequirements = libraryRequirements;
            Location = location;
            Name = name;
            NodeCount = nodeCount;
            NodeSize = nodeSize;
            NodeSizeFamily = nodeSizeFamily;
            ProvisioningState = provisioningState;
            SessionLevelPackagesEnabled = sessionLevelPackagesEnabled;
            SparkConfigProperties = sparkConfigProperties;
            SparkEventsFolder = sparkEventsFolder;
            SparkVersion = sparkVersion;
            Tags = tags;
            Type = type;
        }
    }
}
