// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNextGen.DataFactory.V20180601.Outputs
{

    [OutputType]
    public sealed class DatabricksSparkPythonActivityResponse
    {
        /// <summary>
        /// Activity depends on condition.
        /// </summary>
        public readonly ImmutableArray<Outputs.ActivityDependencyResponse> DependsOn;
        /// <summary>
        /// Activity description.
        /// </summary>
        public readonly string? Description;
        /// <summary>
        /// A list of libraries to be installed on the cluster that will execute the job.
        /// </summary>
        public readonly ImmutableArray<ImmutableDictionary<string, object>> Libraries;
        /// <summary>
        /// Linked service reference.
        /// </summary>
        public readonly Outputs.LinkedServiceReferenceResponse? LinkedServiceName;
        /// <summary>
        /// Activity name.
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// Command line parameters that will be passed to the Python file.
        /// </summary>
        public readonly ImmutableArray<object> Parameters;
        /// <summary>
        /// Activity policy.
        /// </summary>
        public readonly Outputs.ActivityPolicyResponse? Policy;
        /// <summary>
        /// The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string).
        /// </summary>
        public readonly object PythonFile;
        /// <summary>
        /// Type of activity.
        /// Expected value is 'Execution'.
        /// </summary>
        public readonly string Type;
        /// <summary>
        /// Activity user properties.
        /// </summary>
        public readonly ImmutableArray<Outputs.UserPropertyResponse> UserProperties;

        [OutputConstructor]
        private DatabricksSparkPythonActivityResponse(
            ImmutableArray<Outputs.ActivityDependencyResponse> dependsOn,

            string? description,

            ImmutableArray<ImmutableDictionary<string, object>> libraries,

            Outputs.LinkedServiceReferenceResponse? linkedServiceName,

            string name,

            ImmutableArray<object> parameters,

            Outputs.ActivityPolicyResponse? policy,

            object pythonFile,

            string type,

            ImmutableArray<Outputs.UserPropertyResponse> userProperties)
        {
            DependsOn = dependsOn;
            Description = description;
            Libraries = libraries;
            LinkedServiceName = linkedServiceName;
            Name = name;
            Parameters = parameters;
            Policy = policy;
            PythonFile = pythonFile;
            Type = type;
            UserProperties = userProperties;
        }
    }
}
