// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNextGen.DataFactory.V20180601.Inputs
{

    /// <summary>
    /// Azure Databricks linked service.
    /// </summary>
    public sealed class AzureDatabricksLinkedServiceArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// Access token for databricks REST API. Refer to https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("accessToken", required: true)]
        public InputUnion<Inputs.AzureKeyVaultSecretReferenceArgs, Inputs.SecureStringArgs> AccessToken { get; set; } = null!;

        [Input("annotations")]
        private InputList<object>? _annotations;

        /// <summary>
        /// List of tags that can be used for describing the linked service.
        /// </summary>
        public InputList<object> Annotations
        {
            get => _annotations ?? (_annotations = new InputList<object>());
            set => _annotations = value;
        }

        /// <summary>
        /// The integration runtime reference.
        /// </summary>
        [Input("connectVia")]
        public Input<Inputs.IntegrationRuntimeReferenceArgs>? ConnectVia { get; set; }

        /// <summary>
        /// Linked service description.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// &lt;REGION&gt;.azuredatabricks.net, domain name of your Databricks deployment. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("domain", required: true)]
        public Input<object> Domain { get; set; } = null!;

        /// <summary>
        /// The encrypted credential used for authentication. Credentials are encrypted using the integration runtime credential manager. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("encryptedCredential")]
        public Input<object>? EncryptedCredential { get; set; }

        /// <summary>
        /// The id of an existing interactive cluster that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("existingClusterId")]
        public Input<object>? ExistingClusterId { get; set; }

        /// <summary>
        /// The id of an existing instance pool that will be used for all runs of this activity. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("instancePoolId")]
        public Input<object>? InstancePoolId { get; set; }

        [Input("newClusterCustomTags")]
        private InputMap<object>? _newClusterCustomTags;

        /// <summary>
        /// Additional tags for cluster resources. This property is ignored in instance pool configurations.
        /// </summary>
        public InputMap<object> NewClusterCustomTags
        {
            get => _newClusterCustomTags ?? (_newClusterCustomTags = new InputMap<object>());
            set => _newClusterCustomTags = value;
        }

        /// <summary>
        /// The driver node type for the new job cluster. This property is ignored in instance pool configurations. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("newClusterDriverNodeType")]
        public Input<object>? NewClusterDriverNodeType { get; set; }

        /// <summary>
        /// Enable the elastic disk on the new cluster. This property is now ignored, and takes the default elastic disk behavior in Databricks (elastic disks are always enabled). Type: boolean (or Expression with resultType boolean).
        /// </summary>
        [Input("newClusterEnableElasticDisk")]
        public Input<object>? NewClusterEnableElasticDisk { get; set; }

        /// <summary>
        /// User-defined initialization scripts for the new cluster. Type: array of strings (or Expression with resultType array of strings).
        /// </summary>
        [Input("newClusterInitScripts")]
        public Input<object>? NewClusterInitScripts { get; set; }

        /// <summary>
        /// Specify a location to deliver Spark driver, worker, and event logs. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("newClusterLogDestination")]
        public Input<object>? NewClusterLogDestination { get; set; }

        /// <summary>
        /// The node type of the new job cluster. This property is required if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId is specified, this property is ignored. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("newClusterNodeType")]
        public Input<object>? NewClusterNodeType { get; set; }

        /// <summary>
        /// If not using an existing interactive cluster, this specifies the number of worker nodes to use for the new job cluster or instance pool. For new job clusters, this a string-formatted Int32, like '1' means numOfWorker is 1 or '1:10' means auto-scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted Int32, and can only specify a fixed number of worker nodes, such as '2'. Required if newClusterVersion is specified. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("newClusterNumOfWorker")]
        public Input<object>? NewClusterNumOfWorker { get; set; }

        [Input("newClusterSparkConf")]
        private InputMap<object>? _newClusterSparkConf;

        /// <summary>
        /// A set of optional, user-specified Spark configuration key-value pairs.
        /// </summary>
        public InputMap<object> NewClusterSparkConf
        {
            get => _newClusterSparkConf ?? (_newClusterSparkConf = new InputMap<object>());
            set => _newClusterSparkConf = value;
        }

        [Input("newClusterSparkEnvVars")]
        private InputMap<object>? _newClusterSparkEnvVars;

        /// <summary>
        /// A set of optional, user-specified Spark environment variables key-value pairs.
        /// </summary>
        public InputMap<object> NewClusterSparkEnvVars
        {
            get => _newClusterSparkEnvVars ?? (_newClusterSparkEnvVars = new InputMap<object>());
            set => _newClusterSparkEnvVars = value;
        }

        /// <summary>
        /// If not using an existing interactive cluster, this specifies the Spark version of a new job cluster or instance pool nodes created for each run of this activity. Required if instancePoolId is specified. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("newClusterVersion")]
        public Input<object>? NewClusterVersion { get; set; }

        [Input("parameters")]
        private InputMap<Inputs.ParameterSpecificationArgs>? _parameters;

        /// <summary>
        /// Parameters for linked service.
        /// </summary>
        public InputMap<Inputs.ParameterSpecificationArgs> Parameters
        {
            get => _parameters ?? (_parameters = new InputMap<Inputs.ParameterSpecificationArgs>());
            set => _parameters = value;
        }

        /// <summary>
        /// Type of linked service.
        /// </summary>
        [Input("type", required: true)]
        public Input<string> Type { get; set; } = null!;

        public AzureDatabricksLinkedServiceArgs()
        {
        }
    }
}
