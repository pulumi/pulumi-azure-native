// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNextGen.DataFactory.Inputs
{

    /// <summary>
    /// DatabricksSparkPython activity.
    /// </summary>
    public sealed class DatabricksSparkPythonActivityArgs : Pulumi.ResourceArgs
    {
        [Input("dependsOn")]
        private InputList<Inputs.ActivityDependencyArgs>? _dependsOn;

        /// <summary>
        /// Activity depends on condition.
        /// </summary>
        public InputList<Inputs.ActivityDependencyArgs> DependsOn
        {
            get => _dependsOn ?? (_dependsOn = new InputList<Inputs.ActivityDependencyArgs>());
            set => _dependsOn = value;
        }

        /// <summary>
        /// Activity description.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        [Input("libraries")]
        private InputList<ImmutableDictionary<string, object>>? _libraries;

        /// <summary>
        /// A list of libraries to be installed on the cluster that will execute the job.
        /// </summary>
        public InputList<ImmutableDictionary<string, object>> Libraries
        {
            get => _libraries ?? (_libraries = new InputList<ImmutableDictionary<string, object>>());
            set => _libraries = value;
        }

        /// <summary>
        /// Linked service reference.
        /// </summary>
        [Input("linkedServiceName")]
        public Input<Inputs.LinkedServiceReferenceArgs>? LinkedServiceName { get; set; }

        /// <summary>
        /// Activity name.
        /// </summary>
        [Input("name", required: true)]
        public Input<string> Name { get; set; } = null!;

        [Input("parameters")]
        private InputList<object>? _parameters;

        /// <summary>
        /// Command line parameters that will be passed to the Python file.
        /// </summary>
        public InputList<object> Parameters
        {
            get => _parameters ?? (_parameters = new InputList<object>());
            set => _parameters = value;
        }

        /// <summary>
        /// Activity policy.
        /// </summary>
        [Input("policy")]
        public Input<Inputs.ActivityPolicyArgs>? Policy { get; set; }

        /// <summary>
        /// The URI of the Python file to be executed. DBFS paths are supported. Type: string (or Expression with resultType string).
        /// </summary>
        [Input("pythonFile", required: true)]
        public Input<object> PythonFile { get; set; } = null!;

        /// <summary>
        /// Type of activity.
        /// Expected value is 'Execution'.
        /// </summary>
        [Input("type", required: true)]
        public Input<string> Type { get; set; } = null!;

        [Input("userProperties")]
        private InputList<Inputs.UserPropertyArgs>? _userProperties;

        /// <summary>
        /// Activity user properties.
        /// </summary>
        public InputList<Inputs.UserPropertyArgs> UserProperties
        {
            get => _userProperties ?? (_userProperties = new InputList<Inputs.UserPropertyArgs>());
            set => _userProperties = value;
        }

        public DatabricksSparkPythonActivityArgs()
        {
        }
    }
}
