// *** WARNING: this file was generated by pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNative.MachineLearningServices.V20250101Preview.Outputs
{

    [OutputType]
    public sealed class InferenceContainerPropertiesResponse
    {
        /// <summary>
        /// The route to check the liveness of the inference server container.
        /// </summary>
        public readonly Outputs.RouteResponse? LivenessRoute;
        /// <summary>
        /// The route to check the readiness of the inference server container.
        /// </summary>
        public readonly Outputs.RouteResponse? ReadinessRoute;
        /// <summary>
        /// The port to send the scoring requests to, within the inference server container.
        /// </summary>
        public readonly Outputs.RouteResponse? ScoringRoute;
        /// <summary>
        /// The route to check the startup of the application in the container.
        /// </summary>
        public readonly Outputs.RouteResponse? StartupRoute;

        [OutputConstructor]
        private InferenceContainerPropertiesResponse(
            Outputs.RouteResponse? livenessRoute,

            Outputs.RouteResponse? readinessRoute,

            Outputs.RouteResponse? scoringRoute,

            Outputs.RouteResponse? startupRoute)
        {
            LivenessRoute = livenessRoute;
            ReadinessRoute = readinessRoute;
            ScoringRoute = scoringRoute;
            StartupRoute = startupRoute;
        }
    }
}
