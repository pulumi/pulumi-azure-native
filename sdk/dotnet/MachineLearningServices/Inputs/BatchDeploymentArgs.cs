// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNative.MachineLearningServices.Inputs
{

    /// <summary>
    /// Batch inference settings per deployment.
    /// </summary>
    public sealed class BatchDeploymentArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Code configuration for the endpoint deployment.
        /// </summary>
        [Input("codeConfiguration")]
        public Input<Inputs.CodeConfigurationArgs>? CodeConfiguration { get; set; }

        /// <summary>
        /// Compute target for batch inference operation.
        /// </summary>
        [Input("compute")]
        public Input<string>? Compute { get; set; }

        /// <summary>
        /// Description of the endpoint deployment.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// ARM resource ID or AssetId of the environment specification for the endpoint deployment.
        /// </summary>
        [Input("environmentId")]
        public Input<string>? EnvironmentId { get; set; }

        [Input("environmentVariables")]
        private InputMap<string>? _environmentVariables;

        /// <summary>
        /// Environment variables configuration for the deployment.
        /// </summary>
        public InputMap<string> EnvironmentVariables
        {
            get => _environmentVariables ?? (_environmentVariables = new InputMap<string>());
            set => _environmentVariables = value;
        }

        /// <summary>
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// </summary>
        [Input("errorThreshold")]
        public Input<int>? ErrorThreshold { get; set; }

        /// <summary>
        /// Logging level for batch inference operation.
        /// </summary>
        [Input("loggingLevel")]
        public InputUnion<string, Pulumi.AzureNative.MachineLearningServices.BatchLoggingLevel>? LoggingLevel { get; set; }

        /// <summary>
        /// Indicates maximum number of parallelism per instance.
        /// </summary>
        [Input("maxConcurrencyPerInstance")]
        public Input<int>? MaxConcurrencyPerInstance { get; set; }

        /// <summary>
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// </summary>
        [Input("miniBatchSize")]
        public Input<double>? MiniBatchSize { get; set; }

        /// <summary>
        /// Reference to the model asset for the endpoint deployment.
        /// </summary>
        [Input("model")]
        public object? Model { get; set; }

        /// <summary>
        /// Indicates how the output will be organized.
        /// </summary>
        [Input("outputAction")]
        public InputUnion<string, Pulumi.AzureNative.MachineLearningServices.BatchOutputAction>? OutputAction { get; set; }

        /// <summary>
        /// Customized output file name for append_row output action.
        /// </summary>
        [Input("outputFileName")]
        public Input<string>? OutputFileName { get; set; }

        [Input("properties")]
        private InputMap<string>? _properties;

        /// <summary>
        /// Property dictionary. Properties can be added, but not removed or altered.
        /// </summary>
        public InputMap<string> Properties
        {
            get => _properties ?? (_properties = new InputMap<string>());
            set => _properties = value;
        }

        /// <summary>
        /// Indicates compute configuration for the job.
        /// If not provided, will default to the defaults defined in ResourceConfiguration.
        /// </summary>
        [Input("resources")]
        public Input<Inputs.DeploymentResourceConfigurationArgs>? Resources { get; set; }

        /// <summary>
        /// Retry Settings for the batch inference operation.
        /// If not provided, will default to the defaults defined in BatchRetrySettings.
        /// </summary>
        [Input("retrySettings")]
        public Input<Inputs.BatchRetrySettingsArgs>? RetrySettings { get; set; }

        public BatchDeploymentArgs()
        {
            ErrorThreshold = -1;
            LoggingLevel = "Info";
            MaxConcurrencyPerInstance = 1;
            MiniBatchSize = 10;
            OutputAction = "AppendRow";
            OutputFileName = "predictions.csv";
        }
        public static new BatchDeploymentArgs Empty => new BatchDeploymentArgs();
    }
}
