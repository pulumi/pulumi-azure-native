// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.AzureNative.MachineLearningServices.Inputs
{

    /// <summary>
    /// Batch inference settings per deployment.
    /// </summary>
    public sealed class BatchDeploymentArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// Code configuration for the endpoint deployment.
        /// </summary>
        [Input("codeConfiguration")]
        public Input<Inputs.CodeConfigurationArgs>? CodeConfiguration { get; set; }

        /// <summary>
        /// Configuration for compute binding.
        /// </summary>
        [Input("compute")]
        public Input<Inputs.ComputeConfigurationArgs>? Compute { get; set; }

        /// <summary>
        /// Description of the endpoint deployment.
        /// </summary>
        [Input("description")]
        public Input<string>? Description { get; set; }

        /// <summary>
        /// ARM resource ID of the environment specification for the endpoint deployment.
        /// </summary>
        [Input("environmentId")]
        public Input<string>? EnvironmentId { get; set; }

        [Input("environmentVariables")]
        private InputMap<string>? _environmentVariables;

        /// <summary>
        /// Environment variables configuration for the deployment.
        /// </summary>
        public InputMap<string> EnvironmentVariables
        {
            get => _environmentVariables ?? (_environmentVariables = new InputMap<string>());
            set => _environmentVariables = value;
        }

        /// <summary>
        /// Error threshold, if the error count for the entire input goes above this value,
        /// the batch inference will be aborted. Range is [-1, int.MaxValue].
        /// For FileDataset, this value is the count of file failures.
        /// For TabularDataset, this value is the count of record failures.
        /// If set to -1 (the lower bound), all failures during batch inference will be ignored.
        /// </summary>
        [Input("errorThreshold")]
        public Input<int>? ErrorThreshold { get; set; }

        /// <summary>
        /// Logging level for batch inference operation.
        /// </summary>
        [Input("loggingLevel")]
        public InputUnion<string, Pulumi.AzureNative.MachineLearningServices.BatchLoggingLevel>? LoggingLevel { get; set; }

        /// <summary>
        /// Size of the mini-batch passed to each batch invocation.
        /// For FileDataset, this is the number of files per mini-batch.
        /// For TabularDataset, this is the size of the records in bytes, per mini-batch.
        /// </summary>
        [Input("miniBatchSize")]
        public Input<double>? MiniBatchSize { get; set; }

        /// <summary>
        /// Reference to the model asset for the endpoint deployment.
        /// </summary>
        [Input("model")]
        public Input<object>? Model { get; set; }

        /// <summary>
        /// Output configuration for the batch inference operation.
        /// </summary>
        [Input("outputConfiguration")]
        public Input<Inputs.BatchOutputConfigurationArgs>? OutputConfiguration { get; set; }

        [Input("partitionKeys")]
        private InputList<string>? _partitionKeys;

        /// <summary>
        /// Partition keys list used for Named partitioning.
        /// </summary>
        public InputList<string> PartitionKeys
        {
            get => _partitionKeys ?? (_partitionKeys = new InputList<string>());
            set => _partitionKeys = value;
        }

        [Input("properties")]
        private InputMap<string>? _properties;

        /// <summary>
        /// Property dictionary. Properties can be added, but not removed or altered.
        /// </summary>
        public InputMap<string> Properties
        {
            get => _properties ?? (_properties = new InputMap<string>());
            set => _properties = value;
        }

        /// <summary>
        /// Retry Settings for the batch inference operation.
        /// </summary>
        [Input("retrySettings")]
        public Input<Inputs.BatchRetrySettingsArgs>? RetrySettings { get; set; }

        public BatchDeploymentArgs()
        {
        }
    }
}
