# coding=utf-8
# *** WARNING: this file was generated by the Pulumi SDK Generator. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Union
from ... import _utilities, _tables


class GetJobResult:
    """
    Contains information about the job.
    """
    def __init__(__self__, caffe_settings=None, chainer_settings=None, cluster=None, cntk_settings=None, constraints=None, container_settings=None, creation_time=None, custom_toolkit_settings=None, environment_variables=None, execution_info=None, execution_state=None, execution_state_transition_time=None, experiment_name=None, input_directories=None, job_output_directory_path_segment=None, job_preparation=None, location=None, mount_volumes=None, name=None, node_count=None, output_directories=None, priority=None, provisioning_state=None, provisioning_state_transition_time=None, py_torch_settings=None, secrets=None, std_out_err_path_prefix=None, tags=None, tensor_flow_settings=None, tool_type=None, type=None):
        if caffe_settings and not isinstance(caffe_settings, dict):
            raise TypeError("Expected argument 'caffe_settings' to be a dict")
        __self__.caffe_settings = caffe_settings
        """
        Specifies the settings for Caffe job.
        """
        if chainer_settings and not isinstance(chainer_settings, dict):
            raise TypeError("Expected argument 'chainer_settings' to be a dict")
        __self__.chainer_settings = chainer_settings
        """
        Specifies the settings for Chainer job.
        """
        if cluster and not isinstance(cluster, dict):
            raise TypeError("Expected argument 'cluster' to be a dict")
        __self__.cluster = cluster
        """
        Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
        """
        if cntk_settings and not isinstance(cntk_settings, dict):
            raise TypeError("Expected argument 'cntk_settings' to be a dict")
        __self__.cntk_settings = cntk_settings
        """
        Specifies the settings for CNTK (aka Microsoft Cognitive Toolkit) job.
        """
        if constraints and not isinstance(constraints, dict):
            raise TypeError("Expected argument 'constraints' to be a dict")
        __self__.constraints = constraints
        """
        Constraints associated with the Job.
        """
        if container_settings and not isinstance(container_settings, dict):
            raise TypeError("Expected argument 'container_settings' to be a dict")
        __self__.container_settings = container_settings
        """
        If the container was downloaded as part of cluster setup then the same container image will be used. If not provided, the job will run on the VM.
        """
        if creation_time and not isinstance(creation_time, str):
            raise TypeError("Expected argument 'creation_time' to be a str")
        __self__.creation_time = creation_time
        """
        The creation time of the job.
        """
        if custom_toolkit_settings and not isinstance(custom_toolkit_settings, dict):
            raise TypeError("Expected argument 'custom_toolkit_settings' to be a dict")
        __self__.custom_toolkit_settings = custom_toolkit_settings
        """
        Specifies the settings for a custom tool kit job.
        """
        if environment_variables and not isinstance(environment_variables, list):
            raise TypeError("Expected argument 'environment_variables' to be a list")
        __self__.environment_variables = environment_variables
        """
        Batch AI will setup these additional environment variables for the job.
        """
        if execution_info and not isinstance(execution_info, dict):
            raise TypeError("Expected argument 'execution_info' to be a dict")
        __self__.execution_info = execution_info
        """
        Contains information about the execution of a job in the Azure Batch service.
        """
        if execution_state and not isinstance(execution_state, str):
            raise TypeError("Expected argument 'execution_state' to be a str")
        __self__.execution_state = execution_state
        """
        The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.
        """
        if execution_state_transition_time and not isinstance(execution_state_transition_time, str):
            raise TypeError("Expected argument 'execution_state_transition_time' to be a str")
        __self__.execution_state_transition_time = execution_state_transition_time
        """
        The time at which the job entered its current execution state.
        """
        if experiment_name and not isinstance(experiment_name, str):
            raise TypeError("Expected argument 'experiment_name' to be a str")
        __self__.experiment_name = experiment_name
        """
        Describe the experiment information of the job
        """
        if input_directories and not isinstance(input_directories, list):
            raise TypeError("Expected argument 'input_directories' to be a list")
        __self__.input_directories = input_directories
        if job_output_directory_path_segment and not isinstance(job_output_directory_path_segment, str):
            raise TypeError("Expected argument 'job_output_directory_path_segment' to be a str")
        __self__.job_output_directory_path_segment = job_output_directory_path_segment
        """
        Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem.
        """
        if job_preparation and not isinstance(job_preparation, dict):
            raise TypeError("Expected argument 'job_preparation' to be a dict")
        __self__.job_preparation = job_preparation
        """
        The specified actions will run on all the nodes that are part of the job
        """
        if location and not isinstance(location, str):
            raise TypeError("Expected argument 'location' to be a str")
        __self__.location = location
        """
        The location of the resource
        """
        if mount_volumes and not isinstance(mount_volumes, dict):
            raise TypeError("Expected argument 'mount_volumes' to be a dict")
        __self__.mount_volumes = mount_volumes
        """
        These volumes will be mounted before the job execution and will be unmounted after the job completion. The volumes will be mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
        """
        if name and not isinstance(name, str):
            raise TypeError("Expected argument 'name' to be a str")
        __self__.name = name
        """
        The name of the resource
        """
        if node_count and not isinstance(node_count, float):
            raise TypeError("Expected argument 'node_count' to be a float")
        __self__.node_count = node_count
        """
        The job will be gang scheduled on that many compute nodes
        """
        if output_directories and not isinstance(output_directories, list):
            raise TypeError("Expected argument 'output_directories' to be a list")
        __self__.output_directories = output_directories
        if priority and not isinstance(priority, float):
            raise TypeError("Expected argument 'priority' to be a float")
        __self__.priority = priority
        """
        Priority associated with the job. Priority values can range from -1000 to 1000, with -1000 being the lowest priority and 1000 being the highest priority. The default value is 0.
        """
        if provisioning_state and not isinstance(provisioning_state, str):
            raise TypeError("Expected argument 'provisioning_state' to be a str")
        __self__.provisioning_state = provisioning_state
        """
        The provisioned state of the Batch AI job
        """
        if provisioning_state_transition_time and not isinstance(provisioning_state_transition_time, str):
            raise TypeError("Expected argument 'provisioning_state_transition_time' to be a str")
        __self__.provisioning_state_transition_time = provisioning_state_transition_time
        """
        The time at which the job entered its current provisioning state.
        """
        if py_torch_settings and not isinstance(py_torch_settings, dict):
            raise TypeError("Expected argument 'py_torch_settings' to be a dict")
        __self__.py_torch_settings = py_torch_settings
        """
        Specifies the settings for pyTorch job.
        """
        if secrets and not isinstance(secrets, list):
            raise TypeError("Expected argument 'secrets' to be a list")
        __self__.secrets = secrets
        """
        Batch AI will setup these additional environment variables for the job. Server will never report values of these variables back.
        """
        if std_out_err_path_prefix and not isinstance(std_out_err_path_prefix, str):
            raise TypeError("Expected argument 'std_out_err_path_prefix' to be a str")
        __self__.std_out_err_path_prefix = std_out_err_path_prefix
        """
        The path where the Batch AI service will upload stdout and stderror of the job.
        """
        if tags and not isinstance(tags, dict):
            raise TypeError("Expected argument 'tags' to be a dict")
        __self__.tags = tags
        """
        The tags of the resource
        """
        if tensor_flow_settings and not isinstance(tensor_flow_settings, dict):
            raise TypeError("Expected argument 'tensor_flow_settings' to be a dict")
        __self__.tensor_flow_settings = tensor_flow_settings
        """
        Specifies the settings for TensorFlow job.
        """
        if tool_type and not isinstance(tool_type, str):
            raise TypeError("Expected argument 'tool_type' to be a str")
        __self__.tool_type = tool_type
        """
        Possible values are: cntk, tensorflow, caffe, caffe2, chainer, pytorch, custom.
        """
        if type and not isinstance(type, str):
            raise TypeError("Expected argument 'type' to be a str")
        __self__.type = type
        """
        The type of the resource
        """


class AwaitableGetJobResult(GetJobResult):
    # pylint: disable=using-constant-test
    def __await__(self):
        if False:
            yield self
        return GetJobResult(
            caffe_settings=self.caffe_settings,
            chainer_settings=self.chainer_settings,
            cluster=self.cluster,
            cntk_settings=self.cntk_settings,
            constraints=self.constraints,
            container_settings=self.container_settings,
            creation_time=self.creation_time,
            custom_toolkit_settings=self.custom_toolkit_settings,
            environment_variables=self.environment_variables,
            execution_info=self.execution_info,
            execution_state=self.execution_state,
            execution_state_transition_time=self.execution_state_transition_time,
            experiment_name=self.experiment_name,
            input_directories=self.input_directories,
            job_output_directory_path_segment=self.job_output_directory_path_segment,
            job_preparation=self.job_preparation,
            location=self.location,
            mount_volumes=self.mount_volumes,
            name=self.name,
            node_count=self.node_count,
            output_directories=self.output_directories,
            priority=self.priority,
            provisioning_state=self.provisioning_state,
            provisioning_state_transition_time=self.provisioning_state_transition_time,
            py_torch_settings=self.py_torch_settings,
            secrets=self.secrets,
            std_out_err_path_prefix=self.std_out_err_path_prefix,
            tags=self.tags,
            tensor_flow_settings=self.tensor_flow_settings,
            tool_type=self.tool_type,
            type=self.type)


def get_job(name=None, resource_group_name=None, opts=None):
    """
    Use this data source to access information about an existing resource.

    :param str name: The name of the job within the specified resource group. Job names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
    :param str resource_group_name: Name of the resource group to which the resource belongs.
    """
    __args__ = dict()
    __args__['name'] = name
    __args__['resourceGroupName'] = resource_group_name
    if opts is None:
        opts = pulumi.InvokeOptions()
    if opts.version is None:
        opts.version = _utilities.get_version()
    __ret__ = pulumi.runtime.invoke('azurerm:batchai/v20180301:getJob', __args__, opts=opts).value

    return AwaitableGetJobResult(
        caffe_settings=__ret__.get('caffeSettings'),
        chainer_settings=__ret__.get('chainerSettings'),
        cluster=__ret__.get('cluster'),
        cntk_settings=__ret__.get('cntkSettings'),
        constraints=__ret__.get('constraints'),
        container_settings=__ret__.get('containerSettings'),
        creation_time=__ret__.get('creationTime'),
        custom_toolkit_settings=__ret__.get('customToolkitSettings'),
        environment_variables=__ret__.get('environmentVariables'),
        execution_info=__ret__.get('executionInfo'),
        execution_state=__ret__.get('executionState'),
        execution_state_transition_time=__ret__.get('executionStateTransitionTime'),
        experiment_name=__ret__.get('experimentName'),
        input_directories=__ret__.get('inputDirectories'),
        job_output_directory_path_segment=__ret__.get('jobOutputDirectoryPathSegment'),
        job_preparation=__ret__.get('jobPreparation'),
        location=__ret__.get('location'),
        mount_volumes=__ret__.get('mountVolumes'),
        name=__ret__.get('name'),
        node_count=__ret__.get('nodeCount'),
        output_directories=__ret__.get('outputDirectories'),
        priority=__ret__.get('priority'),
        provisioning_state=__ret__.get('provisioningState'),
        provisioning_state_transition_time=__ret__.get('provisioningStateTransitionTime'),
        py_torch_settings=__ret__.get('pyTorchSettings'),
        secrets=__ret__.get('secrets'),
        std_out_err_path_prefix=__ret__.get('stdOutErrPathPrefix'),
        tags=__ret__.get('tags'),
        tensor_flow_settings=__ret__.get('tensorFlowSettings'),
        tool_type=__ret__.get('toolType'),
        type=__ret__.get('type'))
