# coding=utf-8
# *** WARNING: this file was generated by pulumi-language-python. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import builtins
import copy
import warnings
import sys
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
if sys.version_info >= (3, 11):
    from typing import NotRequired, TypedDict, TypeAlias
else:
    from typing_extensions import NotRequired, TypedDict, TypeAlias
from .. import _utilities
from . import outputs

__all__ = [
    'GetInferenceGroupStatusResult',
    'AwaitableGetInferenceGroupStatusResult',
    'get_inference_group_status',
    'get_inference_group_status_output',
]

@pulumi.output_type
class GetInferenceGroupStatusResult:
    def __init__(__self__, actual_capacity_info=None, endpoint_count=None, requested_capacity=None):
        if actual_capacity_info and not isinstance(actual_capacity_info, dict):
            raise TypeError("Expected argument 'actual_capacity_info' to be a dict")
        pulumi.set(__self__, "actual_capacity_info", actual_capacity_info)
        if endpoint_count and not isinstance(endpoint_count, int):
            raise TypeError("Expected argument 'endpoint_count' to be a int")
        pulumi.set(__self__, "endpoint_count", endpoint_count)
        if requested_capacity and not isinstance(requested_capacity, int):
            raise TypeError("Expected argument 'requested_capacity' to be a int")
        pulumi.set(__self__, "requested_capacity", requested_capacity)

    @property
    @pulumi.getter(name="actualCapacityInfo")
    def actual_capacity_info(self) -> Optional['outputs.ActualCapacityInfoResponse']:
        """
        Gets or sets the actual capacity info for the group.
        """
        return pulumi.get(self, "actual_capacity_info")

    @property
    @pulumi.getter(name="endpointCount")
    def endpoint_count(self) -> Optional[builtins.int]:
        """
        Gets or sets the actual number of endpoints in the group.
        """
        return pulumi.get(self, "endpoint_count")

    @property
    @pulumi.getter(name="requestedCapacity")
    def requested_capacity(self) -> Optional[builtins.int]:
        """
        Gets or sets the request number of instances for the group.
        """
        return pulumi.get(self, "requested_capacity")


class AwaitableGetInferenceGroupStatusResult(GetInferenceGroupStatusResult):
    # pylint: disable=using-constant-test
    def __await__(self):
        if False:
            yield self
        return GetInferenceGroupStatusResult(
            actual_capacity_info=self.actual_capacity_info,
            endpoint_count=self.endpoint_count,
            requested_capacity=self.requested_capacity)


def get_inference_group_status(group_name: Optional[builtins.str] = None,
                               pool_name: Optional[builtins.str] = None,
                               resource_group_name: Optional[builtins.str] = None,
                               workspace_name: Optional[builtins.str] = None,
                               opts: Optional[pulumi.InvokeOptions] = None) -> AwaitableGetInferenceGroupStatusResult:
    """
    Uses Azure REST API version 2025-01-01-preview.

    Other available API versions: 2023-08-01-preview, 2024-01-01-preview, 2024-10-01-preview. These can be accessed by generating a local SDK package using the CLI command `pulumi package add azure-native machinelearningservices [ApiVersion]`. See the [version guide](../../../version-guide/#accessing-any-api-version-via-local-packages) for details.


    :param builtins.str group_name: InferenceGroup name.
    :param builtins.str pool_name: InferencePool name.
    :param builtins.str resource_group_name: The name of the resource group. The name is case insensitive.
    :param builtins.str workspace_name: Name of Azure Machine Learning workspace.
    """
    __args__ = dict()
    __args__['groupName'] = group_name
    __args__['poolName'] = pool_name
    __args__['resourceGroupName'] = resource_group_name
    __args__['workspaceName'] = workspace_name
    opts = pulumi.InvokeOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke('azure-native:machinelearningservices:getInferenceGroupStatus', __args__, opts=opts, typ=GetInferenceGroupStatusResult).value

    return AwaitableGetInferenceGroupStatusResult(
        actual_capacity_info=pulumi.get(__ret__, 'actual_capacity_info'),
        endpoint_count=pulumi.get(__ret__, 'endpoint_count'),
        requested_capacity=pulumi.get(__ret__, 'requested_capacity'))
def get_inference_group_status_output(group_name: Optional[pulumi.Input[builtins.str]] = None,
                                      pool_name: Optional[pulumi.Input[builtins.str]] = None,
                                      resource_group_name: Optional[pulumi.Input[builtins.str]] = None,
                                      workspace_name: Optional[pulumi.Input[builtins.str]] = None,
                                      opts: Optional[Union[pulumi.InvokeOptions, pulumi.InvokeOutputOptions]] = None) -> pulumi.Output[GetInferenceGroupStatusResult]:
    """
    Uses Azure REST API version 2025-01-01-preview.

    Other available API versions: 2023-08-01-preview, 2024-01-01-preview, 2024-10-01-preview. These can be accessed by generating a local SDK package using the CLI command `pulumi package add azure-native machinelearningservices [ApiVersion]`. See the [version guide](../../../version-guide/#accessing-any-api-version-via-local-packages) for details.


    :param builtins.str group_name: InferenceGroup name.
    :param builtins.str pool_name: InferencePool name.
    :param builtins.str resource_group_name: The name of the resource group. The name is case insensitive.
    :param builtins.str workspace_name: Name of Azure Machine Learning workspace.
    """
    __args__ = dict()
    __args__['groupName'] = group_name
    __args__['poolName'] = pool_name
    __args__['resourceGroupName'] = resource_group_name
    __args__['workspaceName'] = workspace_name
    opts = pulumi.InvokeOutputOptions.merge(_utilities.get_invoke_opts_defaults(), opts)
    __ret__ = pulumi.runtime.invoke_output('azure-native:machinelearningservices:getInferenceGroupStatus', __args__, opts=opts, typ=GetInferenceGroupStatusResult)
    return __ret__.apply(lambda __response__: GetInferenceGroupStatusResult(
        actual_capacity_info=pulumi.get(__response__, 'actual_capacity_info'),
        endpoint_count=pulumi.get(__response__, 'endpoint_count'),
        requested_capacity=pulumi.get(__response__, 'requested_capacity')))
