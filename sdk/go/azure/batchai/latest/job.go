// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package latest

import (
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v2/go/pulumi"
)

// Information about a Job.
type Job struct {
	pulumi.CustomResourceState

	// Caffe2 job settings.
	Caffe2Settings Caffe2SettingsResponsePtrOutput `pulumi:"caffe2Settings"`
	// Caffe job settings.
	CaffeSettings CaffeSettingsResponsePtrOutput `pulumi:"caffeSettings"`
	// Chainer job settings.
	ChainerSettings ChainerSettingsResponsePtrOutput `pulumi:"chainerSettings"`
	// Resource ID of the cluster associated with the job.
	Cluster ResourceIdResponsePtrOutput `pulumi:"cluster"`
	// CNTK (aka Microsoft Cognitive Toolkit) job settings.
	CntkSettings CNTKsettingsResponsePtrOutput `pulumi:"cntkSettings"`
	// Constraints associated with the Job.
	Constraints JobPropertiesResponseConstraintsPtrOutput `pulumi:"constraints"`
	// If the container was downloaded as part of cluster setup then the same container image will be used. If not provided, the job will run on the VM.
	ContainerSettings ContainerSettingsResponsePtrOutput `pulumi:"containerSettings"`
	// The creation time of the job.
	CreationTime pulumi.StringOutput `pulumi:"creationTime"`
	// Custom MPI job settings.
	CustomMpiSettings CustomMpiSettingsResponsePtrOutput `pulumi:"customMpiSettings"`
	// Custom tool kit job settings.
	CustomToolkitSettings CustomToolkitSettingsResponsePtrOutput `pulumi:"customToolkitSettings"`
	// A collection of user defined environment variables to be setup for the job.
	EnvironmentVariables EnvironmentVariableResponseArrayOutput `pulumi:"environmentVariables"`
	// Information about the execution of a job.
	ExecutionInfo JobPropertiesResponseExecutionInfoPtrOutput `pulumi:"executionInfo"`
	// The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.
	ExecutionState pulumi.StringOutput `pulumi:"executionState"`
	// The time at which the job entered its current execution state.
	ExecutionStateTransitionTime pulumi.StringOutput `pulumi:"executionStateTransitionTime"`
	// Specifies the settings for Horovod job.
	HorovodSettings HorovodSettingsResponsePtrOutput `pulumi:"horovodSettings"`
	// A list of input directories for the job.
	InputDirectories InputDirectoryResponseArrayOutput `pulumi:"inputDirectories"`
	// A segment of job's output directories path created by Batch AI. Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem.
	JobOutputDirectoryPathSegment pulumi.StringOutput `pulumi:"jobOutputDirectoryPathSegment"`
	// The specified actions will run on all the nodes that are part of the job
	JobPreparation JobPreparationResponsePtrOutput `pulumi:"jobPreparation"`
	// Collection of mount volumes available to the job during execution. These volumes are mounted before the job execution and unmounted after the job completion. The volumes are mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
	MountVolumes MountVolumesResponsePtrOutput `pulumi:"mountVolumes"`
	// The name of the resource.
	Name pulumi.StringOutput `pulumi:"name"`
	// The job will be gang scheduled on that many compute nodes
	NodeCount pulumi.IntPtrOutput `pulumi:"nodeCount"`
	// A list of output directories for the job.
	OutputDirectories OutputDirectoryResponseArrayOutput `pulumi:"outputDirectories"`
	// The provisioned state of the Batch AI job
	ProvisioningState pulumi.StringOutput `pulumi:"provisioningState"`
	// The time at which the job entered its current provisioning state.
	ProvisioningStateTransitionTime pulumi.StringOutput `pulumi:"provisioningStateTransitionTime"`
	// pyTorch job settings.
	PyTorchSettings PyTorchSettingsResponsePtrOutput `pulumi:"pyTorchSettings"`
	// Scheduling priority associated with the job.
	SchedulingPriority pulumi.StringPtrOutput `pulumi:"schedulingPriority"`
	// A collection of user defined environment variables with secret values to be setup for the job. Server will never report values of these variables back.
	Secrets EnvironmentVariableWithSecretValueResponseArrayOutput `pulumi:"secrets"`
	// The path where the Batch AI service stores stdout, stderror and execution log of the job.
	StdOutErrPathPrefix pulumi.StringPtrOutput `pulumi:"stdOutErrPathPrefix"`
	// TensorFlow job settings.
	TensorFlowSettings TensorFlowSettingsResponsePtrOutput `pulumi:"tensorFlowSettings"`
	// Possible values are: cntk, tensorflow, caffe, caffe2, chainer, pytorch, custom, custommpi, horovod.
	ToolType pulumi.StringPtrOutput `pulumi:"toolType"`
	// The type of the resource.
	Type pulumi.StringOutput `pulumi:"type"`
}

// NewJob registers a new resource with the given unique name, arguments, and options.
func NewJob(ctx *pulumi.Context,
	name string, args *JobArgs, opts ...pulumi.ResourceOption) (*Job, error) {
	if args == nil || args.Cluster == nil {
		return nil, errors.New("missing required argument 'Cluster'")
	}
	if args == nil || args.ExperimentName == nil {
		return nil, errors.New("missing required argument 'ExperimentName'")
	}
	if args == nil || args.JobName == nil {
		return nil, errors.New("missing required argument 'JobName'")
	}
	if args == nil || args.NodeCount == nil {
		return nil, errors.New("missing required argument 'NodeCount'")
	}
	if args == nil || args.ResourceGroupName == nil {
		return nil, errors.New("missing required argument 'ResourceGroupName'")
	}
	if args == nil || args.StdOutErrPathPrefix == nil {
		return nil, errors.New("missing required argument 'StdOutErrPathPrefix'")
	}
	if args == nil || args.WorkspaceName == nil {
		return nil, errors.New("missing required argument 'WorkspaceName'")
	}
	if args == nil {
		args = &JobArgs{}
	}
	aliases := pulumi.Aliases([]pulumi.Alias{
		{
			Type: pulumi.String("azure-nextgen:batchai/v20180501:Job"),
		},
	})
	opts = append(opts, aliases)
	var resource Job
	err := ctx.RegisterResource("azure-nextgen:batchai/latest:Job", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetJob gets an existing Job resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetJob(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *JobState, opts ...pulumi.ResourceOption) (*Job, error) {
	var resource Job
	err := ctx.ReadResource("azure-nextgen:batchai/latest:Job", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering Job resources.
type jobState struct {
	// Caffe2 job settings.
	Caffe2Settings *Caffe2SettingsResponse `pulumi:"caffe2Settings"`
	// Caffe job settings.
	CaffeSettings *CaffeSettingsResponse `pulumi:"caffeSettings"`
	// Chainer job settings.
	ChainerSettings *ChainerSettingsResponse `pulumi:"chainerSettings"`
	// Resource ID of the cluster associated with the job.
	Cluster *ResourceIdResponse `pulumi:"cluster"`
	// CNTK (aka Microsoft Cognitive Toolkit) job settings.
	CntkSettings *CNTKsettingsResponse `pulumi:"cntkSettings"`
	// Constraints associated with the Job.
	Constraints *JobPropertiesResponseConstraints `pulumi:"constraints"`
	// If the container was downloaded as part of cluster setup then the same container image will be used. If not provided, the job will run on the VM.
	ContainerSettings *ContainerSettingsResponse `pulumi:"containerSettings"`
	// The creation time of the job.
	CreationTime *string `pulumi:"creationTime"`
	// Custom MPI job settings.
	CustomMpiSettings *CustomMpiSettingsResponse `pulumi:"customMpiSettings"`
	// Custom tool kit job settings.
	CustomToolkitSettings *CustomToolkitSettingsResponse `pulumi:"customToolkitSettings"`
	// A collection of user defined environment variables to be setup for the job.
	EnvironmentVariables []EnvironmentVariableResponse `pulumi:"environmentVariables"`
	// Information about the execution of a job.
	ExecutionInfo *JobPropertiesResponseExecutionInfo `pulumi:"executionInfo"`
	// The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.
	ExecutionState *string `pulumi:"executionState"`
	// The time at which the job entered its current execution state.
	ExecutionStateTransitionTime *string `pulumi:"executionStateTransitionTime"`
	// Specifies the settings for Horovod job.
	HorovodSettings *HorovodSettingsResponse `pulumi:"horovodSettings"`
	// A list of input directories for the job.
	InputDirectories []InputDirectoryResponse `pulumi:"inputDirectories"`
	// A segment of job's output directories path created by Batch AI. Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem.
	JobOutputDirectoryPathSegment *string `pulumi:"jobOutputDirectoryPathSegment"`
	// The specified actions will run on all the nodes that are part of the job
	JobPreparation *JobPreparationResponse `pulumi:"jobPreparation"`
	// Collection of mount volumes available to the job during execution. These volumes are mounted before the job execution and unmounted after the job completion. The volumes are mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
	MountVolumes *MountVolumesResponse `pulumi:"mountVolumes"`
	// The name of the resource.
	Name *string `pulumi:"name"`
	// The job will be gang scheduled on that many compute nodes
	NodeCount *int `pulumi:"nodeCount"`
	// A list of output directories for the job.
	OutputDirectories []OutputDirectoryResponse `pulumi:"outputDirectories"`
	// The provisioned state of the Batch AI job
	ProvisioningState *string `pulumi:"provisioningState"`
	// The time at which the job entered its current provisioning state.
	ProvisioningStateTransitionTime *string `pulumi:"provisioningStateTransitionTime"`
	// pyTorch job settings.
	PyTorchSettings *PyTorchSettingsResponse `pulumi:"pyTorchSettings"`
	// Scheduling priority associated with the job.
	SchedulingPriority *string `pulumi:"schedulingPriority"`
	// A collection of user defined environment variables with secret values to be setup for the job. Server will never report values of these variables back.
	Secrets []EnvironmentVariableWithSecretValueResponse `pulumi:"secrets"`
	// The path where the Batch AI service stores stdout, stderror and execution log of the job.
	StdOutErrPathPrefix *string `pulumi:"stdOutErrPathPrefix"`
	// TensorFlow job settings.
	TensorFlowSettings *TensorFlowSettingsResponse `pulumi:"tensorFlowSettings"`
	// Possible values are: cntk, tensorflow, caffe, caffe2, chainer, pytorch, custom, custommpi, horovod.
	ToolType *string `pulumi:"toolType"`
	// The type of the resource.
	Type *string `pulumi:"type"`
}

type JobState struct {
	// Caffe2 job settings.
	Caffe2Settings Caffe2SettingsResponsePtrInput
	// Caffe job settings.
	CaffeSettings CaffeSettingsResponsePtrInput
	// Chainer job settings.
	ChainerSettings ChainerSettingsResponsePtrInput
	// Resource ID of the cluster associated with the job.
	Cluster ResourceIdResponsePtrInput
	// CNTK (aka Microsoft Cognitive Toolkit) job settings.
	CntkSettings CNTKsettingsResponsePtrInput
	// Constraints associated with the Job.
	Constraints JobPropertiesResponseConstraintsPtrInput
	// If the container was downloaded as part of cluster setup then the same container image will be used. If not provided, the job will run on the VM.
	ContainerSettings ContainerSettingsResponsePtrInput
	// The creation time of the job.
	CreationTime pulumi.StringPtrInput
	// Custom MPI job settings.
	CustomMpiSettings CustomMpiSettingsResponsePtrInput
	// Custom tool kit job settings.
	CustomToolkitSettings CustomToolkitSettingsResponsePtrInput
	// A collection of user defined environment variables to be setup for the job.
	EnvironmentVariables EnvironmentVariableResponseArrayInput
	// Information about the execution of a job.
	ExecutionInfo JobPropertiesResponseExecutionInfoPtrInput
	// The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.
	ExecutionState pulumi.StringPtrInput
	// The time at which the job entered its current execution state.
	ExecutionStateTransitionTime pulumi.StringPtrInput
	// Specifies the settings for Horovod job.
	HorovodSettings HorovodSettingsResponsePtrInput
	// A list of input directories for the job.
	InputDirectories InputDirectoryResponseArrayInput
	// A segment of job's output directories path created by Batch AI. Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem.
	JobOutputDirectoryPathSegment pulumi.StringPtrInput
	// The specified actions will run on all the nodes that are part of the job
	JobPreparation JobPreparationResponsePtrInput
	// Collection of mount volumes available to the job during execution. These volumes are mounted before the job execution and unmounted after the job completion. The volumes are mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
	MountVolumes MountVolumesResponsePtrInput
	// The name of the resource.
	Name pulumi.StringPtrInput
	// The job will be gang scheduled on that many compute nodes
	NodeCount pulumi.IntPtrInput
	// A list of output directories for the job.
	OutputDirectories OutputDirectoryResponseArrayInput
	// The provisioned state of the Batch AI job
	ProvisioningState pulumi.StringPtrInput
	// The time at which the job entered its current provisioning state.
	ProvisioningStateTransitionTime pulumi.StringPtrInput
	// pyTorch job settings.
	PyTorchSettings PyTorchSettingsResponsePtrInput
	// Scheduling priority associated with the job.
	SchedulingPriority pulumi.StringPtrInput
	// A collection of user defined environment variables with secret values to be setup for the job. Server will never report values of these variables back.
	Secrets EnvironmentVariableWithSecretValueResponseArrayInput
	// The path where the Batch AI service stores stdout, stderror and execution log of the job.
	StdOutErrPathPrefix pulumi.StringPtrInput
	// TensorFlow job settings.
	TensorFlowSettings TensorFlowSettingsResponsePtrInput
	// Possible values are: cntk, tensorflow, caffe, caffe2, chainer, pytorch, custom, custommpi, horovod.
	ToolType pulumi.StringPtrInput
	// The type of the resource.
	Type pulumi.StringPtrInput
}

func (JobState) ElementType() reflect.Type {
	return reflect.TypeOf((*jobState)(nil)).Elem()
}

type jobArgs struct {
	// Settings for Caffe2 job.
	Caffe2Settings *Caffe2Settings `pulumi:"caffe2Settings"`
	// Settings for Caffe job.
	CaffeSettings *CaffeSettings `pulumi:"caffeSettings"`
	// Settings for Chainer job.
	ChainerSettings *ChainerSettings `pulumi:"chainerSettings"`
	// Resource ID of the cluster on which this job will run.
	Cluster ResourceId `pulumi:"cluster"`
	// Settings for CNTK (aka Microsoft Cognitive Toolkit) job.
	CntkSettings *CNTKsettings `pulumi:"cntkSettings"`
	// Constraints associated with the Job.
	Constraints *JobBasePropertiesConstraints `pulumi:"constraints"`
	// Docker container settings for the job. If not provided, the job will run directly on the node.
	ContainerSettings *ContainerSettings `pulumi:"containerSettings"`
	// Settings for custom MPI job.
	CustomMpiSettings *CustomMpiSettings `pulumi:"customMpiSettings"`
	// Settings for custom tool kit job.
	CustomToolkitSettings *CustomToolkitSettings `pulumi:"customToolkitSettings"`
	// A list of user defined environment variables which will be setup for the job.
	EnvironmentVariables []EnvironmentVariable `pulumi:"environmentVariables"`
	// The name of the experiment. Experiment names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	ExperimentName string `pulumi:"experimentName"`
	// Settings for Horovod job.
	HorovodSettings *HorovodSettings `pulumi:"horovodSettings"`
	// A list of input directories for the job.
	InputDirectories []InputDirectory `pulumi:"inputDirectories"`
	// The name of the job within the specified resource group. Job names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	JobName string `pulumi:"jobName"`
	// A command line to be executed on each node allocated for the job before tool kit is launched.
	JobPreparation *JobPreparation `pulumi:"jobPreparation"`
	// Information on mount volumes to be used by the job. These volumes will be mounted before the job execution and will be unmounted after the job completion. The volumes will be mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
	MountVolumes *MountVolumes `pulumi:"mountVolumes"`
	// Number of compute nodes to run the job on. The job will be gang scheduled on that many compute nodes.
	NodeCount int `pulumi:"nodeCount"`
	// A list of output directories for the job.
	OutputDirectories []OutputDirectory `pulumi:"outputDirectories"`
	// Settings for pyTorch job.
	PyTorchSettings *PyTorchSettings `pulumi:"pyTorchSettings"`
	// Name of the resource group to which the resource belongs.
	ResourceGroupName string `pulumi:"resourceGroupName"`
	// Scheduling priority associated with the job. Possible values: low, normal, high.
	SchedulingPriority *string `pulumi:"schedulingPriority"`
	// A list of user defined environment variables with secret values which will be setup for the job. Server will never report values of these variables back.
	Secrets []EnvironmentVariableWithSecretValue `pulumi:"secrets"`
	// The path where the Batch AI service will store stdout, stderror and execution log of the job.
	StdOutErrPathPrefix string `pulumi:"stdOutErrPathPrefix"`
	// Settings for Tensor Flow job.
	TensorFlowSettings *TensorFlowSettings `pulumi:"tensorFlowSettings"`
	// The name of the workspace. Workspace names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	WorkspaceName string `pulumi:"workspaceName"`
}

// The set of arguments for constructing a Job resource.
type JobArgs struct {
	// Settings for Caffe2 job.
	Caffe2Settings Caffe2SettingsPtrInput
	// Settings for Caffe job.
	CaffeSettings CaffeSettingsPtrInput
	// Settings for Chainer job.
	ChainerSettings ChainerSettingsPtrInput
	// Resource ID of the cluster on which this job will run.
	Cluster ResourceIdInput
	// Settings for CNTK (aka Microsoft Cognitive Toolkit) job.
	CntkSettings CNTKsettingsPtrInput
	// Constraints associated with the Job.
	Constraints JobBasePropertiesConstraintsPtrInput
	// Docker container settings for the job. If not provided, the job will run directly on the node.
	ContainerSettings ContainerSettingsPtrInput
	// Settings for custom MPI job.
	CustomMpiSettings CustomMpiSettingsPtrInput
	// Settings for custom tool kit job.
	CustomToolkitSettings CustomToolkitSettingsPtrInput
	// A list of user defined environment variables which will be setup for the job.
	EnvironmentVariables EnvironmentVariableArrayInput
	// The name of the experiment. Experiment names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	ExperimentName pulumi.StringInput
	// Settings for Horovod job.
	HorovodSettings HorovodSettingsPtrInput
	// A list of input directories for the job.
	InputDirectories InputDirectoryArrayInput
	// The name of the job within the specified resource group. Job names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	JobName pulumi.StringInput
	// A command line to be executed on each node allocated for the job before tool kit is launched.
	JobPreparation JobPreparationPtrInput
	// Information on mount volumes to be used by the job. These volumes will be mounted before the job execution and will be unmounted after the job completion. The volumes will be mounted at location specified by $AZ_BATCHAI_JOB_MOUNT_ROOT environment variable.
	MountVolumes MountVolumesPtrInput
	// Number of compute nodes to run the job on. The job will be gang scheduled on that many compute nodes.
	NodeCount pulumi.IntInput
	// A list of output directories for the job.
	OutputDirectories OutputDirectoryArrayInput
	// Settings for pyTorch job.
	PyTorchSettings PyTorchSettingsPtrInput
	// Name of the resource group to which the resource belongs.
	ResourceGroupName pulumi.StringInput
	// Scheduling priority associated with the job. Possible values: low, normal, high.
	SchedulingPriority pulumi.StringPtrInput
	// A list of user defined environment variables with secret values which will be setup for the job. Server will never report values of these variables back.
	Secrets EnvironmentVariableWithSecretValueArrayInput
	// The path where the Batch AI service will store stdout, stderror and execution log of the job.
	StdOutErrPathPrefix pulumi.StringInput
	// Settings for Tensor Flow job.
	TensorFlowSettings TensorFlowSettingsPtrInput
	// The name of the workspace. Workspace names can only contain a combination of alphanumeric characters along with dash (-) and underscore (_). The name must be from 1 through 64 characters long.
	WorkspaceName pulumi.StringInput
}

func (JobArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*jobArgs)(nil)).Elem()
}
