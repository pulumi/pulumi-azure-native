// Code generated by the Pulumi SDK Generator DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package v20220601preview

import (
	"context"
	"reflect"

	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Policy for sharing applications on this compute instance among users of parent workspace. If Personal, only the creator can access applications on this compute instance. When Shared, any workspace user can access applications on this instance depending on his/her assigned role.
type ApplicationSharingPolicy string

const (
	ApplicationSharingPolicyPersonal = ApplicationSharingPolicy("Personal")
	ApplicationSharingPolicyShared   = ApplicationSharingPolicy("Shared")
)

// Logging level for batch inference operation.
type BatchLoggingLevel string

const (
	BatchLoggingLevelInfo    = BatchLoggingLevel("Info")
	BatchLoggingLevelWarning = BatchLoggingLevel("Warning")
	BatchLoggingLevelDebug   = BatchLoggingLevel("Debug")
)

// Indicates how the output will be organized.
type BatchOutputAction string

const (
	BatchOutputActionSummaryOnly = BatchOutputAction("SummaryOnly")
	BatchOutputActionAppendRow   = BatchOutputAction("AppendRow")
)

// Enum for all classification models supported by AutoML.
type BlockedTransformers string

const (
	// Target encoding for text data.
	BlockedTransformersTextTargetEncoder = BlockedTransformers("TextTargetEncoder")
	// Ohe hot encoding creates a binary feature transformation.
	BlockedTransformersOneHotEncoder = BlockedTransformers("OneHotEncoder")
	// Target encoding for categorical data.
	BlockedTransformersCatTargetEncoder = BlockedTransformers("CatTargetEncoder")
	// Tf-Idf stands for, term-frequency times inverse document-frequency. This is a common term weighting scheme for identifying information from documents.
	BlockedTransformersTfIdf = BlockedTransformers("TfIdf")
	// Weight of Evidence encoding is a technique used to encode categorical variables. It uses the natural log of the P(1)/P(0) to create weights.
	BlockedTransformersWoETargetEncoder = BlockedTransformers("WoETargetEncoder")
	// Label encoder converts labels/categorical variables in a numerical form.
	BlockedTransformersLabelEncoder = BlockedTransformers("LabelEncoder")
	// Word embedding helps represents words or phrases as a vector, or a series of numbers.
	BlockedTransformersWordEmbedding = BlockedTransformers("WordEmbedding")
	// Naive Bayes is a classified that is used for classification of discrete features that are categorically distributed.
	BlockedTransformersNaiveBayes = BlockedTransformers("NaiveBayes")
	// Count Vectorizer converts a collection of text documents to a matrix of token counts.
	BlockedTransformersCountVectorizer = BlockedTransformers("CountVectorizer")
	// Hashing One Hot Encoder can turn categorical variables into a limited number of new features. This is often used for high-cardinality categorical features.
	BlockedTransformersHashOneHotEncoder = BlockedTransformers("HashOneHotEncoder")
)

// Enum for all classification models supported by AutoML.
type ClassificationModels string

const (
	// Logistic regression is a fundamental classification technique.
	// It belongs to the group of linear classifiers and is somewhat similar to polynomial and linear regression.
	// Logistic regression is fast and relatively uncomplicated, and it's convenient for you to interpret the results.
	// Although it's essentially a method for binary classification, it can also be applied to multiclass problems.
	ClassificationModelsLogisticRegression = ClassificationModels("LogisticRegression")
	// SGD: Stochastic gradient descent is an optimization algorithm often used in machine learning applications
	// to find the model parameters that correspond to the best fit between predicted and actual outputs.
	ClassificationModelsSGD = ClassificationModels("SGD")
	// The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification).
	// The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.
	ClassificationModelsMultinomialNaiveBayes = ClassificationModels("MultinomialNaiveBayes")
	// Naive Bayes classifier for multivariate Bernoulli models.
	ClassificationModelsBernoulliNaiveBayes = ClassificationModels("BernoulliNaiveBayes")
	// A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems.
	// After giving an SVM model sets of labeled training data for each category, they're able to categorize new text.
	ClassificationModelsSVM = ClassificationModels("SVM")
	// A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems.
	// After giving an SVM model sets of labeled training data for each category, they're able to categorize new text.
	// Linear SVM performs best when input data is linear, i.e., data can be easily classified by drawing the straight line between classified values on a plotted graph.
	ClassificationModelsLinearSVM = ClassificationModels("LinearSVM")
	// K-nearest neighbors (KNN) algorithm uses 'feature similarity' to predict the values of new datapoints
	// which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.
	ClassificationModelsKNN = ClassificationModels("KNN")
	// Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks.
	// The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.
	ClassificationModelsDecisionTree = ClassificationModels("DecisionTree")
	// Random forest is a supervised learning algorithm.
	// The "forest" it builds, is an ensemble of decision trees, usually trained with the “bagging” method.
	// The general idea of the bagging method is that a combination of learning models increases the overall result.
	ClassificationModelsRandomForest = ClassificationModels("RandomForest")
	// Extreme Trees is an ensemble machine learning algorithm that combines the predictions from many decision trees. It is related to the widely used random forest algorithm.
	ClassificationModelsExtremeRandomTrees = ClassificationModels("ExtremeRandomTrees")
	// LightGBM is a gradient boosting framework that uses tree based learning algorithms.
	ClassificationModelsLightGBM = ClassificationModels("LightGBM")
	// The technique of transiting week learners into a strong learner is called Boosting. The gradient boosting algorithm process works on this theory of execution.
	ClassificationModelsGradientBoosting = ClassificationModels("GradientBoosting")
	// XGBoost: Extreme Gradient Boosting Algorithm. This algorithm is used for structured data where target column values can be divided into distinct class values.
	ClassificationModelsXGBoostClassifier = ClassificationModels("XGBoostClassifier")
)

// Primary metric to optimize for this task.
type ClassificationMultilabelPrimaryMetrics string

const (
	// AUC is the Area under the curve.
	// This metric represents arithmetic mean of the score for each class,
	// weighted by the number of true instances in each class.
	ClassificationMultilabelPrimaryMetricsAUCWeighted = ClassificationMultilabelPrimaryMetrics("AUCWeighted")
	// Accuracy is the ratio of predictions that exactly match the true class labels.
	ClassificationMultilabelPrimaryMetricsAccuracy = ClassificationMultilabelPrimaryMetrics("Accuracy")
	// Normalized macro recall is recall macro-averaged and normalized, so that random
	// performance has a score of 0, and perfect performance has a score of 1.
	ClassificationMultilabelPrimaryMetricsNormMacroRecall = ClassificationMultilabelPrimaryMetrics("NormMacroRecall")
	// The arithmetic mean of the average precision score for each class, weighted by
	// the number of true instances in each class.
	ClassificationMultilabelPrimaryMetricsAveragePrecisionScoreWeighted = ClassificationMultilabelPrimaryMetrics("AveragePrecisionScoreWeighted")
	// The arithmetic mean of precision for each class, weighted by number of true instances in each class.
	ClassificationMultilabelPrimaryMetricsPrecisionScoreWeighted = ClassificationMultilabelPrimaryMetrics("PrecisionScoreWeighted")
	// Intersection Over Union. Intersection of predictions divided by union of predictions.
	ClassificationMultilabelPrimaryMetricsIOU = ClassificationMultilabelPrimaryMetrics("IOU")
)

// Primary metric for Text-Classification task.
type ClassificationPrimaryMetrics string

const (
	// AUC is the Area under the curve.
	// This metric represents arithmetic mean of the score for each class,
	// weighted by the number of true instances in each class.
	ClassificationPrimaryMetricsAUCWeighted = ClassificationPrimaryMetrics("AUCWeighted")
	// Accuracy is the ratio of predictions that exactly match the true class labels.
	ClassificationPrimaryMetricsAccuracy = ClassificationPrimaryMetrics("Accuracy")
	// Normalized macro recall is recall macro-averaged and normalized, so that random
	// performance has a score of 0, and perfect performance has a score of 1.
	ClassificationPrimaryMetricsNormMacroRecall = ClassificationPrimaryMetrics("NormMacroRecall")
	// The arithmetic mean of the average precision score for each class, weighted by
	// the number of true instances in each class.
	ClassificationPrimaryMetricsAveragePrecisionScoreWeighted = ClassificationPrimaryMetrics("AveragePrecisionScoreWeighted")
	// The arithmetic mean of precision for each class, weighted by number of true instances in each class.
	ClassificationPrimaryMetricsPrecisionScoreWeighted = ClassificationPrimaryMetrics("PrecisionScoreWeighted")
)

// Intended usage of the cluster
type ClusterPurpose string

const (
	ClusterPurposeFastProd  = ClusterPurpose("FastProd")
	ClusterPurposeDenseProd = ClusterPurpose("DenseProd")
	ClusterPurposeDevTest   = ClusterPurpose("DevTest")
)

// The Compute Instance Authorization type. Available values are personal (default).
type ComputeInstanceAuthorizationType string

const (
	ComputeInstanceAuthorizationTypePersonal = ComputeInstanceAuthorizationType("personal")
)

// The type of compute
type ComputeType string

const (
	ComputeTypeAKS               = ComputeType("AKS")
	ComputeTypeKubernetes        = ComputeType("Kubernetes")
	ComputeTypeAmlCompute        = ComputeType("AmlCompute")
	ComputeTypeComputeInstance   = ComputeType("ComputeInstance")
	ComputeTypeDataFactory       = ComputeType("DataFactory")
	ComputeTypeVirtualMachine    = ComputeType("VirtualMachine")
	ComputeTypeHDInsight         = ComputeType("HDInsight")
	ComputeTypeDatabricks        = ComputeType("Databricks")
	ComputeTypeDataLakeAnalytics = ComputeType("DataLakeAnalytics")
	ComputeTypeSynapseSpark      = ComputeType("SynapseSpark")
)

// Authentication type of the connection target
type ConnectionAuthType string

const (
	ConnectionAuthTypePAT              = ConnectionAuthType("PAT")
	ConnectionAuthTypeManagedIdentity  = ConnectionAuthType("ManagedIdentity")
	ConnectionAuthTypeUsernamePassword = ConnectionAuthType("UsernamePassword")
	ConnectionAuthTypeNone             = ConnectionAuthType("None")
	ConnectionAuthTypeSAS              = ConnectionAuthType("SAS")
)

// Category of the connection
type ConnectionCategory string

const (
	ConnectionCategoryPythonFeed        = ConnectionCategory("PythonFeed")
	ConnectionCategoryContainerRegistry = ConnectionCategory("ContainerRegistry")
	ConnectionCategoryGit               = ConnectionCategory("Git")
)

// The type of container to retrieve logs from.
type ContainerType string

const (
	ContainerTypeStorageInitializer = ContainerType("StorageInitializer")
	ContainerTypeInferenceServer    = ContainerType("InferenceServer")
)

// [Required] Credential type used to authentication with storage.
type CredentialsType string

const (
	CredentialsTypeAccountKey       = CredentialsType("AccountKey")
	CredentialsTypeCertificate      = CredentialsType("Certificate")
	CredentialsTypeNone             = CredentialsType("None")
	CredentialsTypeSas              = CredentialsType("Sas")
	CredentialsTypeServicePrincipal = CredentialsType("ServicePrincipal")
	CredentialsTypeKerberosKeytab   = CredentialsType("KerberosKeytab")
	CredentialsTypeKerberosPassword = CredentialsType("KerberosPassword")
)

// [Required] Specifies the type of data.
type DataType string

const (
	DataType_Uri_file   = DataType("uri_file")
	DataType_Uri_folder = DataType("uri_folder")
	DataTypeMltable     = DataType("mltable")
)

// [Required] Storage type backing the datastore.
type DatastoreType string

const (
	DatastoreTypeAzureBlob         = DatastoreType("AzureBlob")
	DatastoreTypeAzureDataLakeGen1 = DatastoreType("AzureDataLakeGen1")
	DatastoreTypeAzureDataLakeGen2 = DatastoreType("AzureDataLakeGen2")
	DatastoreTypeAzureFile         = DatastoreType("AzureFile")
	DatastoreTypeHdfs              = DatastoreType("Hdfs")
)

// [Required] Specifies the type of distribution framework.
type DistributionType string

const (
	DistributionTypePyTorch    = DistributionType("PyTorch")
	DistributionTypeTensorFlow = DistributionType("TensorFlow")
	DistributionTypeMpi        = DistributionType("Mpi")
)

// [Required] Name of policy configuration
type EarlyTerminationPolicyType string

const (
	EarlyTerminationPolicyTypeBandit              = EarlyTerminationPolicyType("Bandit")
	EarlyTerminationPolicyTypeMedianStopping      = EarlyTerminationPolicyType("MedianStopping")
	EarlyTerminationPolicyTypeTruncationSelection = EarlyTerminationPolicyType("TruncationSelection")
)

// If Enabled, allow egress public network access. If Disabled, this will create secure egress. Default: Enabled.
type EgressPublicNetworkAccessType string

const (
	EgressPublicNetworkAccessTypeEnabled  = EgressPublicNetworkAccessType("Enabled")
	EgressPublicNetworkAccessTypeDisabled = EgressPublicNetworkAccessType("Disabled")
)

// Indicates whether or not the encryption is enabled for the workspace.
type EncryptionStatus string

const (
	EncryptionStatusEnabled  = EncryptionStatus("Enabled")
	EncryptionStatusDisabled = EncryptionStatus("Disabled")
)

// [Required] Use 'Key' for key based authentication and 'AMLToken' for Azure Machine Learning token-based authentication. 'Key' doesn't expire but 'AMLToken' does.
type EndpointAuthMode string

const (
	EndpointAuthModeAMLToken = EndpointAuthMode("AMLToken")
	EndpointAuthModeKey      = EndpointAuthMode("Key")
	EndpointAuthModeAADToken = EndpointAuthMode("AADToken")
)

// [Required] The compute type of the endpoint.
type EndpointComputeType string

const (
	EndpointComputeTypeManaged        = EndpointComputeType("Managed")
	EndpointComputeTypeKubernetes     = EndpointComputeType("Kubernetes")
	EndpointComputeTypeAzureMLCompute = EndpointComputeType("AzureMLCompute")
)

// Type of the Environment Variable. Possible values are: local - For local variable
type EnvironmentVariableType string

const (
	EnvironmentVariableTypeLocal = EnvironmentVariableType("local")
)

// Flag for generating lags for the numeric features with 'auto' or null.
type FeatureLags string

const (
	// No feature lags generated.
	FeatureLagsNone = FeatureLags("None")
	// System auto-generates feature lags.
	FeatureLagsAuto = FeatureLags("Auto")
)

// Featurization mode - User can keep the default 'Auto' mode and AutoML will take care of necessary transformation of the data in featurization phase.
// If 'Off' is selected then no featurization is done.
// If 'Custom' is selected then user can specify additional inputs to customize how featurization is done.
type FeaturizationMode string

const (
	// Auto mode, system performs featurization without any custom featurization inputs.
	FeaturizationModeAuto = FeaturizationMode("Auto")
	// Custom featurization.
	FeaturizationModeCustom = FeaturizationMode("Custom")
	// Featurization off. 'Forecasting' task cannot use this value.
	FeaturizationModeOff = FeaturizationMode("Off")
)

// [Required] Set forecast horizon value selection mode.
type ForecastHorizonMode string

const (
	// Forecast horizon to be determined automatically.
	ForecastHorizonModeAuto = ForecastHorizonMode("Auto")
	// Use the custom forecast horizon.
	ForecastHorizonModeCustom = ForecastHorizonMode("Custom")
)

// Enum for all forecasting models supported by AutoML.
type ForecastingModels string

const (
	// Auto-Autoregressive Integrated Moving Average (ARIMA) model uses time-series data and statistical analysis to interpret the data and make future predictions.
	// This model aims to explain data by using time series data on its past values and uses linear regression to make predictions.
	ForecastingModelsAutoArima = ForecastingModels("AutoArima")
	// Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.
	// It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well.
	ForecastingModelsProphet = ForecastingModels("Prophet")
	// The Naive forecasting model makes predictions by carrying forward the latest target value for each time-series in the training data.
	ForecastingModelsNaive = ForecastingModels("Naive")
	// The Seasonal Naive forecasting model makes predictions by carrying forward the latest season of target values for each time-series in the training data.
	ForecastingModelsSeasonalNaive = ForecastingModels("SeasonalNaive")
	// The Average forecasting model makes predictions by carrying forward the average of the target values for each time-series in the training data.
	ForecastingModelsAverage = ForecastingModels("Average")
	// The Seasonal Average forecasting model makes predictions by carrying forward the average value of the latest season of data for each time-series in the training data.
	ForecastingModelsSeasonalAverage = ForecastingModels("SeasonalAverage")
	// Exponential smoothing is a time series forecasting method for univariate data that can be extended to support data with a systematic trend or seasonal component.
	ForecastingModelsExponentialSmoothing = ForecastingModels("ExponentialSmoothing")
	// An Autoregressive Integrated Moving Average with Explanatory Variable (ARIMAX) model can be viewed as a multiple regression model with one or more autoregressive (AR) terms and/or one or more moving average (MA) terms.
	// This method is suitable for forecasting when data is stationary/non stationary, and multivariate with any type of data pattern, i.e., level/trend /seasonality/cyclicity.
	ForecastingModelsArimax = ForecastingModels("Arimax")
	// TCNForecaster: Temporal Convolutional Networks Forecaster. //TODO: Ask forecasting team for brief intro.
	ForecastingModelsTCNForecaster = ForecastingModels("TCNForecaster")
	// Elastic net is a popular type of regularized linear regression that combines two popular penalties, specifically the L1 and L2 penalty functions.
	ForecastingModelsElasticNet = ForecastingModels("ElasticNet")
	// The technique of transiting week learners into a strong learner is called Boosting. The gradient boosting algorithm process works on this theory of execution.
	ForecastingModelsGradientBoosting = ForecastingModels("GradientBoosting")
	// Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks.
	// The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.
	ForecastingModelsDecisionTree = ForecastingModels("DecisionTree")
	// K-nearest neighbors (KNN) algorithm uses 'feature similarity' to predict the values of new datapoints
	// which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.
	ForecastingModelsKNN = ForecastingModels("KNN")
	// Lasso model fit with Least Angle Regression a.k.a. Lars. It is a Linear Model trained with an L1 prior as regularizer.
	ForecastingModelsLassoLars = ForecastingModels("LassoLars")
	// SGD: Stochastic gradient descent is an optimization algorithm often used in machine learning applications
	// to find the model parameters that correspond to the best fit between predicted and actual outputs.
	// It's an inexact but powerful technique.
	ForecastingModelsSGD = ForecastingModels("SGD")
	// Random forest is a supervised learning algorithm.
	// The "forest" it builds, is an ensemble of decision trees, usually trained with the “bagging” method.
	// The general idea of the bagging method is that a combination of learning models increases the overall result.
	ForecastingModelsRandomForest = ForecastingModels("RandomForest")
	// Extreme Trees is an ensemble machine learning algorithm that combines the predictions from many decision trees. It is related to the widely used random forest algorithm.
	ForecastingModelsExtremeRandomTrees = ForecastingModels("ExtremeRandomTrees")
	// LightGBM is a gradient boosting framework that uses tree based learning algorithms.
	ForecastingModelsLightGBM = ForecastingModels("LightGBM")
	// XGBoostRegressor: Extreme Gradient Boosting Regressor is a supervised machine learning model using ensemble of base learners.
	ForecastingModelsXGBoostRegressor = ForecastingModels("XGBoostRegressor")
)

// Primary metric for forecasting task.
type ForecastingPrimaryMetrics string

const (
	// The Spearman's rank coefficient of correlation is a non-parametric measure of rank correlation.
	ForecastingPrimaryMetricsSpearmanCorrelation = ForecastingPrimaryMetrics("SpearmanCorrelation")
	// The Normalized Root Mean Squared Error (NRMSE) the RMSE facilitates the comparison between models with different scales.
	ForecastingPrimaryMetricsNormalizedRootMeanSquaredError = ForecastingPrimaryMetrics("NormalizedRootMeanSquaredError")
	// The R2 score is one of the performance evaluation measures for forecasting-based machine learning models.
	ForecastingPrimaryMetricsR2Score = ForecastingPrimaryMetrics("R2Score")
	// The Normalized Mean Absolute Error (NMAE) is a validation metric to compare the Mean Absolute Error (MAE) of (time) series with different scales.
	ForecastingPrimaryMetricsNormalizedMeanAbsoluteError = ForecastingPrimaryMetrics("NormalizedMeanAbsoluteError")
)

// [Required] Defines supported metric goals for hyperparameter tuning
type Goal string

const (
	GoalMinimize = Goal("Minimize")
	GoalMaximize = Goal("Maximize")
)

// [Required] Specifies the type of identity framework.
type IdentityConfigurationType string

const (
	IdentityConfigurationTypeManaged      = IdentityConfigurationType("Managed")
	IdentityConfigurationTypeAMLToken     = IdentityConfigurationType("AMLToken")
	IdentityConfigurationTypeUserIdentity = IdentityConfigurationType("UserIdentity")
)

// Annotation type of image labeling job.
type ImageAnnotationType string

const (
	ImageAnnotationTypeClassification       = ImageAnnotationType("Classification")
	ImageAnnotationTypeBoundingBox          = ImageAnnotationType("BoundingBox")
	ImageAnnotationTypeInstanceSegmentation = ImageAnnotationType("InstanceSegmentation")
)

// Type of the image. Possible values are: docker - For docker images. azureml - For AzureML images
type ImageType string

const (
	ImageTypeDocker  = ImageType("docker")
	ImageTypeAzureml = ImageType("azureml")
)

// Input Asset Delivery Mode.
type InputDeliveryMode string

const (
	InputDeliveryModeReadOnlyMount  = InputDeliveryMode("ReadOnlyMount")
	InputDeliveryModeReadWriteMount = InputDeliveryMode("ReadWriteMount")
	InputDeliveryModeDownload       = InputDeliveryMode("Download")
	InputDeliveryModeDirect         = InputDeliveryMode("Direct")
	InputDeliveryModeEvalMount      = InputDeliveryMode("EvalMount")
	InputDeliveryModeEvalDownload   = InputDeliveryMode("EvalDownload")
)

// Primary metric to optimize for this task.
type InstanceSegmentationPrimaryMetrics string

const (
	// Mean Average Precision (MAP) is the average of AP (Average Precision).
	// AP is calculated for each class and averaged to get the MAP.
	InstanceSegmentationPrimaryMetricsMeanAveragePrecision = InstanceSegmentationPrimaryMetrics("MeanAveragePrecision")
)

// [Required] Specifies the type of job.
type JobInputType string

const (
	JobInputTypeLiteral       = JobInputType("literal")
	JobInputType_Uri_file     = JobInputType("uri_file")
	JobInputType_Uri_folder   = JobInputType("uri_folder")
	JobInputTypeMltable       = JobInputType("mltable")
	JobInputType_Custom_model = JobInputType("custom_model")
	JobInputType_Mlflow_model = JobInputType("mlflow_model")
	JobInputType_Triton_model = JobInputType("triton_model")
)

// [Required] JobLimit type.
type JobLimitsType string

const (
	JobLimitsTypeCommand = JobLimitsType("Command")
	JobLimitsTypeSweep   = JobLimitsType("Sweep")
)

// [Required] Specifies the type of job.
type JobOutputType string

const (
	JobOutputType_Uri_file     = JobOutputType("uri_file")
	JobOutputType_Uri_folder   = JobOutputType("uri_folder")
	JobOutputTypeMltable       = JobOutputType("mltable")
	JobOutputType_Custom_model = JobOutputType("custom_model")
	JobOutputType_Mlflow_model = JobOutputType("mlflow_model")
	JobOutputType_Triton_model = JobOutputType("triton_model")
)

// [Required] Specifies the type of job.
type JobType string

const (
	JobTypeAutoML   = JobType("AutoML")
	JobTypeCommand  = JobType("Command")
	JobTypeLabeling = JobType("Labeling")
	JobTypeSweep    = JobType("Sweep")
	JobTypePipeline = JobType("Pipeline")
	JobTypeSpark    = JobType("Spark")
)

// Type of learning rate scheduler. Must be 'warmup_cosine' or 'step'.
type LearningRateScheduler string

const (
	// No learning rate scheduler selected.
	LearningRateSchedulerNone = LearningRateScheduler("None")
	// Cosine Annealing With Warmup.
	LearningRateSchedulerWarmupCosine = LearningRateScheduler("WarmupCosine")
	// Step learning rate scheduler.
	LearningRateSchedulerStep = LearningRateScheduler("Step")
)

// Load Balancer Type
type LoadBalancerType string

const (
	LoadBalancerTypePublicIp             = LoadBalancerType("PublicIp")
	LoadBalancerTypeInternalLoadBalancer = LoadBalancerType("InternalLoadBalancer")
)

// Log verbosity for the job.
type LogVerbosity string

const (
	// No logs emitted.
	LogVerbosityNotSet = LogVerbosity("NotSet")
	// Debug and above log statements logged.
	LogVerbosityDebug = LogVerbosity("Debug")
	// Info and above log statements logged.
	LogVerbosityInfo = LogVerbosity("Info")
	// Warning and above log statements logged.
	LogVerbosityWarning = LogVerbosity("Warning")
	// Error and above log statements logged.
	LogVerbosityError = LogVerbosity("Error")
	// Only critical statements logged.
	LogVerbosityCritical = LogVerbosity("Critical")
)

// [Required] Indicates whether MLAssist feature is enabled.
type MLAssistConfigurationType string

const (
	MLAssistConfigurationTypeEnabled  = MLAssistConfigurationType("Enabled")
	MLAssistConfigurationTypeDisabled = MLAssistConfigurationType("Disabled")
)

// Type of managed service identity (where both SystemAssigned and UserAssigned types are allowed).
type ManagedServiceIdentityType string

const (
	ManagedServiceIdentityTypeNone                         = ManagedServiceIdentityType("None")
	ManagedServiceIdentityTypeSystemAssigned               = ManagedServiceIdentityType("SystemAssigned")
	ManagedServiceIdentityTypeUserAssigned                 = ManagedServiceIdentityType("UserAssigned")
	ManagedServiceIdentityType_SystemAssigned_UserAssigned = ManagedServiceIdentityType("SystemAssigned,UserAssigned")
)

// [Required] Media type of the job.
type MediaType string

const (
	MediaTypeImage = MediaType("Image")
	MediaTypeText  = MediaType("Text")
)

// Model size. Must be 'small', 'medium', 'large', or 'xlarge'.
// Note: training run may get into CUDA OOM if the model size is too big.
// Note: This settings is only supported for the 'yolov5' algorithm.
type ModelSize string

const (
	// No value selected.
	ModelSizeNone = ModelSize("None")
	// Small size.
	ModelSizeSmall = ModelSize("Small")
	// Medium size.
	ModelSizeMedium = ModelSize("Medium")
	// Large size.
	ModelSizeLarge = ModelSize("Large")
	// Extra large size.
	ModelSizeExtraLarge = ModelSize("ExtraLarge")
)

// [Required] Mode for determining N-Cross validations.
type NCrossValidationsMode string

const (
	// Determine N-Cross validations value automatically. Supported only for 'Forecasting' AutoML task.
	NCrossValidationsModeAuto = NCrossValidationsMode("Auto")
	// Use custom N-Cross validations value.
	NCrossValidationsModeCustom = NCrossValidationsMode("Custom")
)

// Primary metric to optimize for this task.
type ObjectDetectionPrimaryMetrics string

const (
	// Mean Average Precision (MAP) is the average of AP (Average Precision).
	// AP is calculated for each class and averaged to get the MAP.
	ObjectDetectionPrimaryMetricsMeanAveragePrecision = ObjectDetectionPrimaryMetrics("MeanAveragePrecision")
)

// The OS type of the environment.
type OperatingSystemType string

const (
	OperatingSystemTypeLinux   = OperatingSystemType("Linux")
	OperatingSystemTypeWindows = OperatingSystemType("Windows")
)

// Compute OS Type
type OsType string

const (
	OsTypeLinux   = OsType("Linux")
	OsTypeWindows = OsType("Windows")
)

// Output Asset Delivery Mode.
type OutputDeliveryMode string

const (
	OutputDeliveryModeReadWriteMount = OutputDeliveryMode("ReadWriteMount")
	OutputDeliveryModeUpload         = OutputDeliveryMode("Upload")
	OutputDeliveryModeDirect         = OutputDeliveryMode("Direct")
)

// Indicates whether the connection has been Approved/Rejected/Removed by the owner of the service.
type PrivateEndpointServiceConnectionStatus string

const (
	PrivateEndpointServiceConnectionStatusPending      = PrivateEndpointServiceConnectionStatus("Pending")
	PrivateEndpointServiceConnectionStatusApproved     = PrivateEndpointServiceConnectionStatus("Approved")
	PrivateEndpointServiceConnectionStatusRejected     = PrivateEndpointServiceConnectionStatus("Rejected")
	PrivateEndpointServiceConnectionStatusDisconnected = PrivateEndpointServiceConnectionStatus("Disconnected")
	PrivateEndpointServiceConnectionStatusTimeout      = PrivateEndpointServiceConnectionStatus("Timeout")
)

// Protocol over which communication will happen over this endpoint
type Protocol string

const (
	ProtocolTcp  = Protocol("tcp")
	ProtocolUdp  = Protocol("udp")
	ProtocolHttp = Protocol("http")
)

// Whether requests from Public Network are allowed.
type PublicNetworkAccess string

const (
	PublicNetworkAccessEnabled  = PublicNetworkAccess("Enabled")
	PublicNetworkAccessDisabled = PublicNetworkAccess("Disabled")
)

// Set to "Enabled" for endpoints that should allow public access when Private Link is enabled.
type PublicNetworkAccessType string

const (
	PublicNetworkAccessTypeEnabled  = PublicNetworkAccessType("Enabled")
	PublicNetworkAccessTypeDisabled = PublicNetworkAccessType("Disabled")
)

// The specific type of random algorithm
type RandomSamplingAlgorithmRule string

const (
	RandomSamplingAlgorithmRuleRandom = RandomSamplingAlgorithmRule("Random")
	RandomSamplingAlgorithmRuleSobol  = RandomSamplingAlgorithmRule("Sobol")
)

// [Required] The frequency to trigger schedule.
type RecurrenceFrequency string

const (
	// Minute frequency
	RecurrenceFrequencyMinute = RecurrenceFrequency("Minute")
	// Hour frequency
	RecurrenceFrequencyHour = RecurrenceFrequency("Hour")
	// Day frequency
	RecurrenceFrequencyDay = RecurrenceFrequency("Day")
	// Week frequency
	RecurrenceFrequencyWeek = RecurrenceFrequency("Week")
	// Month frequency
	RecurrenceFrequencyMonth = RecurrenceFrequency("Month")
)

// [Required] Specifies the type of asset reference.
type ReferenceType string

const (
	ReferenceTypeId         = ReferenceType("Id")
	ReferenceTypeDataPath   = ReferenceType("DataPath")
	ReferenceTypeOutputPath = ReferenceType("OutputPath")
)

// Enum for all Regression models supported by AutoML.
type RegressionModels string

const (
	// Elastic net is a popular type of regularized linear regression that combines two popular penalties, specifically the L1 and L2 penalty functions.
	RegressionModelsElasticNet = RegressionModels("ElasticNet")
	// The technique of transiting week learners into a strong learner is called Boosting. The gradient boosting algorithm process works on this theory of execution.
	RegressionModelsGradientBoosting = RegressionModels("GradientBoosting")
	// Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks.
	// The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.
	RegressionModelsDecisionTree = RegressionModels("DecisionTree")
	// K-nearest neighbors (KNN) algorithm uses 'feature similarity' to predict the values of new datapoints
	// which further means that the new data point will be assigned a value based on how closely it matches the points in the training set.
	RegressionModelsKNN = RegressionModels("KNN")
	// Lasso model fit with Least Angle Regression a.k.a. Lars. It is a Linear Model trained with an L1 prior as regularizer.
	RegressionModelsLassoLars = RegressionModels("LassoLars")
	// SGD: Stochastic gradient descent is an optimization algorithm often used in machine learning applications
	// to find the model parameters that correspond to the best fit between predicted and actual outputs.
	// It's an inexact but powerful technique.
	RegressionModelsSGD = RegressionModels("SGD")
	// Random forest is a supervised learning algorithm.
	// The "forest" it builds, is an ensemble of decision trees, usually trained with the “bagging” method.
	// The general idea of the bagging method is that a combination of learning models increases the overall result.
	RegressionModelsRandomForest = RegressionModels("RandomForest")
	// Extreme Trees is an ensemble machine learning algorithm that combines the predictions from many decision trees. It is related to the widely used random forest algorithm.
	RegressionModelsExtremeRandomTrees = RegressionModels("ExtremeRandomTrees")
	// LightGBM is a gradient boosting framework that uses tree based learning algorithms.
	RegressionModelsLightGBM = RegressionModels("LightGBM")
	// XGBoostRegressor: Extreme Gradient Boosting Regressor is a supervised machine learning model using ensemble of base learners.
	RegressionModelsXGBoostRegressor = RegressionModels("XGBoostRegressor")
)

// Primary metric for regression task.
type RegressionPrimaryMetrics string

const (
	// The Spearman's rank coefficient of correlation is a nonparametric measure of rank correlation.
	RegressionPrimaryMetricsSpearmanCorrelation = RegressionPrimaryMetrics("SpearmanCorrelation")
	// The Normalized Root Mean Squared Error (NRMSE) the RMSE facilitates the comparison between models with different scales.
	RegressionPrimaryMetricsNormalizedRootMeanSquaredError = RegressionPrimaryMetrics("NormalizedRootMeanSquaredError")
	// The R2 score is one of the performance evaluation measures for forecasting-based machine learning models.
	RegressionPrimaryMetricsR2Score = RegressionPrimaryMetrics("R2Score")
	// The Normalized Mean Absolute Error (NMAE) is a validation metric to compare the Mean Absolute Error (MAE) of (time) series with different scales.
	RegressionPrimaryMetricsNormalizedMeanAbsoluteError = RegressionPrimaryMetrics("NormalizedMeanAbsoluteError")
)

// State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh port is closed on all nodes of the cluster. Enabled - Indicates that the public ssh port is open on all nodes of the cluster. NotSpecified - Indicates that the public ssh port is closed on all nodes of the cluster if VNet is defined, else is open all public nodes. It can be default only during cluster creation time, after creation it will be either enabled or disabled.
type RemoteLoginPortPublicAccess string

const (
	RemoteLoginPortPublicAccessEnabled      = RemoteLoginPortPublicAccess("Enabled")
	RemoteLoginPortPublicAccessDisabled     = RemoteLoginPortPublicAccess("Disabled")
	RemoteLoginPortPublicAccessNotSpecified = RemoteLoginPortPublicAccess("NotSpecified")
)

// [Required] The algorithm used for generating hyperparameter values, along with configuration properties
type SamplingAlgorithmType string

const (
	SamplingAlgorithmTypeGrid     = SamplingAlgorithmType("Grid")
	SamplingAlgorithmTypeRandom   = SamplingAlgorithmType("Random")
	SamplingAlgorithmTypeBayesian = SamplingAlgorithmType("Bayesian")
)

// [Required] Type of deployment scaling algorithm
type ScaleType string

const (
	ScaleTypeDefault           = ScaleType("Default")
	ScaleTypeTargetUtilization = ScaleType("TargetUtilization")
)

// [Required] Specifies the action type of the schedule
type ScheduleActionType string

const (
	ScheduleActionTypeCreateJob           = ScheduleActionType("CreateJob")
	ScheduleActionTypeInvokeBatchEndpoint = ScheduleActionType("InvokeBatchEndpoint")
)

// [Required] Seasonality mode.
type SeasonalityMode string

const (
	// Seasonality to be determined automatically.
	SeasonalityModeAuto = SeasonalityMode("Auto")
	// Use the custom seasonality value.
	SeasonalityModeCustom = SeasonalityMode("Custom")
)

// [Required] Credential type used to authentication with storage.
type SecretsType string

const (
	SecretsTypeAccountKey       = SecretsType("AccountKey")
	SecretsTypeCertificate      = SecretsType("Certificate")
	SecretsTypeSas              = SecretsType("Sas")
	SecretsTypeServicePrincipal = SecretsType("ServicePrincipal")
	SecretsTypeKerberosPassword = SecretsType("KerberosPassword")
	SecretsTypeKerberosKeytab   = SecretsType("KerberosKeytab")
)

// Indicates which identity to use to authenticate service data access to customer's storage.
type ServiceDataAccessAuthIdentity string

const (
	// Do not use any identity for service data access.
	ServiceDataAccessAuthIdentityNone = ServiceDataAccessAuthIdentity("None")
	// Use the system assigned managed identity of the Workspace to authenticate service data access.
	ServiceDataAccessAuthIdentityWorkspaceSystemAssignedIdentity = ServiceDataAccessAuthIdentity("WorkspaceSystemAssignedIdentity")
	// Use the user assigned managed identity of the Workspace to authenticate service data access.
	ServiceDataAccessAuthIdentityWorkspaceUserAssignedIdentity = ServiceDataAccessAuthIdentity("WorkspaceUserAssignedIdentity")
)

// The parameter defining how if AutoML should handle short time series.
type ShortSeriesHandlingConfiguration string

const (
	// Represents no/null value.
	ShortSeriesHandlingConfigurationNone = ShortSeriesHandlingConfiguration("None")
	// Short series will be padded if there are no long series, otherwise short series will be dropped.
	ShortSeriesHandlingConfigurationAuto = ShortSeriesHandlingConfiguration("Auto")
	// All the short series will be padded.
	ShortSeriesHandlingConfigurationPad = ShortSeriesHandlingConfiguration("Pad")
	// All the short series will be dropped.
	ShortSeriesHandlingConfigurationDrop = ShortSeriesHandlingConfiguration("Drop")
)

// This field is required to be implemented by the Resource Provider if the service has more than one tier, but is not required on a PUT.
type SkuTier string

const (
	SkuTierFree     = SkuTier("Free")
	SkuTierBasic    = SkuTier("Basic")
	SkuTierStandard = SkuTier("Standard")
	SkuTierPremium  = SkuTier("Premium")
)

func (SkuTier) ElementType() reflect.Type {
	return reflect.TypeOf((*SkuTier)(nil)).Elem()
}

func (e SkuTier) ToSkuTierOutput() SkuTierOutput {
	return pulumi.ToOutput(e).(SkuTierOutput)
}

func (e SkuTier) ToSkuTierOutputWithContext(ctx context.Context) SkuTierOutput {
	return pulumi.ToOutputWithContext(ctx, e).(SkuTierOutput)
}

func (e SkuTier) ToSkuTierPtrOutput() SkuTierPtrOutput {
	return e.ToSkuTierPtrOutputWithContext(context.Background())
}

func (e SkuTier) ToSkuTierPtrOutputWithContext(ctx context.Context) SkuTierPtrOutput {
	return SkuTier(e).ToSkuTierOutputWithContext(ctx).ToSkuTierPtrOutputWithContext(ctx)
}

func (e SkuTier) ToStringOutput() pulumi.StringOutput {
	return pulumi.ToOutput(pulumi.String(e)).(pulumi.StringOutput)
}

func (e SkuTier) ToStringOutputWithContext(ctx context.Context) pulumi.StringOutput {
	return pulumi.ToOutputWithContext(ctx, pulumi.String(e)).(pulumi.StringOutput)
}

func (e SkuTier) ToStringPtrOutput() pulumi.StringPtrOutput {
	return pulumi.String(e).ToStringPtrOutputWithContext(context.Background())
}

func (e SkuTier) ToStringPtrOutputWithContext(ctx context.Context) pulumi.StringPtrOutput {
	return pulumi.String(e).ToStringOutputWithContext(ctx).ToStringPtrOutputWithContext(ctx)
}

type SkuTierOutput struct{ *pulumi.OutputState }

func (SkuTierOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*SkuTier)(nil)).Elem()
}

func (o SkuTierOutput) ToSkuTierOutput() SkuTierOutput {
	return o
}

func (o SkuTierOutput) ToSkuTierOutputWithContext(ctx context.Context) SkuTierOutput {
	return o
}

func (o SkuTierOutput) ToSkuTierPtrOutput() SkuTierPtrOutput {
	return o.ToSkuTierPtrOutputWithContext(context.Background())
}

func (o SkuTierOutput) ToSkuTierPtrOutputWithContext(ctx context.Context) SkuTierPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v SkuTier) *SkuTier {
		return &v
	}).(SkuTierPtrOutput)
}

func (o SkuTierOutput) ToStringOutput() pulumi.StringOutput {
	return o.ToStringOutputWithContext(context.Background())
}

func (o SkuTierOutput) ToStringOutputWithContext(ctx context.Context) pulumi.StringOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, e SkuTier) string {
		return string(e)
	}).(pulumi.StringOutput)
}

func (o SkuTierOutput) ToStringPtrOutput() pulumi.StringPtrOutput {
	return o.ToStringPtrOutputWithContext(context.Background())
}

func (o SkuTierOutput) ToStringPtrOutputWithContext(ctx context.Context) pulumi.StringPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, e SkuTier) *string {
		v := string(e)
		return &v
	}).(pulumi.StringPtrOutput)
}

type SkuTierPtrOutput struct{ *pulumi.OutputState }

func (SkuTierPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**SkuTier)(nil)).Elem()
}

func (o SkuTierPtrOutput) ToSkuTierPtrOutput() SkuTierPtrOutput {
	return o
}

func (o SkuTierPtrOutput) ToSkuTierPtrOutputWithContext(ctx context.Context) SkuTierPtrOutput {
	return o
}

func (o SkuTierPtrOutput) Elem() SkuTierOutput {
	return o.ApplyT(func(v *SkuTier) SkuTier {
		if v != nil {
			return *v
		}
		var ret SkuTier
		return ret
	}).(SkuTierOutput)
}

func (o SkuTierPtrOutput) ToStringPtrOutput() pulumi.StringPtrOutput {
	return o.ToStringPtrOutputWithContext(context.Background())
}

func (o SkuTierPtrOutput) ToStringPtrOutputWithContext(ctx context.Context) pulumi.StringPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, e *SkuTier) *string {
		if e == nil {
			return nil
		}
		v := string(*e)
		return &v
	}).(pulumi.StringPtrOutput)
}

// SkuTierInput is an input type that accepts SkuTierArgs and SkuTierOutput values.
// You can construct a concrete instance of `SkuTierInput` via:
//
//	SkuTierArgs{...}
type SkuTierInput interface {
	pulumi.Input

	ToSkuTierOutput() SkuTierOutput
	ToSkuTierOutputWithContext(context.Context) SkuTierOutput
}

var skuTierPtrType = reflect.TypeOf((**SkuTier)(nil)).Elem()

type SkuTierPtrInput interface {
	pulumi.Input

	ToSkuTierPtrOutput() SkuTierPtrOutput
	ToSkuTierPtrOutputWithContext(context.Context) SkuTierPtrOutput
}

type skuTierPtr string

func SkuTierPtr(v string) SkuTierPtrInput {
	return (*skuTierPtr)(&v)
}

func (*skuTierPtr) ElementType() reflect.Type {
	return skuTierPtrType
}

func (in *skuTierPtr) ToSkuTierPtrOutput() SkuTierPtrOutput {
	return pulumi.ToOutput(in).(SkuTierPtrOutput)
}

func (in *skuTierPtr) ToSkuTierPtrOutputWithContext(ctx context.Context) SkuTierPtrOutput {
	return pulumi.ToOutputWithContext(ctx, in).(SkuTierPtrOutput)
}

// [Required] Type of the job's entry point.
type SparkJobEntryType string

const (
	SparkJobEntryTypeSparkJobPythonEntry = SparkJobEntryType("SparkJobPythonEntry")
	SparkJobEntryTypeSparkJobScalaEntry  = SparkJobEntryType("SparkJobScalaEntry")
)

// State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh port is closed on this instance. Enabled - Indicates that the public ssh port is open and accessible according to the VNet/subnet policy if applicable.
type SshPublicAccess string

const (
	SshPublicAccessEnabled  = SshPublicAccess("Enabled")
	SshPublicAccessDisabled = SshPublicAccess("Disabled")
)

// Enable or disable ssl for scoring
type SslConfigStatus string

const (
	SslConfigStatusDisabled = SslConfigStatus("Disabled")
	SslConfigStatusEnabled  = SslConfigStatus("Enabled")
	SslConfigStatusAuto     = SslConfigStatus("Auto")
)

// The meta-learner is a model trained on the output of the individual heterogeneous models.
type StackMetaLearnerType string

const (
	StackMetaLearnerTypeNone = StackMetaLearnerType("None")
	// Default meta-learners are LogisticRegression for classification tasks.
	StackMetaLearnerTypeLogisticRegression = StackMetaLearnerType("LogisticRegression")
	// Default meta-learners are LogisticRegression for classification task when CV is on.
	StackMetaLearnerTypeLogisticRegressionCV = StackMetaLearnerType("LogisticRegressionCV")
	StackMetaLearnerTypeLightGBMClassifier   = StackMetaLearnerType("LightGBMClassifier")
	// Default meta-learners are LogisticRegression for regression task.
	StackMetaLearnerTypeElasticNet = StackMetaLearnerType("ElasticNet")
	// Default meta-learners are LogisticRegression for regression task when CV is on.
	StackMetaLearnerTypeElasticNetCV      = StackMetaLearnerType("ElasticNetCV")
	StackMetaLearnerTypeLightGBMRegressor = StackMetaLearnerType("LightGBMRegressor")
	StackMetaLearnerTypeLinearRegression  = StackMetaLearnerType("LinearRegression")
)

// Type of optimizer.
type StochasticOptimizer string

const (
	// No optimizer selected.
	StochasticOptimizerNone = StochasticOptimizer("None")
	// Stochastic Gradient Descent optimizer.
	StochasticOptimizerSgd = StochasticOptimizer("Sgd")
	// Adam is algorithm the optimizes stochastic objective functions based on adaptive estimates of moments
	StochasticOptimizerAdam = StochasticOptimizer("Adam")
	// AdamW is a variant of the optimizer Adam that has an improved implementation of weight decay.
	StochasticOptimizerAdamw = StochasticOptimizer("Adamw")
)

// The function to be used to aggregate the time series target column to conform to a user specified frequency.
// If the TargetAggregateFunction is set i.e. not 'None', but the freq parameter is not set, the error is raised. The possible target aggregation functions are: "sum", "max", "min" and "mean".
type TargetAggregationFunction string

const (
	// Represent no value set.
	TargetAggregationFunctionNone = TargetAggregationFunction("None")
	TargetAggregationFunctionSum  = TargetAggregationFunction("Sum")
	TargetAggregationFunctionMax  = TargetAggregationFunction("Max")
	TargetAggregationFunctionMin  = TargetAggregationFunction("Min")
	TargetAggregationFunctionMean = TargetAggregationFunction("Mean")
)

// [Required] Set target lags mode - Auto/Custom
type TargetLagsMode string

const (
	// Target lags to be determined automatically.
	TargetLagsModeAuto = TargetLagsMode("Auto")
	// Use the custom target lags.
	TargetLagsModeCustom = TargetLagsMode("Custom")
)

// [Required] TargetRollingWindowSiz detection mode.
type TargetRollingWindowSizeMode string

const (
	// Determine rolling windows size automatically.
	TargetRollingWindowSizeModeAuto = TargetRollingWindowSizeMode("Auto")
	// Use the specified rolling window size.
	TargetRollingWindowSizeModeCustom = TargetRollingWindowSizeMode("Custom")
)

// [Required] Task type for AutoMLJob.
type TaskType string

const (
	// Classification in machine learning and statistics is a supervised learning approach in which
	// the computer program learns from the data given to it and make new observations or classifications.
	TaskTypeClassification = TaskType("Classification")
	// Regression means to predict the value using the input data. Regression models are used to predict a continuous value.
	TaskTypeRegression = TaskType("Regression")
	// Forecasting is a special kind of regression task that deals with time-series data and creates forecasting model
	// that can be used to predict the near future values based on the inputs.
	TaskTypeForecasting = TaskType("Forecasting")
	// Image Classification. Multi-class image classification is used when an image is classified with only a single label
	// from a set of classes - e.g. each image is classified as either an image of a 'cat' or a 'dog' or a 'duck'.
	TaskTypeImageClassification = TaskType("ImageClassification")
	// Image Classification Multilabel. Multi-label image classification is used when an image could have one or more labels
	// from a set of labels - e.g. an image could be labeled with both 'cat' and 'dog'.
	TaskTypeImageClassificationMultilabel = TaskType("ImageClassificationMultilabel")
	// Image Object Detection. Object detection is used to identify objects in an image and locate each object with a
	// bounding box e.g. locate all dogs and cats in an image and draw a bounding box around each.
	TaskTypeImageObjectDetection = TaskType("ImageObjectDetection")
	// Image Instance Segmentation. Instance segmentation is used to identify objects in an image at the pixel level,
	// drawing a polygon around each object in the image.
	TaskTypeImageInstanceSegmentation = TaskType("ImageInstanceSegmentation")
	// Text classification (also known as text tagging or text categorization) is the process of sorting texts into categories.
	// Categories are mutually exclusive.
	TaskTypeTextClassification = TaskType("TextClassification")
	// Multilabel classification task assigns each sample to a group (zero or more) of target labels.
	TaskTypeTextClassificationMultilabel = TaskType("TextClassificationMultilabel")
	// Text Named Entity Recognition a.k.a. TextNER.
	// Named Entity Recognition (NER) is the ability to take free-form text and identify the occurrences of entities such as people, locations, organizations, and more.
	TaskTypeTextNER = TaskType("TextNER")
)

// Annotation type of text labeling job.
type TextAnnotationType string

const (
	TextAnnotationTypeClassification         = TextAnnotationType("Classification")
	TextAnnotationTypeNamedEntityRecognition = TextAnnotationType("NamedEntityRecognition")
)

// [Required]
type TriggerType string

const (
	TriggerTypeRecurrence = TriggerType("Recurrence")
	TriggerTypeCron       = TriggerType("Cron")
)

// Configure STL Decomposition of the time-series target column.
type UseStl string

const (
	// No stl decomposition.
	UseStlNone        = UseStl("None")
	UseStlSeason      = UseStl("Season")
	UseStlSeasonTrend = UseStl("SeasonTrend")
)

// Metric computation method to use for validation metrics.
type ValidationMetricType string

const (
	// No metric.
	ValidationMetricTypeNone = ValidationMetricType("None")
	// Coco metric.
	ValidationMetricTypeCoco = ValidationMetricType("Coco")
	// Voc metric.
	ValidationMetricTypeVoc = ValidationMetricType("Voc")
	// CocoVoc metric.
	ValidationMetricTypeCocoVoc = ValidationMetricType("CocoVoc")
)

// format for the workspace connection value
type ValueFormat string

const (
	ValueFormatJSON = ValueFormat("JSON")
)

// Virtual Machine priority
type VmPriority string

const (
	VmPriorityDedicated   = VmPriority("Dedicated")
	VmPriorityLowPriority = VmPriority("LowPriority")
)

// Type of Volume Definition. Possible Values: bind,volume,tmpfs,npipe
type VolumeDefinitionType string

const (
	VolumeDefinitionTypeBind   = VolumeDefinitionType("bind")
	VolumeDefinitionTypeVolume = VolumeDefinitionType("volume")
	VolumeDefinitionTypeTmpfs  = VolumeDefinitionType("tmpfs")
	VolumeDefinitionTypeNpipe  = VolumeDefinitionType("npipe")
)

// Enum of weekday
type WeekDay string

const (
	// Monday weekday
	WeekDayMonday = WeekDay("Monday")
	// Tuesday weekday
	WeekDayTuesday = WeekDay("Tuesday")
	// Wednesday weekday
	WeekDayWednesday = WeekDay("Wednesday")
	// Thursday weekday
	WeekDayThursday = WeekDay("Thursday")
	// Friday weekday
	WeekDayFriday = WeekDay("Friday")
	// Saturday weekday
	WeekDaySaturday = WeekDay("Saturday")
	// Sunday weekday
	WeekDaySunday = WeekDay("Sunday")
)

func init() {
	pulumi.RegisterOutputType(SkuTierOutput{})
	pulumi.RegisterOutputType(SkuTierPtrOutput{})
}
