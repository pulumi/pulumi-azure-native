// *** WARNING: this file was generated by pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../types/input";
import * as outputs from "../../types/output";
import * as enums from "../../types/enums";
import * as utilities from "../../utilities";

/**
 * A Big Data pool
 *
 * @deprecated azure-native:synapse/v20210401preview:BigDataPool is being removed in the next major version of this provider. Upgrade to at least azure-native:synapse/v20210501:BigDataPool to guarantee forwards compatibility.
 */
export class BigDataPool extends pulumi.CustomResource {
    /**
     * Get an existing BigDataPool resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, opts?: pulumi.CustomResourceOptions): BigDataPool {
        pulumi.log.warn("BigDataPool is deprecated: azure-native:synapse/v20210401preview:BigDataPool is being removed in the next major version of this provider. Upgrade to at least azure-native:synapse/v20210501:BigDataPool to guarantee forwards compatibility.")
        return new BigDataPool(name, undefined as any, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'azure-native:synapse/v20210401preview:BigDataPool';

    /**
     * Returns true if the given object is an instance of BigDataPool.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is BigDataPool {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === BigDataPool.__pulumiType;
    }

    /**
     * Auto-pausing properties
     */
    public readonly autoPause!: pulumi.Output<outputs.synapse.v20210401preview.AutoPausePropertiesResponse | undefined>;
    /**
     * Auto-scaling properties
     */
    public readonly autoScale!: pulumi.Output<outputs.synapse.v20210401preview.AutoScalePropertiesResponse | undefined>;
    /**
     * The cache size
     */
    public readonly cacheSize!: pulumi.Output<number | undefined>;
    /**
     * The time when the Big Data pool was created.
     */
    public readonly creationDate!: pulumi.Output<string | undefined>;
    /**
     * List of custom libraries/packages associated with the spark pool.
     */
    public readonly customLibraries!: pulumi.Output<outputs.synapse.v20210401preview.LibraryInfoResponse[] | undefined>;
    /**
     * The default folder where Spark logs will be written.
     */
    public readonly defaultSparkLogFolder!: pulumi.Output<string | undefined>;
    /**
     * Dynamic Executor Allocation
     */
    public readonly dynamicExecutorAllocation!: pulumi.Output<outputs.synapse.v20210401preview.DynamicExecutorAllocationResponse | undefined>;
    /**
     * Whether compute isolation is required or not.
     */
    public readonly isComputeIsolationEnabled!: pulumi.Output<boolean | undefined>;
    /**
     * The time when the Big Data pool was updated successfully.
     */
    public /*out*/ readonly lastSucceededTimestamp!: pulumi.Output<string>;
    /**
     * Library version requirements
     */
    public readonly libraryRequirements!: pulumi.Output<outputs.synapse.v20210401preview.LibraryRequirementsResponse | undefined>;
    /**
     * The geo-location where the resource lives
     */
    public readonly location!: pulumi.Output<string>;
    /**
     * The name of the resource
     */
    public /*out*/ readonly name!: pulumi.Output<string>;
    /**
     * The number of nodes in the Big Data pool.
     */
    public readonly nodeCount!: pulumi.Output<number | undefined>;
    /**
     * The level of compute power that each node in the Big Data pool has.
     */
    public readonly nodeSize!: pulumi.Output<string | undefined>;
    /**
     * The kind of nodes that the Big Data pool provides.
     */
    public readonly nodeSizeFamily!: pulumi.Output<string | undefined>;
    /**
     * The state of the Big Data pool.
     */
    public readonly provisioningState!: pulumi.Output<string | undefined>;
    /**
     * Whether session level packages enabled.
     */
    public readonly sessionLevelPackagesEnabled!: pulumi.Output<boolean | undefined>;
    /**
     * Spark configuration file to specify additional properties
     */
    public readonly sparkConfigProperties!: pulumi.Output<outputs.synapse.v20210401preview.LibraryRequirementsResponse | undefined>;
    /**
     * The Spark events folder
     */
    public readonly sparkEventsFolder!: pulumi.Output<string | undefined>;
    /**
     * The Apache Spark version.
     */
    public readonly sparkVersion!: pulumi.Output<string | undefined>;
    /**
     * Resource tags.
     */
    public readonly tags!: pulumi.Output<{[key: string]: string} | undefined>;
    /**
     * The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
     */
    public /*out*/ readonly type!: pulumi.Output<string>;

    /**
     * Create a BigDataPool resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    /** @deprecated azure-native:synapse/v20210401preview:BigDataPool is being removed in the next major version of this provider. Upgrade to at least azure-native:synapse/v20210501:BigDataPool to guarantee forwards compatibility. */
    constructor(name: string, args: BigDataPoolArgs, opts?: pulumi.CustomResourceOptions) {
        pulumi.log.warn("BigDataPool is deprecated: azure-native:synapse/v20210401preview:BigDataPool is being removed in the next major version of this provider. Upgrade to at least azure-native:synapse/v20210501:BigDataPool to guarantee forwards compatibility.")
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (!opts.id) {
            if ((!args || args.resourceGroupName === undefined) && !opts.urn) {
                throw new Error("Missing required property 'resourceGroupName'");
            }
            if ((!args || args.workspaceName === undefined) && !opts.urn) {
                throw new Error("Missing required property 'workspaceName'");
            }
            resourceInputs["autoPause"] = args ? args.autoPause : undefined;
            resourceInputs["autoScale"] = args ? args.autoScale : undefined;
            resourceInputs["bigDataPoolName"] = args ? args.bigDataPoolName : undefined;
            resourceInputs["cacheSize"] = args ? args.cacheSize : undefined;
            resourceInputs["creationDate"] = args ? args.creationDate : undefined;
            resourceInputs["customLibraries"] = args ? args.customLibraries : undefined;
            resourceInputs["defaultSparkLogFolder"] = args ? args.defaultSparkLogFolder : undefined;
            resourceInputs["dynamicExecutorAllocation"] = args ? args.dynamicExecutorAllocation : undefined;
            resourceInputs["force"] = args ? args.force : undefined;
            resourceInputs["isComputeIsolationEnabled"] = args ? args.isComputeIsolationEnabled : undefined;
            resourceInputs["libraryRequirements"] = args ? args.libraryRequirements : undefined;
            resourceInputs["location"] = args ? args.location : undefined;
            resourceInputs["nodeCount"] = args ? args.nodeCount : undefined;
            resourceInputs["nodeSize"] = args ? args.nodeSize : undefined;
            resourceInputs["nodeSizeFamily"] = args ? args.nodeSizeFamily : undefined;
            resourceInputs["provisioningState"] = args ? args.provisioningState : undefined;
            resourceInputs["resourceGroupName"] = args ? args.resourceGroupName : undefined;
            resourceInputs["sessionLevelPackagesEnabled"] = args ? args.sessionLevelPackagesEnabled : undefined;
            resourceInputs["sparkConfigProperties"] = args ? args.sparkConfigProperties : undefined;
            resourceInputs["sparkEventsFolder"] = args ? args.sparkEventsFolder : undefined;
            resourceInputs["sparkVersion"] = args ? args.sparkVersion : undefined;
            resourceInputs["tags"] = args ? args.tags : undefined;
            resourceInputs["workspaceName"] = args ? args.workspaceName : undefined;
            resourceInputs["lastSucceededTimestamp"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["type"] = undefined /*out*/;
        } else {
            resourceInputs["autoPause"] = undefined /*out*/;
            resourceInputs["autoScale"] = undefined /*out*/;
            resourceInputs["cacheSize"] = undefined /*out*/;
            resourceInputs["creationDate"] = undefined /*out*/;
            resourceInputs["customLibraries"] = undefined /*out*/;
            resourceInputs["defaultSparkLogFolder"] = undefined /*out*/;
            resourceInputs["dynamicExecutorAllocation"] = undefined /*out*/;
            resourceInputs["isComputeIsolationEnabled"] = undefined /*out*/;
            resourceInputs["lastSucceededTimestamp"] = undefined /*out*/;
            resourceInputs["libraryRequirements"] = undefined /*out*/;
            resourceInputs["location"] = undefined /*out*/;
            resourceInputs["name"] = undefined /*out*/;
            resourceInputs["nodeCount"] = undefined /*out*/;
            resourceInputs["nodeSize"] = undefined /*out*/;
            resourceInputs["nodeSizeFamily"] = undefined /*out*/;
            resourceInputs["provisioningState"] = undefined /*out*/;
            resourceInputs["sessionLevelPackagesEnabled"] = undefined /*out*/;
            resourceInputs["sparkConfigProperties"] = undefined /*out*/;
            resourceInputs["sparkEventsFolder"] = undefined /*out*/;
            resourceInputs["sparkVersion"] = undefined /*out*/;
            resourceInputs["tags"] = undefined /*out*/;
            resourceInputs["type"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        const aliasOpts = { aliases: [{ type: "azure-native:synapse:BigDataPool" }, { type: "azure-native:synapse/v20190601preview:BigDataPool" }, { type: "azure-native:synapse/v20201201:BigDataPool" }, { type: "azure-native:synapse/v20210301:BigDataPool" }, { type: "azure-native:synapse/v20210501:BigDataPool" }, { type: "azure-native:synapse/v20210601:BigDataPool" }, { type: "azure-native:synapse/v20210601preview:BigDataPool" }] };
        opts = pulumi.mergeOptions(opts, aliasOpts);
        super(BigDataPool.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * The set of arguments for constructing a BigDataPool resource.
 */
export interface BigDataPoolArgs {
    /**
     * Auto-pausing properties
     */
    autoPause?: pulumi.Input<inputs.synapse.v20210401preview.AutoPausePropertiesArgs>;
    /**
     * Auto-scaling properties
     */
    autoScale?: pulumi.Input<inputs.synapse.v20210401preview.AutoScalePropertiesArgs>;
    /**
     * Big Data pool name
     */
    bigDataPoolName?: pulumi.Input<string>;
    /**
     * The cache size
     */
    cacheSize?: pulumi.Input<number>;
    /**
     * The time when the Big Data pool was created.
     */
    creationDate?: pulumi.Input<string>;
    /**
     * List of custom libraries/packages associated with the spark pool.
     */
    customLibraries?: pulumi.Input<pulumi.Input<inputs.synapse.v20210401preview.LibraryInfoArgs>[]>;
    /**
     * The default folder where Spark logs will be written.
     */
    defaultSparkLogFolder?: pulumi.Input<string>;
    /**
     * Dynamic Executor Allocation
     */
    dynamicExecutorAllocation?: pulumi.Input<inputs.synapse.v20210401preview.DynamicExecutorAllocationArgs>;
    /**
     * Whether to stop any running jobs in the Big Data pool
     */
    force?: pulumi.Input<boolean>;
    /**
     * Whether compute isolation is required or not.
     */
    isComputeIsolationEnabled?: pulumi.Input<boolean>;
    /**
     * Library version requirements
     */
    libraryRequirements?: pulumi.Input<inputs.synapse.v20210401preview.LibraryRequirementsArgs>;
    /**
     * The geo-location where the resource lives
     */
    location?: pulumi.Input<string>;
    /**
     * The number of nodes in the Big Data pool.
     */
    nodeCount?: pulumi.Input<number>;
    /**
     * The level of compute power that each node in the Big Data pool has.
     */
    nodeSize?: pulumi.Input<string | enums.synapse.v20210401preview.NodeSize>;
    /**
     * The kind of nodes that the Big Data pool provides.
     */
    nodeSizeFamily?: pulumi.Input<string | enums.synapse.v20210401preview.NodeSizeFamily>;
    /**
     * The state of the Big Data pool.
     */
    provisioningState?: pulumi.Input<string>;
    /**
     * The name of the resource group. The name is case insensitive.
     */
    resourceGroupName: pulumi.Input<string>;
    /**
     * Whether session level packages enabled.
     */
    sessionLevelPackagesEnabled?: pulumi.Input<boolean>;
    /**
     * Spark configuration file to specify additional properties
     */
    sparkConfigProperties?: pulumi.Input<inputs.synapse.v20210401preview.LibraryRequirementsArgs>;
    /**
     * The Spark events folder
     */
    sparkEventsFolder?: pulumi.Input<string>;
    /**
     * The Apache Spark version.
     */
    sparkVersion?: pulumi.Input<string>;
    /**
     * Resource tags.
     */
    tags?: pulumi.Input<{[key: string]: pulumi.Input<string>}>;
    /**
     * The name of the workspace
     */
    workspaceName: pulumi.Input<string>;
}
