// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../../types/input";
import * as outputs from "../../../types/output";
import * as enums from "../../../types/enums";
import * as utilities from "../../../utilities";

/**
 * A Machine Learning compute based on AKS.
 */
export interface AKSResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'AKS'.
     */
    computeType: "AKS";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * AKS properties
     */
    properties?: outputs.machinelearningservices.v20220501.AKSSchemaResponseProperties;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}
/**
 * aksresponseProvideDefaults sets the appropriate defaults for AKSResponse
 */
export function aksresponseProvideDefaults(val: AKSResponse): AKSResponse {
    return {
        ...val,
        properties: (val.properties ? outputs.machinelearningservices.v20220501.aksschemaResponsePropertiesProvideDefaults(val.properties) : undefined),
    };
}

/**
 * AKS properties
 */
export interface AKSSchemaResponseProperties {
    /**
     * Number of agents
     */
    agentCount?: number;
    /**
     * Agent virtual machine size
     */
    agentVmSize?: string;
    /**
     * AKS networking configuration for vnet
     */
    aksNetworkingConfiguration?: outputs.machinelearningservices.v20220501.AksNetworkingConfigurationResponse;
    /**
     * Cluster full qualified domain name
     */
    clusterFqdn?: string;
    /**
     * Intended usage of the cluster
     */
    clusterPurpose?: string;
    /**
     * Load Balancer Subnet
     */
    loadBalancerSubnet?: string;
    /**
     * Load Balancer Type
     */
    loadBalancerType?: string;
    /**
     * SSL configuration
     */
    sslConfiguration?: outputs.machinelearningservices.v20220501.SslConfigurationResponse;
    /**
     * System services
     */
    systemServices: outputs.machinelearningservices.v20220501.SystemServiceResponse[];
}
/**
 * aksschemaResponsePropertiesProvideDefaults sets the appropriate defaults for AKSSchemaResponseProperties
 */
export function aksschemaResponsePropertiesProvideDefaults(val: AKSSchemaResponseProperties): AKSSchemaResponseProperties {
    return {
        ...val,
        clusterPurpose: (val.clusterPurpose) ?? "FastProd",
        loadBalancerType: (val.loadBalancerType) ?? "PublicIp",
    };
}

/**
 * Account key datastore credentials configuration.
 */
export interface AccountKeyDatastoreCredentialsResponse {
    /**
     * Enum to determine the datastore credentials type.
     * Expected value is 'AccountKey'.
     */
    credentialsType: "AccountKey";
}

/**
 * Advance configuration for AKS networking
 */
export interface AksNetworkingConfigurationResponse {
    /**
     * An IP address assigned to the Kubernetes DNS service. It must be within the Kubernetes service address range specified in serviceCidr.
     */
    dnsServiceIP?: string;
    /**
     * A CIDR notation IP range assigned to the Docker bridge network. It must not overlap with any Subnet IP ranges or the Kubernetes service address range.
     */
    dockerBridgeCidr?: string;
    /**
     * A CIDR notation IP range from which to assign service cluster IPs. It must not overlap with any Subnet IP ranges.
     */
    serviceCidr?: string;
    /**
     * Virtual network subnet resource ID the compute nodes belong to
     */
    subnetId?: string;
}

/**
 * Compute node information related to a AmlCompute.
 */
export interface AmlComputeNodeInformationResponse {
    /**
     * ID of the compute node.
     */
    nodeId: string;
    /**
     * State of the compute node. Values are idle, running, preparing, unusable, leaving and preempted.
     */
    nodeState: string;
    /**
     * SSH port number of the node.
     */
    port: number;
    /**
     * Private IP address of the compute node.
     */
    privateIpAddress: string;
    /**
     * Public IP address of the compute node.
     */
    publicIpAddress: string;
    /**
     * ID of the Experiment running on the node, if any else null.
     */
    runId: string;
}

/**
 * AML Compute properties
 */
export interface AmlComputePropertiesResponse {
    /**
     * Allocation state of the compute. Possible values are: steady - Indicates that the compute is not resizing. There are no changes to the number of compute nodes in the compute in progress. A compute enters this state when it is created and when no operations are being performed on the compute to change the number of compute nodes. resizing - Indicates that the compute is resizing; that is, compute nodes are being added to or removed from the compute.
     */
    allocationState: string;
    /**
     * The time at which the compute entered its current allocation state.
     */
    allocationStateTransitionTime: string;
    /**
     * The number of compute nodes currently assigned to the compute.
     */
    currentNodeCount: number;
    /**
     * Enable or disable node public IP address provisioning. Possible values are: Possible values are: true - Indicates that the compute nodes will have public IPs provisioned. false - Indicates that the compute nodes will have a private endpoint and no public IPs.
     */
    enableNodePublicIp?: boolean;
    /**
     * Collection of errors encountered by various compute nodes during node setup.
     */
    errors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * Network is isolated or not
     */
    isolatedNetwork?: boolean;
    /**
     * Counts of various node states on the compute.
     */
    nodeStateCounts: outputs.machinelearningservices.v20220501.NodeStateCountsResponse;
    /**
     * Compute OS Type
     */
    osType?: string;
    /**
     * A property bag containing additional properties.
     */
    propertyBag?: any;
    /**
     * State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh port is closed on all nodes of the cluster. Enabled - Indicates that the public ssh port is open on all nodes of the cluster. NotSpecified - Indicates that the public ssh port is closed on all nodes of the cluster if VNet is defined, else is open all public nodes. It can be default only during cluster creation time, after creation it will be either enabled or disabled.
     */
    remoteLoginPortPublicAccess?: string;
    /**
     * Scale settings for AML Compute
     */
    scaleSettings?: outputs.machinelearningservices.v20220501.ScaleSettingsResponse;
    /**
     * Virtual network subnet resource ID the compute nodes belong to.
     */
    subnet?: outputs.machinelearningservices.v20220501.ResourceIdResponse;
    /**
     * The target number of compute nodes for the compute. If the allocationState is resizing, this property denotes the target node count for the ongoing resize operation. If the allocationState is steady, this property denotes the target node count for the previous resize operation.
     */
    targetNodeCount: number;
    /**
     * Credentials for an administrator user account that will be created on each compute node.
     */
    userAccountCredentials?: outputs.machinelearningservices.v20220501.UserAccountCredentialsResponse;
    /**
     * Virtual Machine image for AML Compute - windows only
     */
    virtualMachineImage?: outputs.machinelearningservices.v20220501.VirtualMachineImageResponse;
    /**
     * Virtual Machine priority
     */
    vmPriority?: string;
    /**
     * Virtual Machine Size
     */
    vmSize?: string;
}
/**
 * amlComputePropertiesResponseProvideDefaults sets the appropriate defaults for AmlComputePropertiesResponse
 */
export function amlComputePropertiesResponseProvideDefaults(val: AmlComputePropertiesResponse): AmlComputePropertiesResponse {
    return {
        ...val,
        enableNodePublicIp: (val.enableNodePublicIp) ?? true,
        osType: (val.osType) ?? "Linux",
        remoteLoginPortPublicAccess: (val.remoteLoginPortPublicAccess) ?? "NotSpecified",
        scaleSettings: (val.scaleSettings ? outputs.machinelearningservices.v20220501.scaleSettingsResponseProvideDefaults(val.scaleSettings) : undefined),
    };
}

/**
 * An Azure Machine Learning compute.
 */
export interface AmlComputeResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'AmlCompute'.
     */
    computeType: "AmlCompute";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * Properties of AmlCompute
     */
    properties?: outputs.machinelearningservices.v20220501.AmlComputePropertiesResponse;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}
/**
 * amlComputeResponseProvideDefaults sets the appropriate defaults for AmlComputeResponse
 */
export function amlComputeResponseProvideDefaults(val: AmlComputeResponse): AmlComputeResponse {
    return {
        ...val,
        properties: (val.properties ? outputs.machinelearningservices.v20220501.amlComputePropertiesResponseProvideDefaults(val.properties) : undefined),
    };
}

/**
 * AML Token identity configuration.
 */
export interface AmlTokenResponse {
    /**
     * Enum to determine identity framework.
     * Expected value is 'AMLToken'.
     */
    identityType: "AMLToken";
}

/**
 * A user that can be assigned to a compute instance.
 */
export interface AssignedUserResponse {
    /**
     * User’s AAD Object Id.
     */
    objectId: string;
    /**
     * User’s AAD Tenant Id.
     */
    tenantId: string;
}

/**
 * Auto pause properties
 */
export interface AutoPausePropertiesResponse {
    delayInMinutes?: number;
    enabled?: boolean;
}

/**
 * Auto scale properties
 */
export interface AutoScalePropertiesResponse {
    enabled?: boolean;
    maxNodeCount?: number;
    minNodeCount?: number;
}

/**
 * Azure Blob datastore configuration.
 */
export interface AzureBlobDatastoreResponse {
    /**
     * Storage account name.
     */
    accountName?: string;
    /**
     * Storage account container name.
     */
    containerName?: string;
    /**
     * [Required] Account credentials.
     */
    credentials: outputs.machinelearningservices.v20220501.AccountKeyDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.CertificateDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.NoneDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.SasDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.ServicePrincipalDatastoreCredentialsResponse;
    /**
     * Enum to determine the datastore contents type.
     * Expected value is 'AzureBlob'.
     */
    datastoreType: "AzureBlob";
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Azure cloud endpoint for the storage account.
     */
    endpoint?: string;
    /**
     * Readonly property to indicate if datastore is the workspace default datastore
     */
    isDefault: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Protocol used to communicate with the storage account.
     */
    protocol?: string;
    /**
     * Indicates which identity to use to authenticate service data access to customer's storage.
     */
    serviceDataAccessAuthIdentity?: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * azureBlobDatastoreResponseProvideDefaults sets the appropriate defaults for AzureBlobDatastoreResponse
 */
export function azureBlobDatastoreResponseProvideDefaults(val: AzureBlobDatastoreResponse): AzureBlobDatastoreResponse {
    return {
        ...val,
        serviceDataAccessAuthIdentity: (val.serviceDataAccessAuthIdentity) ?? "None",
    };
}

/**
 * Azure Data Lake Gen1 datastore configuration.
 */
export interface AzureDataLakeGen1DatastoreResponse {
    /**
     * [Required] Account credentials.
     */
    credentials: outputs.machinelearningservices.v20220501.AccountKeyDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.CertificateDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.NoneDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.SasDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.ServicePrincipalDatastoreCredentialsResponse;
    /**
     * Enum to determine the datastore contents type.
     * Expected value is 'AzureDataLakeGen1'.
     */
    datastoreType: "AzureDataLakeGen1";
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Readonly property to indicate if datastore is the workspace default datastore
     */
    isDefault: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Indicates which identity to use to authenticate service data access to customer's storage.
     */
    serviceDataAccessAuthIdentity?: string;
    /**
     * [Required] Azure Data Lake store name.
     */
    storeName: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * azureDataLakeGen1DatastoreResponseProvideDefaults sets the appropriate defaults for AzureDataLakeGen1DatastoreResponse
 */
export function azureDataLakeGen1DatastoreResponseProvideDefaults(val: AzureDataLakeGen1DatastoreResponse): AzureDataLakeGen1DatastoreResponse {
    return {
        ...val,
        serviceDataAccessAuthIdentity: (val.serviceDataAccessAuthIdentity) ?? "None",
    };
}

/**
 * Azure Data Lake Gen2 datastore configuration.
 */
export interface AzureDataLakeGen2DatastoreResponse {
    /**
     * [Required] Storage account name.
     */
    accountName: string;
    /**
     * [Required] Account credentials.
     */
    credentials: outputs.machinelearningservices.v20220501.AccountKeyDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.CertificateDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.NoneDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.SasDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.ServicePrincipalDatastoreCredentialsResponse;
    /**
     * Enum to determine the datastore contents type.
     * Expected value is 'AzureDataLakeGen2'.
     */
    datastoreType: "AzureDataLakeGen2";
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Azure cloud endpoint for the storage account.
     */
    endpoint?: string;
    /**
     * [Required] The name of the Data Lake Gen2 filesystem.
     */
    filesystem: string;
    /**
     * Readonly property to indicate if datastore is the workspace default datastore
     */
    isDefault: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Protocol used to communicate with the storage account.
     */
    protocol?: string;
    /**
     * Indicates which identity to use to authenticate service data access to customer's storage.
     */
    serviceDataAccessAuthIdentity?: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * azureDataLakeGen2DatastoreResponseProvideDefaults sets the appropriate defaults for AzureDataLakeGen2DatastoreResponse
 */
export function azureDataLakeGen2DatastoreResponseProvideDefaults(val: AzureDataLakeGen2DatastoreResponse): AzureDataLakeGen2DatastoreResponse {
    return {
        ...val,
        serviceDataAccessAuthIdentity: (val.serviceDataAccessAuthIdentity) ?? "None",
    };
}

/**
 * Azure File datastore configuration.
 */
export interface AzureFileDatastoreResponse {
    /**
     * [Required] Storage account name.
     */
    accountName: string;
    /**
     * [Required] Account credentials.
     */
    credentials: outputs.machinelearningservices.v20220501.AccountKeyDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.CertificateDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.NoneDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.SasDatastoreCredentialsResponse | outputs.machinelearningservices.v20220501.ServicePrincipalDatastoreCredentialsResponse;
    /**
     * Enum to determine the datastore contents type.
     * Expected value is 'AzureFile'.
     */
    datastoreType: "AzureFile";
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Azure cloud endpoint for the storage account.
     */
    endpoint?: string;
    /**
     * [Required] The name of the Azure file share that the datastore points to.
     */
    fileShareName: string;
    /**
     * Readonly property to indicate if datastore is the workspace default datastore
     */
    isDefault: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Protocol used to communicate with the storage account.
     */
    protocol?: string;
    /**
     * Indicates which identity to use to authenticate service data access to customer's storage.
     */
    serviceDataAccessAuthIdentity?: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * azureFileDatastoreResponseProvideDefaults sets the appropriate defaults for AzureFileDatastoreResponse
 */
export function azureFileDatastoreResponseProvideDefaults(val: AzureFileDatastoreResponse): AzureFileDatastoreResponse {
    return {
        ...val,
        serviceDataAccessAuthIdentity: (val.serviceDataAccessAuthIdentity) ?? "None",
    };
}

/**
 * Defines an early termination policy based on slack criteria, and a frequency and delay interval for evaluation
 */
export interface BanditPolicyResponse {
    /**
     * Number of intervals by which to delay the first evaluation.
     */
    delayEvaluation?: number;
    /**
     * Interval (number of runs) between policy evaluations.
     */
    evaluationInterval?: number;
    /**
     *
     * Expected value is 'Bandit'.
     */
    policyType: "Bandit";
    /**
     * Absolute distance allowed from the best performing run.
     */
    slackAmount?: number;
    /**
     * Ratio of the allowed distance from the best performing run.
     */
    slackFactor?: number;
}
/**
 * banditPolicyResponseProvideDefaults sets the appropriate defaults for BanditPolicyResponse
 */
export function banditPolicyResponseProvideDefaults(val: BanditPolicyResponse): BanditPolicyResponse {
    return {
        ...val,
        delayEvaluation: (val.delayEvaluation) ?? 0,
        evaluationInterval: (val.evaluationInterval) ?? 0,
        slackAmount: (val.slackAmount) ?? 0,
        slackFactor: (val.slackFactor) ?? 0,
    };
}

/**
 * Batch inference settings per deployment.
 */
export interface BatchDeploymentResponse {
    /**
     * Code configuration for the endpoint deployment.
     */
    codeConfiguration?: outputs.machinelearningservices.v20220501.CodeConfigurationResponse;
    /**
     * Compute target for batch inference operation.
     */
    compute?: string;
    /**
     * Description of the endpoint deployment.
     */
    description?: string;
    /**
     * ARM resource ID or AssetId of the environment specification for the endpoint deployment.
     */
    environmentId?: string;
    /**
     * Environment variables configuration for the deployment.
     */
    environmentVariables?: {[key: string]: string};
    /**
     * Error threshold, if the error count for the entire input goes above this value,
     * the batch inference will be aborted. Range is [-1, int.MaxValue].
     * For FileDataset, this value is the count of file failures.
     * For TabularDataset, this value is the count of record failures.
     * If set to -1 (the lower bound), all failures during batch inference will be ignored.
     */
    errorThreshold?: number;
    /**
     * Logging level for batch inference operation.
     */
    loggingLevel?: string;
    /**
     * Indicates maximum number of parallelism per instance.
     */
    maxConcurrencyPerInstance?: number;
    /**
     * Size of the mini-batch passed to each batch invocation.
     * For FileDataset, this is the number of files per mini-batch.
     * For TabularDataset, this is the size of the records in bytes, per mini-batch.
     */
    miniBatchSize?: number;
    /**
     * Reference to the model asset for the endpoint deployment.
     */
    model?: outputs.machinelearningservices.v20220501.DataPathAssetReferenceResponse | outputs.machinelearningservices.v20220501.IdAssetReferenceResponse | outputs.machinelearningservices.v20220501.OutputPathAssetReferenceResponse;
    /**
     * Indicates how the output will be organized.
     */
    outputAction?: string;
    /**
     * Customized output file name for append_row output action.
     */
    outputFileName?: string;
    /**
     * Property dictionary. Properties can be added, but not removed or altered.
     */
    properties?: {[key: string]: string};
    /**
     * Provisioning state for the endpoint deployment.
     */
    provisioningState: string;
    /**
     * Indicates compute configuration for the job.
     * If not provided, will default to the defaults defined in ResourceConfiguration.
     */
    resources?: outputs.machinelearningservices.v20220501.ResourceConfigurationResponse;
    /**
     * Retry Settings for the batch inference operation.
     * If not provided, will default to the defaults defined in BatchRetrySettings.
     */
    retrySettings?: outputs.machinelearningservices.v20220501.BatchRetrySettingsResponse;
}
/**
 * batchDeploymentResponseProvideDefaults sets the appropriate defaults for BatchDeploymentResponse
 */
export function batchDeploymentResponseProvideDefaults(val: BatchDeploymentResponse): BatchDeploymentResponse {
    return {
        ...val,
        errorThreshold: (val.errorThreshold) ?? -1,
        loggingLevel: (val.loggingLevel) ?? "Info",
        maxConcurrencyPerInstance: (val.maxConcurrencyPerInstance) ?? 1,
        miniBatchSize: (val.miniBatchSize) ?? 10,
        outputAction: (val.outputAction) ?? "AppendRow",
        outputFileName: (val.outputFileName) ?? "predictions.csv",
        resources: (val.resources ? outputs.machinelearningservices.v20220501.resourceConfigurationResponseProvideDefaults(val.resources) : undefined),
        retrySettings: (val.retrySettings ? outputs.machinelearningservices.v20220501.batchRetrySettingsResponseProvideDefaults(val.retrySettings) : undefined),
    };
}

/**
 * Batch endpoint default values
 */
export interface BatchEndpointDefaultsResponse {
    /**
     * Name of the deployment that will be default for the endpoint.
     * This deployment will end up getting 100% traffic when the endpoint scoring URL is invoked.
     */
    deploymentName?: string;
}

/**
 * Batch endpoint configuration.
 */
export interface BatchEndpointResponse {
    /**
     * [Required] Use 'Key' for key based authentication and 'AMLToken' for Azure Machine Learning token-based authentication. 'Key' doesn't expire but 'AMLToken' does.
     */
    authMode: string;
    /**
     * Default values for Batch Endpoint
     */
    defaults?: outputs.machinelearningservices.v20220501.BatchEndpointDefaultsResponse;
    /**
     * Description of the inference endpoint.
     */
    description?: string;
    /**
     * Property dictionary. Properties can be added, but not removed or altered.
     */
    properties?: {[key: string]: string};
    /**
     * Provisioning state for the endpoint.
     */
    provisioningState: string;
    /**
     * Endpoint URI.
     */
    scoringUri: string;
    /**
     * Endpoint Swagger URI.
     */
    swaggerUri: string;
}

/**
 * Retry settings for a batch inference operation.
 */
export interface BatchRetrySettingsResponse {
    /**
     * Maximum retry count for a mini-batch
     */
    maxRetries?: number;
    /**
     * Invocation timeout for a mini-batch, in ISO 8601 format.
     */
    timeout?: string;
}
/**
 * batchRetrySettingsResponseProvideDefaults sets the appropriate defaults for BatchRetrySettingsResponse
 */
export function batchRetrySettingsResponseProvideDefaults(val: BatchRetrySettingsResponse): BatchRetrySettingsResponse {
    return {
        ...val,
        maxRetries: (val.maxRetries) ?? 3,
        timeout: (val.timeout) ?? "PT30S",
    };
}

/**
 * Defines a Sampling Algorithm that generates values based on previous values
 */
export interface BayesianSamplingAlgorithmResponse {
    /**
     *
     * Expected value is 'Bayesian'.
     */
    samplingAlgorithmType: "Bayesian";
}

/**
 * Configuration settings for Docker build context
 */
export interface BuildContextResponse {
    /**
     * [Required] URI of the Docker build context used to build the image. Supports blob URIs on environment creation and may return blob or Git URIs.
     * <seealso href="https://docs.docker.com/engine/reference/commandline/build/#extended-description" />
     */
    contextUri: string;
    /**
     * Path to the Dockerfile in the build context.
     * <seealso href="https://docs.docker.com/engine/reference/builder/" />
     */
    dockerfilePath?: string;
}
/**
 * buildContextResponseProvideDefaults sets the appropriate defaults for BuildContextResponse
 */
export function buildContextResponseProvideDefaults(val: BuildContextResponse): BuildContextResponse {
    return {
        ...val,
        dockerfilePath: (val.dockerfilePath) ?? "Dockerfile",
    };
}

/**
 * Certificate datastore credentials configuration.
 */
export interface CertificateDatastoreCredentialsResponse {
    /**
     * Authority URL used for authentication.
     */
    authorityUrl?: string;
    /**
     * [Required] Service principal client ID.
     */
    clientId: string;
    /**
     * Enum to determine the datastore credentials type.
     * Expected value is 'Certificate'.
     */
    credentialsType: "Certificate";
    /**
     * Resource the service principal has access to.
     */
    resourceUrl?: string;
    /**
     * [Required] ID of the tenant to which the service principal belongs.
     */
    tenantId: string;
    /**
     * [Required] Thumbprint of the certificate used for authentication.
     */
    thumbprint: string;
}

/**
 * Configuration for a scoring code asset.
 */
export interface CodeConfigurationResponse {
    /**
     * ARM resource ID of the code asset.
     */
    codeId?: string;
    /**
     * [Required] The script to execute on startup. eg. "score.py"
     */
    scoringScript: string;
}

/**
 * Container for code asset versions.
 */
export interface CodeContainerResponse {
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The latest version inside this container.
     */
    latestVersion: string;
    /**
     * The next auto incremental version
     */
    nextVersion: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * codeContainerResponseProvideDefaults sets the appropriate defaults for CodeContainerResponse
 */
export function codeContainerResponseProvideDefaults(val: CodeContainerResponse): CodeContainerResponse {
    return {
        ...val,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Code asset version details.
 */
export interface CodeVersionResponse {
    /**
     * Uri where code is located
     */
    codeUri?: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * codeVersionResponseProvideDefaults sets the appropriate defaults for CodeVersionResponse
 */
export function codeVersionResponseProvideDefaults(val: CodeVersionResponse): CodeVersionResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Command Job limit class.
 */
export interface CommandJobLimitsResponse {
    /**
     *
     * Expected value is 'Command'.
     */
    jobLimitsType: "Command";
    /**
     * The max run duration in ISO 8601 format, after which the job will be cancelled. Only supports duration with precision as low as Seconds.
     */
    timeout?: string;
}

/**
 * Command job definition.
 */
export interface CommandJobResponse {
    /**
     * ARM resource ID of the code asset.
     */
    codeId?: string;
    /**
     * [Required] The command to execute on startup of the job. eg. "python train.py"
     */
    command: string;
    /**
     * ARM resource ID of the compute resource.
     */
    computeId?: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Display name of job.
     */
    displayName?: string;
    /**
     * Distribution configuration of the job. If set, this should be one of Mpi, Tensorflow, PyTorch, or null.
     */
    distribution?: outputs.machinelearningservices.v20220501.MpiResponse | outputs.machinelearningservices.v20220501.PyTorchResponse | outputs.machinelearningservices.v20220501.TensorFlowResponse;
    /**
     * [Required] The ARM resource ID of the Environment specification for the job.
     */
    environmentId: string;
    /**
     * Environment variables included in the job.
     */
    environmentVariables?: {[key: string]: string};
    /**
     * The name of the experiment the job belongs to. If not set, the job is placed in the "Default" experiment.
     */
    experimentName?: string;
    /**
     * Identity configuration. If set, this should be one of AmlToken, ManagedIdentity, UserIdentity or null.
     * Defaults to AmlToken if null.
     */
    identity?: outputs.machinelearningservices.v20220501.AmlTokenResponse | outputs.machinelearningservices.v20220501.ManagedIdentityResponse | outputs.machinelearningservices.v20220501.UserIdentityResponse;
    /**
     * Mapping of input data bindings used in the job.
     */
    inputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobInputResponse | outputs.machinelearningservices.v20220501.LiteralJobInputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobInputResponse | outputs.machinelearningservices.v20220501.MLTableJobInputResponse | outputs.machinelearningservices.v20220501.TritonModelJobInputResponse | outputs.machinelearningservices.v20220501.UriFileJobInputResponse | outputs.machinelearningservices.v20220501.UriFolderJobInputResponse};
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * Enum to determine the type of job.
     * Expected value is 'Command'.
     */
    jobType: "Command";
    /**
     * Command Job limit.
     */
    limits?: outputs.machinelearningservices.v20220501.CommandJobLimitsResponse;
    /**
     * Mapping of output data bindings used in the job.
     */
    outputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLTableJobOutputResponse | outputs.machinelearningservices.v20220501.TritonModelJobOutputResponse | outputs.machinelearningservices.v20220501.UriFileJobOutputResponse | outputs.machinelearningservices.v20220501.UriFolderJobOutputResponse};
    /**
     * Input parameters.
     */
    parameters: any;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Compute Resource configuration for the job.
     */
    resources?: outputs.machinelearningservices.v20220501.ResourceConfigurationResponse;
    /**
     * List of JobEndpoints.
     * For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
     */
    services?: {[key: string]: outputs.machinelearningservices.v20220501.JobServiceResponse};
    /**
     * Status of the job.
     */
    status: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * commandJobResponseProvideDefaults sets the appropriate defaults for CommandJobResponse
 */
export function commandJobResponseProvideDefaults(val: CommandJobResponse): CommandJobResponse {
    return {
        ...val,
        experimentName: (val.experimentName) ?? "Default",
        isArchived: (val.isArchived) ?? false,
        resources: (val.resources ? outputs.machinelearningservices.v20220501.resourceConfigurationResponseProvideDefaults(val.resources) : undefined),
    };
}

/**
 * Component container definition.
 * <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />
 */
export interface ComponentContainerResponse {
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The latest version inside this container.
     */
    latestVersion: string;
    /**
     * The next auto incremental version
     */
    nextVersion: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * componentContainerResponseProvideDefaults sets the appropriate defaults for ComponentContainerResponse
 */
export function componentContainerResponseProvideDefaults(val: ComponentContainerResponse): ComponentContainerResponse {
    return {
        ...val,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Definition of a component version: defines resources that span component types.
 */
export interface ComponentVersionResponse {
    /**
     * Defines Component definition details.
     * <see href="https://docs.microsoft.com/en-us/azure/machine-learning/reference-yaml-component-command" />
     */
    componentSpec?: any;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * componentVersionResponseProvideDefaults sets the appropriate defaults for ComponentVersionResponse
 */
export function componentVersionResponseProvideDefaults(val: ComponentVersionResponse): ComponentVersionResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Defines an Aml Instance application and its connectivity endpoint URI.
 */
export interface ComputeInstanceApplicationResponse {
    /**
     * Name of the ComputeInstance application.
     */
    displayName?: string;
    /**
     * Application' endpoint URI.
     */
    endpointUri?: string;
}

/**
 * Defines all connectivity endpoints and properties for an ComputeInstance.
 */
export interface ComputeInstanceConnectivityEndpointsResponse {
    /**
     * Private IP Address of this ComputeInstance (local to the VNET in which the compute instance is deployed).
     */
    privateIpAddress: string;
    /**
     * Public IP Address of this ComputeInstance.
     */
    publicIpAddress: string;
}

/**
 * Defines an Aml Instance container.
 */
export interface ComputeInstanceContainerResponse {
    /**
     * Auto save settings.
     */
    autosave?: string;
    /**
     * Environment information of this container.
     */
    environment?: outputs.machinelearningservices.v20220501.ComputeInstanceEnvironmentInfoResponse;
    /**
     * Information of GPU.
     */
    gpu?: string;
    /**
     * Name of the ComputeInstance container.
     */
    name?: string;
    /**
     * network of this container.
     */
    network?: string;
    /**
     * services of this containers.
     */
    services: any[];
}

/**
 * Describes information on user who created this ComputeInstance.
 */
export interface ComputeInstanceCreatedByResponse {
    /**
     * Uniquely identifies the user within his/her organization.
     */
    userId: string;
    /**
     * Name of the user.
     */
    userName: string;
    /**
     * Uniquely identifies user' Azure Active Directory organization.
     */
    userOrgId: string;
}

/**
 * Defines an Aml Instance DataDisk.
 */
export interface ComputeInstanceDataDiskResponse {
    /**
     * Caching type of Data Disk.
     */
    caching?: string;
    /**
     * The initial disk size in gigabytes.
     */
    diskSizeGB?: number;
    /**
     * The lun is used to uniquely identify each data disk. If attaching multiple disks, each should have a distinct lun.
     */
    lun?: number;
    /**
     * type of this storage account.
     */
    storageAccountType?: string;
}
/**
 * computeInstanceDataDiskResponseProvideDefaults sets the appropriate defaults for ComputeInstanceDataDiskResponse
 */
export function computeInstanceDataDiskResponseProvideDefaults(val: ComputeInstanceDataDiskResponse): ComputeInstanceDataDiskResponse {
    return {
        ...val,
        storageAccountType: (val.storageAccountType) ?? "Standard_LRS",
    };
}

/**
 * Defines an Aml Instance DataMount.
 */
export interface ComputeInstanceDataMountResponse {
    /**
     * who this data mount created by.
     */
    createdBy?: string;
    /**
     * Error of this data mount.
     */
    error?: string;
    /**
     * Mount Action.
     */
    mountAction?: string;
    /**
     * name of the ComputeInstance data mount.
     */
    mountName?: string;
    /**
     * Path of this data mount.
     */
    mountPath?: string;
    /**
     * Mount state.
     */
    mountState?: string;
    /**
     * The time when the disk mounted.
     */
    mountedOn?: string;
    /**
     * Source of the ComputeInstance data mount.
     */
    source?: string;
    /**
     * Data source type.
     */
    sourceType?: string;
}

/**
 * Environment information
 */
export interface ComputeInstanceEnvironmentInfoResponse {
    /**
     * name of environment.
     */
    name?: string;
    /**
     * version of environment.
     */
    version?: string;
}

/**
 * The last operation on ComputeInstance.
 */
export interface ComputeInstanceLastOperationResponse {
    /**
     * Name of the last operation.
     */
    operationName?: string;
    /**
     * Operation status.
     */
    operationStatus?: string;
    /**
     * Time of the last operation.
     */
    operationTime?: string;
    /**
     * Trigger of operation.
     */
    operationTrigger?: string;
}

/**
 * Compute Instance properties
 */
export interface ComputeInstancePropertiesResponse {
    /**
     * Policy for sharing applications on this compute instance among users of parent workspace. If Personal, only the creator can access applications on this compute instance. When Shared, any workspace user can access applications on this instance depending on his/her assigned role.
     */
    applicationSharingPolicy?: string;
    /**
     * Describes available applications and their endpoints on this ComputeInstance.
     */
    applications: outputs.machinelearningservices.v20220501.ComputeInstanceApplicationResponse[];
    /**
     * The Compute Instance Authorization type. Available values are personal (default).
     */
    computeInstanceAuthorizationType?: string;
    /**
     * Describes all connectivity endpoints available for this ComputeInstance.
     */
    connectivityEndpoints: outputs.machinelearningservices.v20220501.ComputeInstanceConnectivityEndpointsResponse;
    /**
     * Describes informations of containers on this ComputeInstance.
     */
    containers: outputs.machinelearningservices.v20220501.ComputeInstanceContainerResponse[];
    /**
     * Describes information on user who created this ComputeInstance.
     */
    createdBy: outputs.machinelearningservices.v20220501.ComputeInstanceCreatedByResponse;
    /**
     * Describes informations of dataDisks on this ComputeInstance.
     */
    dataDisks: outputs.machinelearningservices.v20220501.ComputeInstanceDataDiskResponse[];
    /**
     * Describes informations of dataMounts on this ComputeInstance.
     */
    dataMounts: outputs.machinelearningservices.v20220501.ComputeInstanceDataMountResponse[];
    /**
     * Enable or disable node public IP address provisioning. Possible values are: Possible values are: true - Indicates that the compute nodes will have public IPs provisioned. false - Indicates that the compute nodes will have a private endpoint and no public IPs.
     */
    enableNodePublicIp?: boolean;
    /**
     * Collection of errors encountered on this ComputeInstance.
     */
    errors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The last operation on ComputeInstance.
     */
    lastOperation: outputs.machinelearningservices.v20220501.ComputeInstanceLastOperationResponse;
    /**
     * Settings for a personal compute instance.
     */
    personalComputeInstanceSettings?: outputs.machinelearningservices.v20220501.PersonalComputeInstanceSettingsResponse;
    /**
     * The list of schedules to be applied on the computes.
     */
    schedules: outputs.machinelearningservices.v20220501.ComputeSchedulesResponse;
    /**
     * Details of customized scripts to execute for setting up the cluster.
     */
    setupScripts?: outputs.machinelearningservices.v20220501.SetupScriptsResponse;
    /**
     * Specifies policy and settings for SSH access.
     */
    sshSettings?: outputs.machinelearningservices.v20220501.ComputeInstanceSshSettingsResponse;
    /**
     * The current state of this ComputeInstance.
     */
    state: string;
    /**
     * Virtual network subnet resource ID the compute nodes belong to.
     */
    subnet?: outputs.machinelearningservices.v20220501.ResourceIdResponse;
    /**
     * ComputeInstance version.
     */
    versions: outputs.machinelearningservices.v20220501.ComputeInstanceVersionResponse;
    /**
     * Virtual Machine Size
     */
    vmSize?: string;
}
/**
 * computeInstancePropertiesResponseProvideDefaults sets the appropriate defaults for ComputeInstancePropertiesResponse
 */
export function computeInstancePropertiesResponseProvideDefaults(val: ComputeInstancePropertiesResponse): ComputeInstancePropertiesResponse {
    return {
        ...val,
        applicationSharingPolicy: (val.applicationSharingPolicy) ?? "Shared",
        computeInstanceAuthorizationType: (val.computeInstanceAuthorizationType) ?? "personal",
        sshSettings: (val.sshSettings ? outputs.machinelearningservices.v20220501.computeInstanceSshSettingsResponseProvideDefaults(val.sshSettings) : undefined),
    };
}

/**
 * An Azure Machine Learning compute instance.
 */
export interface ComputeInstanceResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'ComputeInstance'.
     */
    computeType: "ComputeInstance";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * Properties of ComputeInstance
     */
    properties?: outputs.machinelearningservices.v20220501.ComputeInstancePropertiesResponse;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}
/**
 * computeInstanceResponseProvideDefaults sets the appropriate defaults for ComputeInstanceResponse
 */
export function computeInstanceResponseProvideDefaults(val: ComputeInstanceResponse): ComputeInstanceResponse {
    return {
        ...val,
        properties: (val.properties ? outputs.machinelearningservices.v20220501.computeInstancePropertiesResponseProvideDefaults(val.properties) : undefined),
    };
}

/**
 * Specifies policy and settings for SSH access.
 */
export interface ComputeInstanceSshSettingsResponse {
    /**
     * Specifies the SSH rsa public key file as a string. Use "ssh-keygen -t rsa -b 2048" to generate your SSH key pairs.
     */
    adminPublicKey?: string;
    /**
     * Describes the admin user name.
     */
    adminUserName: string;
    /**
     * Describes the port for connecting through SSH.
     */
    sshPort: number;
    /**
     * State of the public SSH port. Possible values are: Disabled - Indicates that the public ssh port is closed on this instance. Enabled - Indicates that the public ssh port is open and accessible according to the VNet/subnet policy if applicable.
     */
    sshPublicAccess?: string;
}
/**
 * computeInstanceSshSettingsResponseProvideDefaults sets the appropriate defaults for ComputeInstanceSshSettingsResponse
 */
export function computeInstanceSshSettingsResponseProvideDefaults(val: ComputeInstanceSshSettingsResponse): ComputeInstanceSshSettingsResponse {
    return {
        ...val,
        sshPublicAccess: (val.sshPublicAccess) ?? "Disabled",
    };
}

/**
 * Version of computeInstance.
 */
export interface ComputeInstanceVersionResponse {
    /**
     * Runtime of compute instance.
     */
    runtime?: string;
}

/**
 * The list of schedules to be applied on the computes
 */
export interface ComputeSchedulesResponse {
    /**
     * The list of compute start stop schedules to be applied.
     */
    computeStartStop?: outputs.machinelearningservices.v20220501.ComputeStartStopScheduleResponse[];
}

/**
 * Compute start stop schedule properties
 */
export interface ComputeStartStopScheduleResponse {
    /**
     * The compute power action.
     */
    action?: string;
    /**
     * Schedule id.
     */
    id: string;
    /**
     * The current deployment state of schedule.
     */
    provisioningStatus: string;
    schedule?: outputs.machinelearningservices.v20220501.ScheduleBaseResponse;
}

/**
 * Resource requirements for each container instance within an online deployment.
 */
export interface ContainerResourceRequirementsResponse {
    /**
     * Container resource limit info:
     */
    containerResourceLimits?: outputs.machinelearningservices.v20220501.ContainerResourceSettingsResponse;
    /**
     * Container resource request info:
     */
    containerResourceRequests?: outputs.machinelearningservices.v20220501.ContainerResourceSettingsResponse;
}

export interface ContainerResourceSettingsResponse {
    /**
     * Number of vCPUs request/limit for container. More info:
     * https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
     */
    cpu?: string;
    /**
     * Number of Nvidia GPU cards request/limit for container. More info:
     * https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
     */
    gpu?: string;
    /**
     * Memory size request/limit for container. More info:
     * https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
     */
    memory?: string;
}

export interface CosmosDbSettingsResponse {
    /**
     * The throughput of the collections in cosmosdb database
     */
    collectionsThroughput?: number;
}

export interface CustomModelJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'custom_model'.
     */
    jobInputType: "custom_model";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * customModelJobInputResponseProvideDefaults sets the appropriate defaults for CustomModelJobInputResponse
 */
export function customModelJobInputResponseProvideDefaults(val: CustomModelJobInputResponse): CustomModelJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface CustomModelJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'custom_model'.
     */
    jobOutputType: "custom_model";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * customModelJobOutputResponseProvideDefaults sets the appropriate defaults for CustomModelJobOutputResponse
 */
export function customModelJobOutputResponseProvideDefaults(val: CustomModelJobOutputResponse): CustomModelJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

/**
 * Container for data asset versions.
 */
export interface DataContainerResponse {
    /**
     * [Required] Specifies the type of data.
     */
    dataType: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The latest version inside this container.
     */
    latestVersion: string;
    /**
     * The next auto incremental version
     */
    nextVersion: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * dataContainerResponseProvideDefaults sets the appropriate defaults for DataContainerResponse
 */
export function dataContainerResponseProvideDefaults(val: DataContainerResponse): DataContainerResponse {
    return {
        ...val,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * A DataFactory compute.
 */
export interface DataFactoryResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'DataFactory'.
     */
    computeType: "DataFactory";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

/**
 * A DataLakeAnalytics compute.
 */
export interface DataLakeAnalyticsResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'DataLakeAnalytics'.
     */
    computeType: "DataLakeAnalytics";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    properties?: outputs.machinelearningservices.v20220501.DataLakeAnalyticsSchemaResponseProperties;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

export interface DataLakeAnalyticsSchemaResponseProperties {
    /**
     * DataLake Store Account Name
     */
    dataLakeStoreAccountName?: string;
}

/**
 * Reference to an asset via its path in a datastore.
 */
export interface DataPathAssetReferenceResponse {
    /**
     * ARM resource ID of the datastore where the asset is located.
     */
    datastoreId?: string;
    /**
     * The path of the file/directory in the datastore.
     */
    path?: string;
    /**
     * Enum to determine which reference method to use for an asset.
     * Expected value is 'DataPath'.
     */
    referenceType: "DataPath";
}

/**
 * Properties of Databricks
 */
export interface DatabricksPropertiesResponse {
    /**
     * Databricks access token
     */
    databricksAccessToken?: string;
    /**
     * Workspace Url
     */
    workspaceUrl?: string;
}

/**
 * A DataFactory compute.
 */
export interface DatabricksResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'Databricks'.
     */
    computeType: "Databricks";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * Properties of Databricks
     */
    properties?: outputs.machinelearningservices.v20220501.DatabricksPropertiesResponse;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

export interface DefaultScaleSettingsResponse {
    /**
     *
     * Expected value is 'Default'.
     */
    scaleType: "Default";
}

export interface EncryptionKeyVaultPropertiesResponse {
    /**
     * For future use - The client id of the identity which will be used to access key vault.
     */
    identityClientId?: string;
    /**
     * Key vault uri to access the encryption key.
     */
    keyIdentifier: string;
    /**
     * The ArmId of the keyVault where the customer owned encryption key is present.
     */
    keyVaultArmId: string;
}

export interface EncryptionPropertyResponse {
    /**
     * The identity that will be used to access the key vault for encryption at rest.
     */
    identity?: outputs.machinelearningservices.v20220501.IdentityForCmkResponse;
    /**
     * Customer Key vault properties.
     */
    keyVaultProperties: outputs.machinelearningservices.v20220501.EncryptionKeyVaultPropertiesResponse;
    /**
     * Indicates whether or not the encryption is enabled for the workspace.
     */
    status: string;
}

/**
 * Container for environment specification versions.
 */
export interface EnvironmentContainerResponse {
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The latest version inside this container.
     */
    latestVersion: string;
    /**
     * The next auto incremental version
     */
    nextVersion: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * environmentContainerResponseProvideDefaults sets the appropriate defaults for EnvironmentContainerResponse
 */
export function environmentContainerResponseProvideDefaults(val: EnvironmentContainerResponse): EnvironmentContainerResponse {
    return {
        ...val,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Environment version details.
 */
export interface EnvironmentVersionResponse {
    /**
     * Configuration settings for Docker build context.
     */
    build?: outputs.machinelearningservices.v20220501.BuildContextResponse;
    /**
     * Standard configuration file used by Conda that lets you install any kind of package, including Python, R, and C/C++ packages.
     * <see href="https://repo2docker.readthedocs.io/en/latest/config_files.html#environment-yml-install-a-conda-environment" />
     */
    condaFile?: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Environment type is either user managed or curated by the Azure ML service
     * <see href="https://docs.microsoft.com/en-us/azure/machine-learning/resource-curated-environments" />
     */
    environmentType: string;
    /**
     * Name of the image that will be used for the environment.
     * <seealso href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-custom-docker-image#use-a-custom-base-image" />
     */
    image?: string;
    /**
     * Defines configuration specific to inference.
     */
    inferenceConfig?: outputs.machinelearningservices.v20220501.InferenceContainerPropertiesResponse;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The OS type of the environment.
     */
    osType?: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * environmentVersionResponseProvideDefaults sets the appropriate defaults for EnvironmentVersionResponse
 */
export function environmentVersionResponseProvideDefaults(val: EnvironmentVersionResponse): EnvironmentVersionResponse {
    return {
        ...val,
        build: (val.build ? outputs.machinelearningservices.v20220501.buildContextResponseProvideDefaults(val.build) : undefined),
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
        osType: (val.osType) ?? "Linux",
    };
}

/**
 * The resource management error additional info.
 */
export interface ErrorAdditionalInfoResponse {
    /**
     * The additional info.
     */
    info: any;
    /**
     * The additional info type.
     */
    type: string;
}

/**
 * The error detail.
 */
export interface ErrorDetailResponse {
    /**
     * The error additional info.
     */
    additionalInfo: outputs.machinelearningservices.v20220501.ErrorAdditionalInfoResponse[];
    /**
     * The error code.
     */
    code: string;
    /**
     * The error details.
     */
    details: outputs.machinelearningservices.v20220501.ErrorDetailResponse[];
    /**
     * The error message.
     */
    message: string;
    /**
     * The error target.
     */
    target: string;
}

/**
 * Common error response for all Azure Resource Manager APIs to return error details for failed operations. (This also follows the OData error response format.).
 */
export interface ErrorResponseResponse {
    /**
     * The error object.
     */
    error?: outputs.machinelearningservices.v20220501.ErrorDetailResponse;
}

export interface FlavorDataResponse {
    /**
     * Model flavor-specific data.
     */
    data?: {[key: string]: string};
}

/**
 * Defines a Sampling Algorithm that exhaustively generates every value combination in the space
 */
export interface GridSamplingAlgorithmResponse {
    /**
     *
     * Expected value is 'Grid'.
     */
    samplingAlgorithmType: "Grid";
}

/**
 * HDInsight compute properties
 */
export interface HDInsightPropertiesResponse {
    /**
     * Public IP address of the master node of the cluster.
     */
    address?: string;
    /**
     * Admin credentials for master node of the cluster
     */
    administratorAccount?: outputs.machinelearningservices.v20220501.VirtualMachineSshCredentialsResponse;
    /**
     * Port open for ssh connections on the master node of the cluster.
     */
    sshPort?: number;
}

/**
 * A HDInsight compute.
 */
export interface HDInsightResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'HDInsight'.
     */
    computeType: "HDInsight";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * HDInsight compute properties
     */
    properties?: outputs.machinelearningservices.v20220501.HDInsightPropertiesResponse;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

/**
 * Reference to an asset via its ARM resource ID.
 */
export interface IdAssetReferenceResponse {
    /**
     * [Required] ARM resource ID of the asset.
     */
    assetId: string;
    /**
     * Enum to determine which reference method to use for an asset.
     * Expected value is 'Id'.
     */
    referenceType: "Id";
}

/**
 * Identity that will be used to access key vault for encryption at rest
 */
export interface IdentityForCmkResponse {
    /**
     * The ArmId of the user assigned identity that will be used to access the customer managed key vault
     */
    userAssignedIdentity?: string;
}

export interface InferenceContainerPropertiesResponse {
    /**
     * The route to check the liveness of the inference server container.
     */
    livenessRoute?: outputs.machinelearningservices.v20220501.RouteResponse;
    /**
     * The route to check the readiness of the inference server container.
     */
    readinessRoute?: outputs.machinelearningservices.v20220501.RouteResponse;
    /**
     * The port to send the scoring requests to, within the inference server container.
     */
    scoringRoute?: outputs.machinelearningservices.v20220501.RouteResponse;
}

/**
 * Instance type schema.
 */
export interface InstanceTypeSchemaResponse {
    /**
     * Node Selector
     */
    nodeSelector?: {[key: string]: string};
    /**
     * Resource requests/limits for this instance type
     */
    resources?: outputs.machinelearningservices.v20220501.InstanceTypeSchemaResponseResources;
}

/**
 * Resource requests/limits for this instance type
 */
export interface InstanceTypeSchemaResponseResources {
    /**
     * Resource limits for this instance type
     */
    limits?: {[key: string]: string};
    /**
     * Resource requests for this instance type
     */
    requests?: {[key: string]: string};
}

/**
 * Job endpoint definition
 */
export interface JobServiceResponse {
    /**
     * Url for endpoint.
     */
    endpoint?: string;
    /**
     * Any error in the service.
     */
    errorMessage: string;
    /**
     * Endpoint type.
     */
    jobServiceType?: string;
    /**
     * Port for endpoint.
     */
    port?: number;
    /**
     * Additional properties to set on the endpoint.
     */
    properties?: {[key: string]: string};
    /**
     * Status of endpoint.
     */
    status: string;
}

/**
 * Properties specific to a KubernetesOnlineDeployment.
 */
export interface KubernetesOnlineDeploymentResponse {
    /**
     * If true, enables Application Insights logging.
     */
    appInsightsEnabled?: boolean;
    /**
     * Code configuration for the endpoint deployment.
     */
    codeConfiguration?: outputs.machinelearningservices.v20220501.CodeConfigurationResponse;
    /**
     * The resource requirements for the container (cpu and memory).
     */
    containerResourceRequirements?: outputs.machinelearningservices.v20220501.ContainerResourceRequirementsResponse;
    /**
     * Description of the endpoint deployment.
     */
    description?: string;
    /**
     * Enum to determine endpoint compute type.
     * Expected value is 'Kubernetes'.
     */
    endpointComputeType: "Kubernetes";
    /**
     * ARM resource ID or AssetId of the environment specification for the endpoint deployment.
     */
    environmentId?: string;
    /**
     * Environment variables configuration for the deployment.
     */
    environmentVariables?: {[key: string]: string};
    /**
     * Compute instance type.
     */
    instanceType?: string;
    /**
     * Liveness probe monitors the health of the container regularly.
     */
    livenessProbe?: outputs.machinelearningservices.v20220501.ProbeSettingsResponse;
    /**
     * The URI path to the model.
     */
    model?: string;
    /**
     * The path to mount the model in custom container.
     */
    modelMountPath?: string;
    /**
     * Property dictionary. Properties can be added, but not removed or altered.
     */
    properties?: {[key: string]: string};
    /**
     * Provisioning state for the endpoint deployment.
     */
    provisioningState: string;
    /**
     * Readiness probe validates if the container is ready to serve traffic. The properties and defaults are the same as liveness probe.
     */
    readinessProbe?: outputs.machinelearningservices.v20220501.ProbeSettingsResponse;
    /**
     * Request settings for the deployment.
     */
    requestSettings?: outputs.machinelearningservices.v20220501.OnlineRequestSettingsResponse;
    /**
     * Scale settings for the deployment.
     * If it is null or not provided,
     * it defaults to TargetUtilizationScaleSettings for KubernetesOnlineDeployment
     * and to DefaultScaleSettings for ManagedOnlineDeployment.
     */
    scaleSettings?: outputs.machinelearningservices.v20220501.DefaultScaleSettingsResponse | outputs.machinelearningservices.v20220501.TargetUtilizationScaleSettingsResponse;
}
/**
 * kubernetesOnlineDeploymentResponseProvideDefaults sets the appropriate defaults for KubernetesOnlineDeploymentResponse
 */
export function kubernetesOnlineDeploymentResponseProvideDefaults(val: KubernetesOnlineDeploymentResponse): KubernetesOnlineDeploymentResponse {
    return {
        ...val,
        appInsightsEnabled: (val.appInsightsEnabled) ?? false,
        livenessProbe: (val.livenessProbe ? outputs.machinelearningservices.v20220501.probeSettingsResponseProvideDefaults(val.livenessProbe) : undefined),
        readinessProbe: (val.readinessProbe ? outputs.machinelearningservices.v20220501.probeSettingsResponseProvideDefaults(val.readinessProbe) : undefined),
        requestSettings: (val.requestSettings ? outputs.machinelearningservices.v20220501.onlineRequestSettingsResponseProvideDefaults(val.requestSettings) : undefined),
    };
}

/**
 * Kubernetes properties
 */
export interface KubernetesPropertiesResponse {
    /**
     * Default instance type
     */
    defaultInstanceType?: string;
    /**
     * Extension instance release train.
     */
    extensionInstanceReleaseTrain?: string;
    /**
     * Extension principal-id.
     */
    extensionPrincipalId?: string;
    /**
     * Instance Type Schema
     */
    instanceTypes?: {[key: string]: outputs.machinelearningservices.v20220501.InstanceTypeSchemaResponse};
    /**
     * Compute namespace
     */
    namespace?: string;
    /**
     * Relay connection string.
     */
    relayConnectionString?: string;
    /**
     * ServiceBus connection string.
     */
    serviceBusConnectionString?: string;
    /**
     * VC name.
     */
    vcName?: string;
}
/**
 * kubernetesPropertiesResponseProvideDefaults sets the appropriate defaults for KubernetesPropertiesResponse
 */
export function kubernetesPropertiesResponseProvideDefaults(val: KubernetesPropertiesResponse): KubernetesPropertiesResponse {
    return {
        ...val,
        namespace: (val.namespace) ?? "default",
    };
}

/**
 * A Machine Learning compute based on Kubernetes Compute.
 */
export interface KubernetesResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'Kubernetes'.
     */
    computeType: "Kubernetes";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    /**
     * Properties of Kubernetes
     */
    properties?: outputs.machinelearningservices.v20220501.KubernetesPropertiesResponse;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}
/**
 * kubernetesResponseProvideDefaults sets the appropriate defaults for KubernetesResponse
 */
export function kubernetesResponseProvideDefaults(val: KubernetesResponse): KubernetesResponse {
    return {
        ...val,
        properties: (val.properties ? outputs.machinelearningservices.v20220501.kubernetesPropertiesResponseProvideDefaults(val.properties) : undefined),
    };
}

export interface ListNotebookKeysResultResponse {
    primaryAccessKey: string;
    secondaryAccessKey: string;
}

/**
 * Literal input type.
 */
export interface LiteralJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'literal'.
     */
    jobInputType: "literal";
    /**
     * [Required] Literal value for the input.
     */
    value: string;
}

export interface MLFlowModelJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'mlflow_model'.
     */
    jobInputType: "mlflow_model";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * mlflowModelJobInputResponseProvideDefaults sets the appropriate defaults for MLFlowModelJobInputResponse
 */
export function mlflowModelJobInputResponseProvideDefaults(val: MLFlowModelJobInputResponse): MLFlowModelJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface MLFlowModelJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'mlflow_model'.
     */
    jobOutputType: "mlflow_model";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * mlflowModelJobOutputResponseProvideDefaults sets the appropriate defaults for MLFlowModelJobOutputResponse
 */
export function mlflowModelJobOutputResponseProvideDefaults(val: MLFlowModelJobOutputResponse): MLFlowModelJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

/**
 * MLTable data definition
 */
export interface MLTableDataResponse {
    /**
     * Enum to determine the type of data.
     * Expected value is 'mltable'.
     */
    dataType: "mltable";
    /**
     * [Required] Uri of the data. Usage/meaning depends on Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20220501.Assets.DataVersionBase.DataType
     */
    dataUri: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Uris referenced in the MLTable definition (required for lineage)
     */
    referencedUris?: string[];
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * mltableDataResponseProvideDefaults sets the appropriate defaults for MLTableDataResponse
 */
export function mltableDataResponseProvideDefaults(val: MLTableDataResponse): MLTableDataResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

export interface MLTableJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'mltable'.
     */
    jobInputType: "mltable";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * mltableJobInputResponseProvideDefaults sets the appropriate defaults for MLTableJobInputResponse
 */
export function mltableJobInputResponseProvideDefaults(val: MLTableJobInputResponse): MLTableJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface MLTableJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'mltable'.
     */
    jobOutputType: "mltable";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * mltableJobOutputResponseProvideDefaults sets the appropriate defaults for MLTableJobOutputResponse
 */
export function mltableJobOutputResponseProvideDefaults(val: MLTableJobOutputResponse): MLTableJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

export interface ManagedIdentityAuthTypeWorkspaceConnectionPropertiesResponse {
    /**
     * Authentication type of the connection target
     * Expected value is 'ManagedIdentity'.
     */
    authType: "ManagedIdentity";
    /**
     * Category of the connection
     */
    category?: string;
    credentials?: outputs.machinelearningservices.v20220501.WorkspaceConnectionManagedIdentityResponse;
    target?: string;
    /**
     * Value details of the workspace connection.
     */
    value?: string;
    /**
     * format for the workspace connection value
     */
    valueFormat?: string;
}

/**
 * Managed identity configuration.
 */
export interface ManagedIdentityResponse {
    /**
     * Specifies a user-assigned identity by client ID. For system-assigned, do not set this field.
     */
    clientId?: string;
    /**
     * Enum to determine identity framework.
     * Expected value is 'Managed'.
     */
    identityType: "Managed";
    /**
     * Specifies a user-assigned identity by object ID. For system-assigned, do not set this field.
     */
    objectId?: string;
    /**
     * Specifies a user-assigned identity by ARM resource ID. For system-assigned, do not set this field.
     */
    resourceId?: string;
}

/**
 * Properties specific to a ManagedOnlineDeployment.
 */
export interface ManagedOnlineDeploymentResponse {
    /**
     * If true, enables Application Insights logging.
     */
    appInsightsEnabled?: boolean;
    /**
     * Code configuration for the endpoint deployment.
     */
    codeConfiguration?: outputs.machinelearningservices.v20220501.CodeConfigurationResponse;
    /**
     * Description of the endpoint deployment.
     */
    description?: string;
    /**
     * Enum to determine endpoint compute type.
     * Expected value is 'Managed'.
     */
    endpointComputeType: "Managed";
    /**
     * ARM resource ID or AssetId of the environment specification for the endpoint deployment.
     */
    environmentId?: string;
    /**
     * Environment variables configuration for the deployment.
     */
    environmentVariables?: {[key: string]: string};
    /**
     * Compute instance type.
     */
    instanceType?: string;
    /**
     * Liveness probe monitors the health of the container regularly.
     */
    livenessProbe?: outputs.machinelearningservices.v20220501.ProbeSettingsResponse;
    /**
     * The URI path to the model.
     */
    model?: string;
    /**
     * The path to mount the model in custom container.
     */
    modelMountPath?: string;
    /**
     * Property dictionary. Properties can be added, but not removed or altered.
     */
    properties?: {[key: string]: string};
    /**
     * Provisioning state for the endpoint deployment.
     */
    provisioningState: string;
    /**
     * Readiness probe validates if the container is ready to serve traffic. The properties and defaults are the same as liveness probe.
     */
    readinessProbe?: outputs.machinelearningservices.v20220501.ProbeSettingsResponse;
    /**
     * Request settings for the deployment.
     */
    requestSettings?: outputs.machinelearningservices.v20220501.OnlineRequestSettingsResponse;
    /**
     * Scale settings for the deployment.
     * If it is null or not provided,
     * it defaults to TargetUtilizationScaleSettings for KubernetesOnlineDeployment
     * and to DefaultScaleSettings for ManagedOnlineDeployment.
     */
    scaleSettings?: outputs.machinelearningservices.v20220501.DefaultScaleSettingsResponse | outputs.machinelearningservices.v20220501.TargetUtilizationScaleSettingsResponse;
}
/**
 * managedOnlineDeploymentResponseProvideDefaults sets the appropriate defaults for ManagedOnlineDeploymentResponse
 */
export function managedOnlineDeploymentResponseProvideDefaults(val: ManagedOnlineDeploymentResponse): ManagedOnlineDeploymentResponse {
    return {
        ...val,
        appInsightsEnabled: (val.appInsightsEnabled) ?? false,
        livenessProbe: (val.livenessProbe ? outputs.machinelearningservices.v20220501.probeSettingsResponseProvideDefaults(val.livenessProbe) : undefined),
        readinessProbe: (val.readinessProbe ? outputs.machinelearningservices.v20220501.probeSettingsResponseProvideDefaults(val.readinessProbe) : undefined),
        requestSettings: (val.requestSettings ? outputs.machinelearningservices.v20220501.onlineRequestSettingsResponseProvideDefaults(val.requestSettings) : undefined),
    };
}

/**
 * Managed service identity (system assigned and/or user assigned identities)
 */
export interface ManagedServiceIdentityResponse {
    /**
     * The service principal ID of the system assigned identity. This property will only be provided for a system assigned identity.
     */
    principalId: string;
    /**
     * The tenant ID of the system assigned identity. This property will only be provided for a system assigned identity.
     */
    tenantId: string;
    /**
     * Type of managed service identity (where both SystemAssigned and UserAssigned types are allowed).
     */
    type: string;
    /**
     * The set of user assigned identities associated with the resource. The userAssignedIdentities dictionary keys will be ARM resource ids in the form: '/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identityName}. The dictionary values can be empty objects ({}) in requests.
     */
    userAssignedIdentities?: {[key: string]: outputs.machinelearningservices.v20220501.UserAssignedIdentityResponse};
}

/**
 * Defines an early termination policy based on running averages of the primary metric of all runs
 */
export interface MedianStoppingPolicyResponse {
    /**
     * Number of intervals by which to delay the first evaluation.
     */
    delayEvaluation?: number;
    /**
     * Interval (number of runs) between policy evaluations.
     */
    evaluationInterval?: number;
    /**
     *
     * Expected value is 'MedianStopping'.
     */
    policyType: "MedianStopping";
}
/**
 * medianStoppingPolicyResponseProvideDefaults sets the appropriate defaults for MedianStoppingPolicyResponse
 */
export function medianStoppingPolicyResponseProvideDefaults(val: MedianStoppingPolicyResponse): MedianStoppingPolicyResponse {
    return {
        ...val,
        delayEvaluation: (val.delayEvaluation) ?? 0,
        evaluationInterval: (val.evaluationInterval) ?? 0,
    };
}

export interface ModelContainerResponse {
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The latest version inside this container.
     */
    latestVersion: string;
    /**
     * The next auto incremental version
     */
    nextVersion: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * modelContainerResponseProvideDefaults sets the appropriate defaults for ModelContainerResponse
 */
export function modelContainerResponseProvideDefaults(val: ModelContainerResponse): ModelContainerResponse {
    return {
        ...val,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * Model asset version details.
 */
export interface ModelVersionResponse {
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Mapping of model flavors to their properties.
     */
    flavors?: {[key: string]: outputs.machinelearningservices.v20220501.FlavorDataResponse};
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * Name of the training job which produced this model
     */
    jobName?: string;
    /**
     * The storage format for this entity. Used for NCD.
     */
    modelType?: string;
    /**
     * The URI path to the model contents.
     */
    modelUri?: string;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * modelVersionResponseProvideDefaults sets the appropriate defaults for ModelVersionResponse
 */
export function modelVersionResponseProvideDefaults(val: ModelVersionResponse): ModelVersionResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * MPI distribution configuration.
 */
export interface MpiResponse {
    /**
     * Enum to determine the job distribution type.
     * Expected value is 'Mpi'.
     */
    distributionType: "Mpi";
    /**
     * Number of processes per MPI node.
     */
    processCountPerInstance?: number;
}

/**
 * Counts of various compute node states on the amlCompute.
 */
export interface NodeStateCountsResponse {
    /**
     * Number of compute nodes in idle state.
     */
    idleNodeCount: number;
    /**
     * Number of compute nodes which are leaving the amlCompute.
     */
    leavingNodeCount: number;
    /**
     * Number of compute nodes which are in preempted state.
     */
    preemptedNodeCount: number;
    /**
     * Number of compute nodes which are being prepared.
     */
    preparingNodeCount: number;
    /**
     * Number of compute nodes which are running jobs.
     */
    runningNodeCount: number;
    /**
     * Number of compute nodes which are in unusable state.
     */
    unusableNodeCount: number;
}

export interface NoneAuthTypeWorkspaceConnectionPropertiesResponse {
    /**
     * Authentication type of the connection target
     * Expected value is 'None'.
     */
    authType: "None";
    /**
     * Category of the connection
     */
    category?: string;
    target?: string;
    /**
     * Value details of the workspace connection.
     */
    value?: string;
    /**
     * format for the workspace connection value
     */
    valueFormat?: string;
}

/**
 * Empty/none datastore credentials.
 */
export interface NoneDatastoreCredentialsResponse {
    /**
     * Enum to determine the datastore credentials type.
     * Expected value is 'None'.
     */
    credentialsType: "None";
}

export interface NotebookPreparationErrorResponse {
    errorMessage?: string;
    statusCode?: number;
}

export interface NotebookResourceInfoResponse {
    fqdn?: string;
    /**
     * The error that occurs when preparing notebook.
     */
    notebookPreparationError?: outputs.machinelearningservices.v20220501.NotebookPreparationErrorResponse;
    /**
     * the data plane resourceId that used to initialize notebook component
     */
    resourceId?: string;
}

/**
 * Optimization objective.
 */
export interface ObjectiveResponse {
    /**
     * [Required] Defines supported metric goals for hyperparameter tuning
     */
    goal: string;
    /**
     * [Required] Name of the metric to optimize.
     */
    primaryMetric: string;
}

/**
 * Online endpoint configuration
 */
export interface OnlineEndpointResponse {
    /**
     * [Required] Use 'Key' for key based authentication and 'AMLToken' for Azure Machine Learning token-based authentication. 'Key' doesn't expire but 'AMLToken' does.
     */
    authMode: string;
    /**
     * ARM resource ID of the compute if it exists.
     * optional
     */
    compute?: string;
    /**
     * Description of the inference endpoint.
     */
    description?: string;
    /**
     * Property dictionary. Properties can be added, but not removed or altered.
     */
    properties?: {[key: string]: string};
    /**
     * Provisioning state for the endpoint.
     */
    provisioningState: string;
    /**
     * Endpoint URI.
     */
    scoringUri: string;
    /**
     * Endpoint Swagger URI.
     */
    swaggerUri: string;
    /**
     * Percentage of traffic from endpoint to divert to each deployment. Traffic values need to sum to 100.
     */
    traffic?: {[key: string]: number};
}

/**
 * Online deployment scoring requests configuration.
 */
export interface OnlineRequestSettingsResponse {
    /**
     * The number of maximum concurrent requests per node allowed per deployment. Defaults to 1.
     */
    maxConcurrentRequestsPerInstance?: number;
    /**
     * The maximum amount of time a request will stay in the queue in ISO 8601 format.
     * Defaults to 500ms.
     */
    maxQueueWait?: string;
    /**
     * The scoring timeout in ISO 8601 format.
     * Defaults to 5000ms.
     */
    requestTimeout?: string;
}
/**
 * onlineRequestSettingsResponseProvideDefaults sets the appropriate defaults for OnlineRequestSettingsResponse
 */
export function onlineRequestSettingsResponseProvideDefaults(val: OnlineRequestSettingsResponse): OnlineRequestSettingsResponse {
    return {
        ...val,
        maxConcurrentRequestsPerInstance: (val.maxConcurrentRequestsPerInstance) ?? 1,
        maxQueueWait: (val.maxQueueWait) ?? "PT0.5S",
        requestTimeout: (val.requestTimeout) ?? "PT5S",
    };
}

/**
 * Reference to an asset via its path in a job output.
 */
export interface OutputPathAssetReferenceResponse {
    /**
     * ARM resource ID of the job.
     */
    jobId?: string;
    /**
     * The path of the file/directory in the job output.
     */
    path?: string;
    /**
     * Enum to determine which reference method to use for an asset.
     * Expected value is 'OutputPath'.
     */
    referenceType: "OutputPath";
}

export interface PATAuthTypeWorkspaceConnectionPropertiesResponse {
    /**
     * Authentication type of the connection target
     * Expected value is 'PAT'.
     */
    authType: "PAT";
    /**
     * Category of the connection
     */
    category?: string;
    credentials?: outputs.machinelearningservices.v20220501.WorkspaceConnectionPersonalAccessTokenResponse;
    target?: string;
    /**
     * Value details of the workspace connection.
     */
    value?: string;
    /**
     * format for the workspace connection value
     */
    valueFormat?: string;
}

export interface PasswordResponse {
    name: string;
    value: string;
}

/**
 * Settings for a personal compute instance.
 */
export interface PersonalComputeInstanceSettingsResponse {
    /**
     * A user explicitly assigned to a personal compute instance.
     */
    assignedUser?: outputs.machinelearningservices.v20220501.AssignedUserResponse;
}

/**
 * Pipeline Job definition: defines generic to MFE attributes.
 */
export interface PipelineJobResponse {
    /**
     * ARM resource ID of the compute resource.
     */
    computeId?: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Display name of job.
     */
    displayName?: string;
    /**
     * The name of the experiment the job belongs to. If not set, the job is placed in the "Default" experiment.
     */
    experimentName?: string;
    /**
     * Identity configuration. If set, this should be one of AmlToken, ManagedIdentity, UserIdentity or null.
     * Defaults to AmlToken if null.
     */
    identity?: outputs.machinelearningservices.v20220501.AmlTokenResponse | outputs.machinelearningservices.v20220501.ManagedIdentityResponse | outputs.machinelearningservices.v20220501.UserIdentityResponse;
    /**
     * Inputs for the pipeline job.
     */
    inputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobInputResponse | outputs.machinelearningservices.v20220501.LiteralJobInputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobInputResponse | outputs.machinelearningservices.v20220501.MLTableJobInputResponse | outputs.machinelearningservices.v20220501.TritonModelJobInputResponse | outputs.machinelearningservices.v20220501.UriFileJobInputResponse | outputs.machinelearningservices.v20220501.UriFolderJobInputResponse};
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * Enum to determine the type of job.
     * Expected value is 'Pipeline'.
     */
    jobType: "Pipeline";
    /**
     * Jobs construct the Pipeline Job.
     */
    jobs?: {[key: string]: any};
    /**
     * Outputs for the pipeline job
     */
    outputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLTableJobOutputResponse | outputs.machinelearningservices.v20220501.TritonModelJobOutputResponse | outputs.machinelearningservices.v20220501.UriFileJobOutputResponse | outputs.machinelearningservices.v20220501.UriFolderJobOutputResponse};
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * List of JobEndpoints.
     * For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
     */
    services?: {[key: string]: outputs.machinelearningservices.v20220501.JobServiceResponse};
    /**
     * Pipeline settings, for things like ContinueRunOnStepFailure etc.
     */
    settings?: any;
    /**
     * Status of the job.
     */
    status: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * pipelineJobResponseProvideDefaults sets the appropriate defaults for PipelineJobResponse
 */
export function pipelineJobResponseProvideDefaults(val: PipelineJobResponse): PipelineJobResponse {
    return {
        ...val,
        experimentName: (val.experimentName) ?? "Default",
        isArchived: (val.isArchived) ?? false,
    };
}

/**
 * The Private Endpoint Connection resource.
 */
export interface PrivateEndpointConnectionResponse {
    /**
     * Fully qualified resource ID for the resource. Ex - /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}
     */
    id: string;
    /**
     * The identity of the resource.
     */
    identity?: outputs.machinelearningservices.v20220501.ManagedServiceIdentityResponse;
    /**
     * Specifies the location of the resource.
     */
    location?: string;
    /**
     * The name of the resource
     */
    name: string;
    /**
     * The resource of private end point.
     */
    privateEndpoint?: outputs.machinelearningservices.v20220501.PrivateEndpointResponse;
    /**
     * A collection of information about the state of the connection between service consumer and provider.
     */
    privateLinkServiceConnectionState: outputs.machinelearningservices.v20220501.PrivateLinkServiceConnectionStateResponse;
    /**
     * The provisioning state of the private endpoint connection resource.
     */
    provisioningState: string;
    /**
     * The sku of the workspace.
     */
    sku?: outputs.machinelearningservices.v20220501.SkuResponse;
    /**
     * Azure Resource Manager metadata containing createdBy and modifiedBy information.
     */
    systemData: outputs.machinelearningservices.v20220501.SystemDataResponse;
    /**
     * Contains resource tags defined as key/value pairs.
     */
    tags?: {[key: string]: string};
    /**
     * The type of the resource. E.g. "Microsoft.Compute/virtualMachines" or "Microsoft.Storage/storageAccounts"
     */
    type: string;
}

/**
 * The Private Endpoint resource.
 */
export interface PrivateEndpointResponse {
    /**
     * The ARM identifier for Private Endpoint
     */
    id: string;
    /**
     * The ARM identifier for Subnet resource that private endpoint links to
     */
    subnetArmId: string;
}

/**
 * A collection of information about the state of the connection between service consumer and provider.
 */
export interface PrivateLinkServiceConnectionStateResponse {
    /**
     * A message indicating if changes on the service provider require any updates on the consumer.
     */
    actionsRequired?: string;
    /**
     * The reason for approval/rejection of the connection.
     */
    description?: string;
    /**
     * Indicates whether the connection has been Approved/Rejected/Removed by the owner of the service.
     */
    status?: string;
}

/**
 * Deployment container liveness/readiness probe configuration.
 */
export interface ProbeSettingsResponse {
    /**
     * The number of failures to allow before returning an unhealthy status.
     */
    failureThreshold?: number;
    /**
     * The delay before the first probe in ISO 8601 format.
     */
    initialDelay?: string;
    /**
     * The length of time between probes in ISO 8601 format.
     */
    period?: string;
    /**
     * The number of successful probes before returning a healthy status.
     */
    successThreshold?: number;
    /**
     * The probe timeout in ISO 8601 format.
     */
    timeout?: string;
}
/**
 * probeSettingsResponseProvideDefaults sets the appropriate defaults for ProbeSettingsResponse
 */
export function probeSettingsResponseProvideDefaults(val: ProbeSettingsResponse): ProbeSettingsResponse {
    return {
        ...val,
        failureThreshold: (val.failureThreshold) ?? 30,
        period: (val.period) ?? "PT10S",
        successThreshold: (val.successThreshold) ?? 1,
        timeout: (val.timeout) ?? "PT2S",
    };
}

/**
 * PyTorch distribution configuration.
 */
export interface PyTorchResponse {
    /**
     * Enum to determine the job distribution type.
     * Expected value is 'PyTorch'.
     */
    distributionType: "PyTorch";
    /**
     * Number of processes per node.
     */
    processCountPerInstance?: number;
}

/**
 * Defines a Sampling Algorithm that generates values randomly
 */
export interface RandomSamplingAlgorithmResponse {
    /**
     * The specific type of random algorithm
     */
    rule?: string;
    /**
     *
     * Expected value is 'Random'.
     */
    samplingAlgorithmType: "Random";
    /**
     * An optional integer to use as the seed for random number generation
     */
    seed?: number;
}
/**
 * randomSamplingAlgorithmResponseProvideDefaults sets the appropriate defaults for RandomSamplingAlgorithmResponse
 */
export function randomSamplingAlgorithmResponseProvideDefaults(val: RandomSamplingAlgorithmResponse): RandomSamplingAlgorithmResponse {
    return {
        ...val,
        rule: (val.rule) ?? "Random",
    };
}

export interface RegistryListCredentialsResultResponse {
    location: string;
    passwords?: outputs.machinelearningservices.v20220501.PasswordResponse[];
    username: string;
}

export interface ResourceConfigurationResponse {
    /**
     * Optional number of instances or nodes used by the compute target.
     */
    instanceCount?: number;
    /**
     * Optional type of VM used as supported by the compute target.
     */
    instanceType?: string;
    /**
     * Additional properties bag.
     */
    properties?: {[key: string]: any};
}
/**
 * resourceConfigurationResponseProvideDefaults sets the appropriate defaults for ResourceConfigurationResponse
 */
export function resourceConfigurationResponseProvideDefaults(val: ResourceConfigurationResponse): ResourceConfigurationResponse {
    return {
        ...val,
        instanceCount: (val.instanceCount) ?? 1,
    };
}

/**
 * Represents a resource ID. For example, for a subnet, it is the resource URL for the subnet.
 */
export interface ResourceIdResponse {
    /**
     * The ID of the resource
     */
    id: string;
}

export interface RouteResponse {
    /**
     * [Required] The path for the route.
     */
    path: string;
    /**
     * [Required] The port for the route.
     */
    port: number;
}

export interface SASAuthTypeWorkspaceConnectionPropertiesResponse {
    /**
     * Authentication type of the connection target
     * Expected value is 'SAS'.
     */
    authType: "SAS";
    /**
     * Category of the connection
     */
    category?: string;
    credentials?: outputs.machinelearningservices.v20220501.WorkspaceConnectionSharedAccessSignatureResponse;
    target?: string;
    /**
     * Value details of the workspace connection.
     */
    value?: string;
    /**
     * format for the workspace connection value
     */
    valueFormat?: string;
}

/**
 * SAS datastore credentials configuration.
 */
export interface SasDatastoreCredentialsResponse {
    /**
     * Enum to determine the datastore credentials type.
     * Expected value is 'Sas'.
     */
    credentialsType: "Sas";
}

/**
 * scale settings for AML Compute
 */
export interface ScaleSettingsResponse {
    /**
     * Max number of nodes to use
     */
    maxNodeCount: number;
    /**
     * Min number of nodes to use
     */
    minNodeCount?: number;
    /**
     * Node Idle Time before scaling down amlCompute. This string needs to be in the RFC Format.
     */
    nodeIdleTimeBeforeScaleDown?: string;
}
/**
 * scaleSettingsResponseProvideDefaults sets the appropriate defaults for ScaleSettingsResponse
 */
export function scaleSettingsResponseProvideDefaults(val: ScaleSettingsResponse): ScaleSettingsResponse {
    return {
        ...val,
        minNodeCount: (val.minNodeCount) ?? 0,
    };
}

export interface ScheduleBaseResponse {
    id?: string;
    provisioningStatus?: string;
    status?: string;
}

/**
 * Script reference
 */
export interface ScriptReferenceResponse {
    /**
     * Optional command line arguments passed to the script to run.
     */
    scriptArguments?: string;
    /**
     * The location of scripts in the mounted volume.
     */
    scriptData?: string;
    /**
     * The storage source of the script: inline, workspace.
     */
    scriptSource?: string;
    /**
     * Optional time period passed to timeout command.
     */
    timeout?: string;
}

/**
 * Customized setup scripts
 */
export interface ScriptsToExecuteResponse {
    /**
     * Script that's run only once during provision of the compute.
     */
    creationScript?: outputs.machinelearningservices.v20220501.ScriptReferenceResponse;
    /**
     * Script that's run every time the machine starts.
     */
    startupScript?: outputs.machinelearningservices.v20220501.ScriptReferenceResponse;
}

export interface ServiceManagedResourcesSettingsResponse {
    /**
     * The settings for the service managed cosmosdb account.
     */
    cosmosDb?: outputs.machinelearningservices.v20220501.CosmosDbSettingsResponse;
}

/**
 * Service Principal datastore credentials configuration.
 */
export interface ServicePrincipalDatastoreCredentialsResponse {
    /**
     * Authority URL used for authentication.
     */
    authorityUrl?: string;
    /**
     * [Required] Service principal client ID.
     */
    clientId: string;
    /**
     * Enum to determine the datastore credentials type.
     * Expected value is 'ServicePrincipal'.
     */
    credentialsType: "ServicePrincipal";
    /**
     * Resource the service principal has access to.
     */
    resourceUrl?: string;
    /**
     * [Required] ID of the tenant to which the service principal belongs.
     */
    tenantId: string;
}

/**
 * Details of customized scripts to execute for setting up the cluster.
 */
export interface SetupScriptsResponse {
    /**
     * Customized setup scripts
     */
    scripts?: outputs.machinelearningservices.v20220501.ScriptsToExecuteResponse;
}

export interface SharedPrivateLinkResourceResponse {
    /**
     * The private link resource group id.
     */
    groupId?: string;
    /**
     * Unique name of the private link.
     */
    name?: string;
    /**
     * The resource id that private link links to.
     */
    privateLinkResourceId?: string;
    /**
     * Request message.
     */
    requestMessage?: string;
    /**
     * Indicates whether the connection has been Approved/Rejected/Removed by the owner of the service.
     */
    status?: string;
}

/**
 * The resource model definition representing SKU
 */
export interface SkuResponse {
    /**
     * If the SKU supports scale out/in then the capacity integer should be included. If scale out/in is not possible for the resource this may be omitted.
     */
    capacity?: number;
    /**
     * If the service has different generations of hardware, for the same SKU, then that can be captured here.
     */
    family?: string;
    /**
     * The name of the SKU. Ex - P3. It is typically a letter+number code
     */
    name: string;
    /**
     * The SKU size. When the name field is the combination of tier and some other value, this would be the standalone code. 
     */
    size?: string;
    /**
     * This field is required to be implemented by the Resource Provider if the service has more than one tier, but is not required on a PUT.
     */
    tier?: string;
}

/**
 * The ssl configuration for scoring
 */
export interface SslConfigurationResponse {
    /**
     * Cert data
     */
    cert?: string;
    /**
     * CNAME of the cert
     */
    cname?: string;
    /**
     * Key data
     */
    key?: string;
    /**
     * Leaf domain label of public endpoint
     */
    leafDomainLabel?: string;
    /**
     * Indicates whether to overwrite existing domain label.
     */
    overwriteExistingDomain?: boolean;
    /**
     * Enable or disable ssl for scoring
     */
    status?: string;
}

/**
 * Sweep Job limit class.
 */
export interface SweepJobLimitsResponse {
    /**
     *
     * Expected value is 'Sweep'.
     */
    jobLimitsType: "Sweep";
    /**
     * Sweep Job max concurrent trials.
     */
    maxConcurrentTrials?: number;
    /**
     * Sweep Job max total trials.
     */
    maxTotalTrials?: number;
    /**
     * The max run duration in ISO 8601 format, after which the job will be cancelled. Only supports duration with precision as low as Seconds.
     */
    timeout?: string;
    /**
     * Sweep Job Trial timeout value.
     */
    trialTimeout?: string;
}

/**
 * Sweep job definition.
 */
export interface SweepJobResponse {
    /**
     * ARM resource ID of the compute resource.
     */
    computeId?: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * Display name of job.
     */
    displayName?: string;
    /**
     * Early termination policies enable canceling poor-performing runs before they complete
     */
    earlyTermination?: outputs.machinelearningservices.v20220501.BanditPolicyResponse | outputs.machinelearningservices.v20220501.MedianStoppingPolicyResponse | outputs.machinelearningservices.v20220501.TruncationSelectionPolicyResponse;
    /**
     * The name of the experiment the job belongs to. If not set, the job is placed in the "Default" experiment.
     */
    experimentName?: string;
    /**
     * Identity configuration. If set, this should be one of AmlToken, ManagedIdentity, UserIdentity or null.
     * Defaults to AmlToken if null.
     */
    identity?: outputs.machinelearningservices.v20220501.AmlTokenResponse | outputs.machinelearningservices.v20220501.ManagedIdentityResponse | outputs.machinelearningservices.v20220501.UserIdentityResponse;
    /**
     * Mapping of input data bindings used in the job.
     */
    inputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobInputResponse | outputs.machinelearningservices.v20220501.LiteralJobInputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobInputResponse | outputs.machinelearningservices.v20220501.MLTableJobInputResponse | outputs.machinelearningservices.v20220501.TritonModelJobInputResponse | outputs.machinelearningservices.v20220501.UriFileJobInputResponse | outputs.machinelearningservices.v20220501.UriFolderJobInputResponse};
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * Enum to determine the type of job.
     * Expected value is 'Sweep'.
     */
    jobType: "Sweep";
    /**
     * Sweep Job limit.
     */
    limits?: outputs.machinelearningservices.v20220501.SweepJobLimitsResponse;
    /**
     * [Required] Optimization objective.
     */
    objective: outputs.machinelearningservices.v20220501.ObjectiveResponse;
    /**
     * Mapping of output data bindings used in the job.
     */
    outputs?: {[key: string]: outputs.machinelearningservices.v20220501.CustomModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLFlowModelJobOutputResponse | outputs.machinelearningservices.v20220501.MLTableJobOutputResponse | outputs.machinelearningservices.v20220501.TritonModelJobOutputResponse | outputs.machinelearningservices.v20220501.UriFileJobOutputResponse | outputs.machinelearningservices.v20220501.UriFolderJobOutputResponse};
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * [Required] The hyperparameter sampling algorithm
     */
    samplingAlgorithm: outputs.machinelearningservices.v20220501.BayesianSamplingAlgorithmResponse | outputs.machinelearningservices.v20220501.GridSamplingAlgorithmResponse | outputs.machinelearningservices.v20220501.RandomSamplingAlgorithmResponse;
    /**
     * [Required] A dictionary containing each parameter and its distribution. The dictionary key is the name of the parameter
     */
    searchSpace: any;
    /**
     * List of JobEndpoints.
     * For local jobs, a job endpoint will have an endpoint value of FileStreamObject.
     */
    services?: {[key: string]: outputs.machinelearningservices.v20220501.JobServiceResponse};
    /**
     * Status of the job.
     */
    status: string;
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
    /**
     * [Required] Trial component definition.
     */
    trial: outputs.machinelearningservices.v20220501.TrialComponentResponse;
}
/**
 * sweepJobResponseProvideDefaults sets the appropriate defaults for SweepJobResponse
 */
export function sweepJobResponseProvideDefaults(val: SweepJobResponse): SweepJobResponse {
    return {
        ...val,
        experimentName: (val.experimentName) ?? "Default",
        isArchived: (val.isArchived) ?? false,
        trial: outputs.machinelearningservices.v20220501.trialComponentResponseProvideDefaults(val.trial),
    };
}

/**
 * A SynapseSpark compute.
 */
export interface SynapseSparkResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'SynapseSpark'.
     */
    computeType: "SynapseSpark";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    properties?: outputs.machinelearningservices.v20220501.SynapseSparkResponseProperties;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

export interface SynapseSparkResponseProperties {
    /**
     * Auto pause properties.
     */
    autoPauseProperties?: outputs.machinelearningservices.v20220501.AutoPausePropertiesResponse;
    /**
     * Auto scale properties.
     */
    autoScaleProperties?: outputs.machinelearningservices.v20220501.AutoScalePropertiesResponse;
    /**
     * The number of compute nodes currently assigned to the compute.
     */
    nodeCount?: number;
    /**
     * Node size.
     */
    nodeSize?: string;
    /**
     * Node size family.
     */
    nodeSizeFamily?: string;
    /**
     * Pool name.
     */
    poolName?: string;
    /**
     * Name of the resource group in which workspace is located.
     */
    resourceGroup?: string;
    /**
     * Spark version.
     */
    sparkVersion?: string;
    /**
     * Azure subscription identifier.
     */
    subscriptionId?: string;
    /**
     * Name of Azure Machine Learning workspace.
     */
    workspaceName?: string;
}

/**
 * Metadata pertaining to creation and last modification of the resource.
 */
export interface SystemDataResponse {
    /**
     * The timestamp of resource creation (UTC).
     */
    createdAt?: string;
    /**
     * The identity that created the resource.
     */
    createdBy?: string;
    /**
     * The type of identity that created the resource.
     */
    createdByType?: string;
    /**
     * The timestamp of resource last modification (UTC)
     */
    lastModifiedAt?: string;
    /**
     * The identity that last modified the resource.
     */
    lastModifiedBy?: string;
    /**
     * The type of identity that last modified the resource.
     */
    lastModifiedByType?: string;
}

/**
 * A system service running on a compute.
 */
export interface SystemServiceResponse {
    /**
     * Public IP address
     */
    publicIpAddress: string;
    /**
     * The type of this system service.
     */
    systemServiceType: string;
    /**
     * The version for this type.
     */
    version: string;
}

export interface TargetUtilizationScaleSettingsResponse {
    /**
     * The maximum number of instances that the deployment can scale to. The quota will be reserved for max_instances.
     */
    maxInstances?: number;
    /**
     * The minimum number of instances to always be present.
     */
    minInstances?: number;
    /**
     * The polling interval in ISO 8691 format. Only supports duration with precision as low as Seconds.
     */
    pollingInterval?: string;
    /**
     *
     * Expected value is 'TargetUtilization'.
     */
    scaleType: "TargetUtilization";
    /**
     * Target CPU usage for the autoscaler.
     */
    targetUtilizationPercentage?: number;
}
/**
 * targetUtilizationScaleSettingsResponseProvideDefaults sets the appropriate defaults for TargetUtilizationScaleSettingsResponse
 */
export function targetUtilizationScaleSettingsResponseProvideDefaults(val: TargetUtilizationScaleSettingsResponse): TargetUtilizationScaleSettingsResponse {
    return {
        ...val,
        maxInstances: (val.maxInstances) ?? 1,
        minInstances: (val.minInstances) ?? 1,
        pollingInterval: (val.pollingInterval) ?? "PT1S",
        targetUtilizationPercentage: (val.targetUtilizationPercentage) ?? 70,
    };
}

/**
 * TensorFlow distribution configuration.
 */
export interface TensorFlowResponse {
    /**
     * Enum to determine the job distribution type.
     * Expected value is 'TensorFlow'.
     */
    distributionType: "TensorFlow";
    /**
     * Number of parameter server tasks.
     */
    parameterServerCount?: number;
    /**
     * Number of workers. If not specified, will default to the instance count.
     */
    workerCount?: number;
}
/**
 * tensorFlowResponseProvideDefaults sets the appropriate defaults for TensorFlowResponse
 */
export function tensorFlowResponseProvideDefaults(val: TensorFlowResponse): TensorFlowResponse {
    return {
        ...val,
        parameterServerCount: (val.parameterServerCount) ?? 0,
    };
}

/**
 * Trial component definition.
 */
export interface TrialComponentResponse {
    /**
     * ARM resource ID of the code asset.
     */
    codeId?: string;
    /**
     * [Required] The command to execute on startup of the job. eg. "python train.py"
     */
    command: string;
    /**
     * Distribution configuration of the job. If set, this should be one of Mpi, Tensorflow, PyTorch, or null.
     */
    distribution?: outputs.machinelearningservices.v20220501.MpiResponse | outputs.machinelearningservices.v20220501.PyTorchResponse | outputs.machinelearningservices.v20220501.TensorFlowResponse;
    /**
     * [Required] The ARM resource ID of the Environment specification for the job.
     */
    environmentId: string;
    /**
     * Environment variables included in the job.
     */
    environmentVariables?: {[key: string]: string};
    /**
     * Compute Resource configuration for the job.
     */
    resources?: outputs.machinelearningservices.v20220501.ResourceConfigurationResponse;
}
/**
 * trialComponentResponseProvideDefaults sets the appropriate defaults for TrialComponentResponse
 */
export function trialComponentResponseProvideDefaults(val: TrialComponentResponse): TrialComponentResponse {
    return {
        ...val,
        resources: (val.resources ? outputs.machinelearningservices.v20220501.resourceConfigurationResponseProvideDefaults(val.resources) : undefined),
    };
}

export interface TritonModelJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'triton_model'.
     */
    jobInputType: "triton_model";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * tritonModelJobInputResponseProvideDefaults sets the appropriate defaults for TritonModelJobInputResponse
 */
export function tritonModelJobInputResponseProvideDefaults(val: TritonModelJobInputResponse): TritonModelJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface TritonModelJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'triton_model'.
     */
    jobOutputType: "triton_model";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * tritonModelJobOutputResponseProvideDefaults sets the appropriate defaults for TritonModelJobOutputResponse
 */
export function tritonModelJobOutputResponseProvideDefaults(val: TritonModelJobOutputResponse): TritonModelJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

/**
 * Defines an early termination policy that cancels a given percentage of runs at each evaluation interval.
 */
export interface TruncationSelectionPolicyResponse {
    /**
     * Number of intervals by which to delay the first evaluation.
     */
    delayEvaluation?: number;
    /**
     * Interval (number of runs) between policy evaluations.
     */
    evaluationInterval?: number;
    /**
     *
     * Expected value is 'TruncationSelection'.
     */
    policyType: "TruncationSelection";
    /**
     * The percentage of runs to cancel at each evaluation interval.
     */
    truncationPercentage?: number;
}
/**
 * truncationSelectionPolicyResponseProvideDefaults sets the appropriate defaults for TruncationSelectionPolicyResponse
 */
export function truncationSelectionPolicyResponseProvideDefaults(val: TruncationSelectionPolicyResponse): TruncationSelectionPolicyResponse {
    return {
        ...val,
        delayEvaluation: (val.delayEvaluation) ?? 0,
        evaluationInterval: (val.evaluationInterval) ?? 0,
        truncationPercentage: (val.truncationPercentage) ?? 0,
    };
}

/**
 * uri-file data version entity
 */
export interface UriFileDataVersionResponse {
    /**
     * Enum to determine the type of data.
     * Expected value is 'uri_file'.
     */
    dataType: "uri_file";
    /**
     * [Required] Uri of the data. Usage/meaning depends on Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20220501.Assets.DataVersionBase.DataType
     */
    dataUri: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * uriFileDataVersionResponseProvideDefaults sets the appropriate defaults for UriFileDataVersionResponse
 */
export function uriFileDataVersionResponseProvideDefaults(val: UriFileDataVersionResponse): UriFileDataVersionResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

export interface UriFileJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'uri_file'.
     */
    jobInputType: "uri_file";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * uriFileJobInputResponseProvideDefaults sets the appropriate defaults for UriFileJobInputResponse
 */
export function uriFileJobInputResponseProvideDefaults(val: UriFileJobInputResponse): UriFileJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface UriFileJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'uri_file'.
     */
    jobOutputType: "uri_file";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * uriFileJobOutputResponseProvideDefaults sets the appropriate defaults for UriFileJobOutputResponse
 */
export function uriFileJobOutputResponseProvideDefaults(val: UriFileJobOutputResponse): UriFileJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

/**
 * uri-folder data version entity
 */
export interface UriFolderDataVersionResponse {
    /**
     * Enum to determine the type of data.
     * Expected value is 'uri_folder'.
     */
    dataType: "uri_folder";
    /**
     * [Required] Uri of the data. Usage/meaning depends on Microsoft.MachineLearning.ManagementFrontEnd.Contracts.V20220501.Assets.DataVersionBase.DataType
     */
    dataUri: string;
    /**
     * The asset description text.
     */
    description?: string;
    /**
     * If the name version are system generated (anonymous registration).
     */
    isAnonymous?: boolean;
    /**
     * Is the asset archived?
     */
    isArchived?: boolean;
    /**
     * The asset property dictionary.
     */
    properties?: {[key: string]: string};
    /**
     * Tag dictionary. Tags can be added, removed, and updated.
     */
    tags?: {[key: string]: string};
}
/**
 * uriFolderDataVersionResponseProvideDefaults sets the appropriate defaults for UriFolderDataVersionResponse
 */
export function uriFolderDataVersionResponseProvideDefaults(val: UriFolderDataVersionResponse): UriFolderDataVersionResponse {
    return {
        ...val,
        isAnonymous: (val.isAnonymous) ?? false,
        isArchived: (val.isArchived) ?? false,
    };
}

export interface UriFolderJobInputResponse {
    /**
     * Description for the input.
     */
    description?: string;
    /**
     * Enum to determine the Job Input Type.
     * Expected value is 'uri_folder'.
     */
    jobInputType: "uri_folder";
    /**
     * Input Asset Delivery Mode.
     */
    mode?: string;
    /**
     * [Required] Input Asset URI.
     */
    uri: string;
}
/**
 * uriFolderJobInputResponseProvideDefaults sets the appropriate defaults for UriFolderJobInputResponse
 */
export function uriFolderJobInputResponseProvideDefaults(val: UriFolderJobInputResponse): UriFolderJobInputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadOnlyMount",
    };
}

export interface UriFolderJobOutputResponse {
    /**
     * Description for the output.
     */
    description?: string;
    /**
     * Enum to determine the Job Output Type.
     * Expected value is 'uri_folder'.
     */
    jobOutputType: "uri_folder";
    /**
     * Output Asset Delivery Mode.
     */
    mode?: string;
    /**
     * Output Asset URI.
     */
    uri?: string;
}
/**
 * uriFolderJobOutputResponseProvideDefaults sets the appropriate defaults for UriFolderJobOutputResponse
 */
export function uriFolderJobOutputResponseProvideDefaults(val: UriFolderJobOutputResponse): UriFolderJobOutputResponse {
    return {
        ...val,
        mode: (val.mode) ?? "ReadWriteMount",
    };
}

/**
 * Settings for user account that gets created on each on the nodes of a compute.
 */
export interface UserAccountCredentialsResponse {
    /**
     * Name of the administrator user account which can be used to SSH to nodes.
     */
    adminUserName: string;
    /**
     * Password of the administrator user account.
     */
    adminUserPassword?: string;
    /**
     * SSH public key of the administrator user account.
     */
    adminUserSshPublicKey?: string;
}

/**
 * User assigned identity properties
 */
export interface UserAssignedIdentityResponse {
    /**
     * The client ID of the assigned identity.
     */
    clientId: string;
    /**
     * The principal ID of the assigned identity.
     */
    principalId: string;
}

/**
 * User identity configuration.
 */
export interface UserIdentityResponse {
    /**
     * Enum to determine identity framework.
     * Expected value is 'UserIdentity'.
     */
    identityType: "UserIdentity";
}

export interface UsernamePasswordAuthTypeWorkspaceConnectionPropertiesResponse {
    /**
     * Authentication type of the connection target
     * Expected value is 'UsernamePassword'.
     */
    authType: "UsernamePassword";
    /**
     * Category of the connection
     */
    category?: string;
    credentials?: outputs.machinelearningservices.v20220501.WorkspaceConnectionUsernamePasswordResponse;
    target?: string;
    /**
     * Value details of the workspace connection.
     */
    value?: string;
    /**
     * format for the workspace connection value
     */
    valueFormat?: string;
}

/**
 * Virtual Machine image for Windows AML Compute
 */
export interface VirtualMachineImageResponse {
    /**
     * Virtual Machine image path
     */
    id: string;
}

/**
 * A Machine Learning compute based on Azure Virtual Machines.
 */
export interface VirtualMachineResponse {
    /**
     * Location for the underlying compute
     */
    computeLocation?: string;
    /**
     * The type of compute
     * Expected value is 'VirtualMachine'.
     */
    computeType: "VirtualMachine";
    /**
     * The time at which the compute was created.
     */
    createdOn: string;
    /**
     * The description of the Machine Learning compute.
     */
    description?: string;
    /**
     * Opt-out of local authentication and ensure customers can use only MSI and AAD exclusively for authentication.
     */
    disableLocalAuth?: boolean;
    /**
     * Indicating whether the compute was provisioned by user and brought from outside if true, or machine learning service provisioned it if false.
     */
    isAttachedCompute: boolean;
    /**
     * The time at which the compute was last modified.
     */
    modifiedOn: string;
    properties?: outputs.machinelearningservices.v20220501.VirtualMachineSchemaResponseProperties;
    /**
     * Errors during provisioning
     */
    provisioningErrors: outputs.machinelearningservices.v20220501.ErrorResponseResponse[];
    /**
     * The provision state of the cluster. Valid values are Unknown, Updating, Provisioning, Succeeded, and Failed.
     */
    provisioningState: string;
    /**
     * ARM resource id of the underlying compute
     */
    resourceId?: string;
}

export interface VirtualMachineSchemaResponseProperties {
    /**
     * Public IP address of the virtual machine.
     */
    address?: string;
    /**
     * Admin credentials for virtual machine
     */
    administratorAccount?: outputs.machinelearningservices.v20220501.VirtualMachineSshCredentialsResponse;
    /**
     * Indicates whether this compute will be used for running notebooks.
     */
    isNotebookInstanceCompute?: boolean;
    /**
     * Notebook server port open for ssh connections.
     */
    notebookServerPort?: number;
    /**
     * Port open for ssh connections.
     */
    sshPort?: number;
    /**
     * Virtual Machine size
     */
    virtualMachineSize?: string;
}

/**
 * Admin credentials for virtual machine
 */
export interface VirtualMachineSshCredentialsResponse {
    /**
     * Password of admin account
     */
    password?: string;
    /**
     * Private key data
     */
    privateKeyData?: string;
    /**
     * Public key data
     */
    publicKeyData?: string;
    /**
     * Username of admin account
     */
    username?: string;
}

export interface WorkspaceConnectionManagedIdentityResponse {
    clientId?: string;
    resourceId?: string;
}

export interface WorkspaceConnectionPersonalAccessTokenResponse {
    pat?: string;
}

export interface WorkspaceConnectionSharedAccessSignatureResponse {
    sas?: string;
}

export interface WorkspaceConnectionUsernamePasswordResponse {
    password?: string;
    username?: string;
}

