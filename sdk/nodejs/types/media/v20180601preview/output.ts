// *** WARNING: this file was generated by the Pulumi SDK Generator. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../../../types/input";
import * as outputs from "../../../types/output";
import * as enums from "../../../types/enums";
import * as utilities from "../../../utilities";

/**
 * Describes Advanced Audio Codec (AAC) audio encoding settings.
 */
export interface AacAudioResponse {
    /**
     * The bitrate, in bits per second, of the output encoded audio.
     */
    bitrate?: number;
    /**
     * The number of channels in the audio.
     */
    channels?: number;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.AacAudio'.
     */
    odataType: "#Microsoft.Media.AacAudio";
    /**
     * The encoding profile to be used when encoding audio with AAC.
     */
    profile?: string;
    /**
     * The sampling rate to use for encoding in hertz.
     */
    samplingRate?: number;
}

/**
 * Akamai access control
 */
export interface AkamaiAccessControlResponse {
    /**
     * authentication key list
     */
    akamaiSignatureHeaderAuthenticationKeyList?: outputs.media.v20180601preview.AkamaiSignatureHeaderAuthenticationKeyResponse[];
}

/**
 * Akamai Signature Header authentication key.
 */
export interface AkamaiSignatureHeaderAuthenticationKeyResponse {
    /**
     * authentication key
     */
    base64Key?: string;
    /**
     * The exact time the authentication key.
     */
    expiration?: string;
    /**
     * identifier of the key
     */
    identifier?: string;
}

/**
 * The Audio Analyzer preset applies a pre-defined set of AI-based analysis operations, including speech transcription. Currently, the preset supports processing of content with a single audio track.
 */
export interface AudioAnalyzerPresetResponse {
    /**
     * The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). The list of supported languages are, 'en-US', 'en-GB', 'es-ES', 'es-MX', 'fr-FR', 'it-IT', 'ja-JP', 'pt-BR', 'zh-CN'.
     */
    audioLanguage?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.AudioAnalyzerPreset'.
     */
    odataType: "#Microsoft.Media.AudioAnalyzerPreset";
}

/**
 * Describes the properties of an audio overlay.
 */
export interface AudioOverlayResponse {
    /**
     * The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0.
     */
    audioGainLevel?: number;
    /**
     * The position in the input video at which the overlay ends. The value should be in ISO 8601 duration format. For example, PT30S to end the overlay at 30 seconds in to the input video. If not specified the overlay will be applied until the end of the input video if inputLoop is true. Else, if inputLoop is false, then overlay will last as long as the duration of the overlay media.
     */
    end?: string;
    /**
     * The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S).
     */
    fadeInDuration?: string;
    /**
     * The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S).
     */
    fadeOutDuration?: string;
    /**
     * The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG or PNG formats, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats.
     */
    inputLabel?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.AudioOverlay'.
     */
    odataType: "#Microsoft.Media.AudioOverlay";
    /**
     * The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds in to the input video. If not specified the overlay starts from the beginning of the input video.
     */
    start?: string;
}

/**
 * Defines the common properties for all audio codecs.
 */
export interface AudioResponse {
    /**
     * The bitrate, in bits per second, of the output encoded audio.
     */
    bitrate?: number;
    /**
     * The number of channels in the audio.
     */
    channels?: number;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.Audio'.
     */
    odataType: "#Microsoft.Media.Audio";
    /**
     * The sampling rate to use for encoding in hertz.
     */
    samplingRate?: number;
}

/**
 * Describes a built-in preset for encoding the input video with the Standard Encoder.
 */
export interface BuiltInStandardEncoderPresetResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.BuiltInStandardEncoderPreset'.
     */
    odataType: "#Microsoft.Media.BuiltInStandardEncoderPreset";
    /**
     * The built-in preset to be used for encoding videos.
     */
    presetName: string;
}

/**
 * Class to specify DRM configurations of CommonEncryptionCbcs scheme in Streaming Policy
 */
export interface CbcsDrmConfigurationResponse {
    /**
     * FairPlay configurations
     */
    fairPlay?: outputs.media.v20180601preview.StreamingPolicyFairPlayConfigurationResponse;
    /**
     * PlayReady configurations
     */
    playReady?: outputs.media.v20180601preview.StreamingPolicyPlayReadyConfigurationResponse;
    /**
     * Widevine configurations
     */
    widevine?: outputs.media.v20180601preview.StreamingPolicyWidevineConfigurationResponse;
}

/**
 * Class to specify DRM configurations of CommonEncryptionCenc scheme in Streaming Policy
 */
export interface CencDrmConfigurationResponse {
    /**
     * PlayReady configurations
     */
    playReady?: outputs.media.v20180601preview.StreamingPolicyPlayReadyConfigurationResponse;
    /**
     * Widevine configurations
     */
    widevine?: outputs.media.v20180601preview.StreamingPolicyWidevineConfigurationResponse;
}

/**
 * Class for CommonEncryptionCbcs encryption scheme
 */
export interface CommonEncryptionCbcsResponse {
    /**
     * Representing which tracks should not be encrypted
     */
    clearTracks?: outputs.media.v20180601preview.TrackSelectionResponse[];
    /**
     * Representing default content key for each encryption scheme and separate content keys for specific tracks
     */
    contentKeys?: outputs.media.v20180601preview.StreamingPolicyContentKeysResponse;
    /**
     * Configuration of DRMs for current encryption scheme
     */
    drm?: outputs.media.v20180601preview.CbcsDrmConfigurationResponse;
    /**
     * Representing supported protocols
     */
    enabledProtocols?: outputs.media.v20180601preview.EnabledProtocolsResponse;
}

/**
 * Class for envelope encryption scheme
 */
export interface CommonEncryptionCencResponse {
    /**
     * Representing which tracks should not be encrypted
     */
    clearTracks?: outputs.media.v20180601preview.TrackSelectionResponse[];
    /**
     * Representing default content key for each encryption scheme and separate content keys for specific tracks
     */
    contentKeys?: outputs.media.v20180601preview.StreamingPolicyContentKeysResponse;
    /**
     * Configuration of DRMs for CommonEncryptionCenc encryption scheme
     */
    drm?: outputs.media.v20180601preview.CencDrmConfigurationResponse;
    /**
     * Representing supported protocols
     */
    enabledProtocols?: outputs.media.v20180601preview.EnabledProtocolsResponse;
}

/**
 * Represents a configuration for non-DRM keys.
 */
export interface ContentKeyPolicyClearKeyConfigurationResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyClearKeyConfiguration'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyClearKeyConfiguration";
}

/**
 * Specifies a configuration for FairPlay licenses.
 */
export interface ContentKeyPolicyFairPlayConfigurationResponse {
    /**
     * The key that must be used as FairPlay ASk.
     */
    ask: string;
    /**
     * The Base64 representation of FairPlay certificate in PKCS 12 (pfx) format (including private key).
     */
    fairPlayPfx: string;
    /**
     * The password encrypting FairPlay certificate in PKCS 12 (pfx) format.
     */
    fairPlayPfxPassword: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyFairPlayConfiguration'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyFairPlayConfiguration";
    /**
     * The rental and lease key type.
     */
    rentalAndLeaseKeyType: string;
    /**
     * The rental duration. Must be greater than or equal to 0.
     */
    rentalDuration: number;
}

/**
 * Represents an open restriction. License or key will be delivered on every request.
 */
export interface ContentKeyPolicyOpenRestrictionResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyOpenRestriction'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyOpenRestriction";
}

/**
 * Represents a policy option.
 */
export interface ContentKeyPolicyOptionResponse {
    /**
     * The key delivery configuration.
     */
    configuration: outputs.media.v20180601preview.ContentKeyPolicyClearKeyConfigurationResponse | outputs.media.v20180601preview.ContentKeyPolicyFairPlayConfigurationResponse | outputs.media.v20180601preview.ContentKeyPolicyPlayReadyConfigurationResponse | outputs.media.v20180601preview.ContentKeyPolicyUnknownConfigurationResponse | outputs.media.v20180601preview.ContentKeyPolicyWidevineConfigurationResponse;
    /**
     * The Policy Option description.
     */
    name?: string;
    /**
     * The legacy Policy Option ID.
     */
    policyOptionId: string;
    /**
     * The requirements that must be met to deliver keys with this configuration
     */
    restriction: outputs.media.v20180601preview.ContentKeyPolicyOpenRestrictionResponse | outputs.media.v20180601preview.ContentKeyPolicyTokenRestrictionResponse | outputs.media.v20180601preview.ContentKeyPolicyUnknownRestrictionResponse;
}

/**
 * Specifies a configuration for PlayReady licenses.
 */
export interface ContentKeyPolicyPlayReadyConfigurationResponse {
    /**
     * The PlayReady licenses.
     */
    licenses: outputs.media.v20180601preview.ContentKeyPolicyPlayReadyLicenseResponse[];
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyPlayReadyConfiguration'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyPlayReadyConfiguration";
    /**
     * The custom response data.
     */
    responseCustomData?: string;
}

/**
 * Specifies that the content key ID is in the PlayReady header.
 */
export interface ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeaderResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeader";
}

/**
 * Specifies that the content key ID is specified in the PlayReady configuration.
 */
export interface ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifierResponse {
    /**
     * The content key ID.
     */
    keyId: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifier";
}

/**
 * Configures the Explicit Analog Television Output Restriction control bits. For further details see the PlayReady Compliance Rules.
 */
export interface ContentKeyPolicyPlayReadyExplicitAnalogTelevisionRestrictionResponse {
    /**
     * Indicates whether this restriction is enforced on a Best Effort basis.
     */
    bestEffort: boolean;
    /**
     * Configures the restriction control bits. Must be between 0 and 3 inclusive.
     */
    configurationData: number;
}

/**
 * The PlayReady license
 */
export interface ContentKeyPolicyPlayReadyLicenseResponse {
    /**
     * A flag indicating whether test devices can use the license.
     */
    allowTestDevices: boolean;
    /**
     * The begin date of license
     */
    beginDate?: string;
    /**
     * The content key location.
     */
    contentKeyLocation: outputs.media.v20180601preview.ContentKeyPolicyPlayReadyContentEncryptionKeyFromHeaderResponse | outputs.media.v20180601preview.ContentKeyPolicyPlayReadyContentEncryptionKeyFromKeyIdentifierResponse;
    /**
     * The PlayReady content type.
     */
    contentType: string;
    /**
     * The expiration date of license.
     */
    expirationDate?: string;
    /**
     * The grace period of license.
     */
    gracePeriod?: string;
    /**
     * The license type.
     */
    licenseType: string;
    /**
     * The license PlayRight
     */
    playRight?: outputs.media.v20180601preview.ContentKeyPolicyPlayReadyPlayRightResponse;
    /**
     * The relative begin date of license.
     */
    relativeBeginDate?: string;
    /**
     * The relative expiration date of license.
     */
    relativeExpirationDate?: string;
}

/**
 * Configures the Play Right in the PlayReady license.
 */
export interface ContentKeyPolicyPlayReadyPlayRightResponse {
    /**
     * Configures Automatic Gain Control (AGC) and Color Stripe in the license. Must be between 0 and 3 inclusive.
     */
    agcAndColorStripeRestriction?: number;
    /**
     * Configures Unknown output handling settings of the license.
     */
    allowPassingVideoContentToUnknownOutput: string;
    /**
     * Specifies the output protection level for compressed digital audio.
     */
    analogVideoOpl?: number;
    /**
     * Specifies the output protection level for compressed digital audio.
     */
    compressedDigitalAudioOpl?: number;
    /**
     * Specifies the output protection level for compressed digital video.
     */
    compressedDigitalVideoOpl?: number;
    /**
     * Enables the Image Constraint For Analog Component Video Restriction in the license.
     */
    digitalVideoOnlyContentRestriction: boolean;
    /**
     * Configures the Explicit Analog Television Output Restriction in the license. Configuration data must be between 0 and 3 inclusive.
     */
    explicitAnalogTelevisionOutputRestriction?: outputs.media.v20180601preview.ContentKeyPolicyPlayReadyExplicitAnalogTelevisionRestrictionResponse;
    /**
     * The amount of time that the license is valid after the license is first used to play content.
     */
    firstPlayExpiration?: string;
    /**
     * Enables the Image Constraint For Analog Component Video Restriction in the license.
     */
    imageConstraintForAnalogComponentVideoRestriction: boolean;
    /**
     * Enables the Image Constraint For Analog Component Video Restriction in the license.
     */
    imageConstraintForAnalogComputerMonitorRestriction: boolean;
    /**
     * Configures the Serial Copy Management System (SCMS) in the license. Must be between 0 and 3 inclusive.
     */
    scmsRestriction?: number;
    /**
     * Specifies the output protection level for uncompressed digital audio.
     */
    uncompressedDigitalAudioOpl?: number;
    /**
     * Specifies the output protection level for uncompressed digital video.
     */
    uncompressedDigitalVideoOpl?: number;
}

/**
 * Specifies a RSA key for token validation
 */
export interface ContentKeyPolicyRsaTokenKeyResponse {
    /**
     * The RSA Parameter exponent
     */
    exponent: string;
    /**
     * The RSA Parameter modulus
     */
    modulus: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyRsaTokenKey'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyRsaTokenKey";
}

/**
 * Specifies a symmetric key for token validation.
 */
export interface ContentKeyPolicySymmetricTokenKeyResponse {
    /**
     * The key value of the key
     */
    keyValue: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicySymmetricTokenKey'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicySymmetricTokenKey";
}

/**
 * Represents a token claim.
 */
export interface ContentKeyPolicyTokenClaimResponse {
    /**
     * Token claim type.
     */
    claimType?: string;
    /**
     * Token claim value.
     */
    claimValue?: string;
}

/**
 * Represents a token restriction. Provided token must match these requirements for successful license or key delivery.
 */
export interface ContentKeyPolicyTokenRestrictionResponse {
    /**
     * A list of alternative verification keys.
     */
    alternateVerificationKeys?: (outputs.media.v20180601preview.ContentKeyPolicyRsaTokenKeyResponse | outputs.media.v20180601preview.ContentKeyPolicySymmetricTokenKeyResponse | outputs.media.v20180601preview.ContentKeyPolicyX509CertificateTokenKeyResponse)[];
    /**
     * The audience for the token.
     */
    audience: string;
    /**
     * The token issuer.
     */
    issuer: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyTokenRestriction'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyTokenRestriction";
    /**
     * The OpenID connect discovery document.
     */
    openIdConnectDiscoveryDocument?: string;
    /**
     * The primary verification key.
     */
    primaryVerificationKey: outputs.media.v20180601preview.ContentKeyPolicyRsaTokenKeyResponse | outputs.media.v20180601preview.ContentKeyPolicySymmetricTokenKeyResponse | outputs.media.v20180601preview.ContentKeyPolicyX509CertificateTokenKeyResponse;
    /**
     * A list of required token claims.
     */
    requiredClaims?: outputs.media.v20180601preview.ContentKeyPolicyTokenClaimResponse[];
    /**
     * The type of token.
     */
    restrictionTokenType: string;
}

/**
 * Represents a ContentKeyPolicyConfiguration that is unavailable in the current API version.
 */
export interface ContentKeyPolicyUnknownConfigurationResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyUnknownConfiguration'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyUnknownConfiguration";
}

/**
 * Represents a ContentKeyPolicyRestriction that is unavailable in the current API version.
 */
export interface ContentKeyPolicyUnknownRestrictionResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyUnknownRestriction'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyUnknownRestriction";
}

/**
 * Specifies a configuration for Widevine licenses.
 */
export interface ContentKeyPolicyWidevineConfigurationResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyWidevineConfiguration'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyWidevineConfiguration";
    /**
     * The Widevine template.
     */
    widevineTemplate: string;
}

/**
 * Specifies a certificate for token validation.
 */
export interface ContentKeyPolicyX509CertificateTokenKeyResponse {
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ContentKeyPolicyX509CertificateTokenKey'.
     */
    odataType: "#Microsoft.Media.ContentKeyPolicyX509CertificateTokenKey";
    /**
     * The raw data field of a certificate in PKCS 12 format (X509Certificate2 in .NET)
     */
    rawBody: string;
}

/**
 * A codec flag, which tells the encoder to copy the input audio bitstream.
 */
export interface CopyAudioResponse {
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.CopyAudio'.
     */
    odataType: "#Microsoft.Media.CopyAudio";
}

/**
 * A codec flag, which tells the encoder to copy the input video bitstream without re-encoding.
 */
export interface CopyVideoResponse {
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.CopyVideo'.
     */
    odataType: "#Microsoft.Media.CopyVideo";
}

/**
 * The client access policy.
 */
export interface CrossSiteAccessPoliciesResponse {
    /**
     * The content of clientaccesspolicy.xml used by Silverlight.
     */
    clientAccessPolicy?: string;
    /**
     * The content of crossdomain.xml used by Silverlight.
     */
    crossDomainPolicy?: string;
}

/**
 * Class to specify properties of default content key for each encryption scheme
 */
export interface DefaultKeyResponse {
    /**
     * Label can be used to specify Content Key when creating a Streaming Locator
     */
    label?: string;
    /**
     * Policy used by Default Key
     */
    policyName?: string;
}

/**
 * Describes the de-interlacing settings.
 */
export interface DeinterlaceResponse {
    /**
     * The deinterlacing mode. Defaults to AutoPixelAdaptive.
     */
    mode?: string;
    /**
     * The field parity for de-interlacing, defaults to Auto.
     */
    parity?: string;
}

/**
 * Class to specify which protocols are enabled
 */
export interface EnabledProtocolsResponse {
    /**
     * Enable DASH protocol or not
     */
    dash: boolean;
    /**
     * Enable Download protocol or not
     */
    download: boolean;
    /**
     * Enable HLS protocol or not
     */
    hls: boolean;
    /**
     * Enable SmoothStreaming protocol or not
     */
    smoothStreaming: boolean;
}

/**
 * Class for EnvelopeEncryption encryption scheme
 */
export interface EnvelopeEncryptionResponse {
    /**
     * Representing which tracks should not be encrypted
     */
    clearTracks?: outputs.media.v20180601preview.TrackSelectionResponse[];
    /**
     * Representing default content key for each encryption scheme and separate content keys for specific tracks
     */
    contentKeys?: outputs.media.v20180601preview.StreamingPolicyContentKeysResponse;
    /**
     * KeyAcquisitionUrlTemplate is used to point to user specified service to delivery content keys
     */
    customKeyAcquisitionUrlTemplate?: string;
    /**
     * Representing supported protocols
     */
    enabledProtocols?: outputs.media.v20180601preview.EnabledProtocolsResponse;
}

/**
 * Describes all the filtering operations, such as de-interlacing, rotation etc. that are to be applied to the input media before encoding.
 */
export interface FiltersResponse {
    /**
     * The parameters for the rectangular window with which to crop the input video.
     */
    crop?: outputs.media.v20180601preview.RectangleResponse;
    /**
     * The de-interlacing settings.
     */
    deinterlace?: outputs.media.v20180601preview.DeinterlaceResponse;
    /**
     * The properties of overlays to be applied to the input video. These could be audio, image or video overlays.
     */
    overlays?: (outputs.media.v20180601preview.AudioOverlayResponse | outputs.media.v20180601preview.VideoOverlayResponse)[];
    /**
     * The rotation, if any, to be applied to the input video, before it is encoded. Default is Auto
     */
    rotation?: string;
}

/**
 * Describes the settings to be used when encoding the input video into a desired output bitrate layer with the H.264 video codec.
 */
export interface H264LayerResponse {
    /**
     * Whether or not adaptive B-frames are to be used when encoding this layer. If not specified, the encoder will turn it on whenever the video profile permits its use.
     */
    adaptiveBFrame?: boolean;
    /**
     * The number of B-frames to be used when encoding this layer.  If not specified, the encoder chooses an appropriate number based on the video profile and level.
     */
    bFrames?: number;
    /**
     * The average bitrate in bits per second at which to encode the input video when generating this layer. This is a required field.
     */
    bitrate?: number;
    /**
     * The VBV buffer window length. The value should be in ISO 8601 format. The value should be in the range [0.1-100] seconds. The default is 5 seconds (for example, PT5S).
     */
    bufferWindow?: string;
    /**
     * The entropy mode to be used for this layer. If not specified, the encoder chooses the mode that is appropriate for the profile and level.
     */
    entropyMode?: string;
    /**
     * The frame rate (in frames per second) at which to encode this layer. The value can be in the form of M/N where M and N are integers (For example, 30000/1001), or in the form of a number (For example, 30, or 29.97). The encoder enforces constraints on allowed frame rates based on the profile and level. If it is not specified, the encoder will use the same frame rate as the input video.
     */
    frameRate?: string;
    /**
     * The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
     */
    height?: string;
    /**
     * The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
     */
    label?: string;
    /**
     * Which level of the H.264 standard should be used when encoding this layer. The value can be Auto, or a number that matches the H.264 profile. If not specified, the default is Auto, which lets the encoder choose the Level that is appropriate for this layer.
     */
    level?: string;
    /**
     * The maximum bitrate (in bits per second), at which the VBV buffer should be assumed to refill. If not specified, defaults to the same value as bitrate.
     */
    maxBitrate?: number;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.H264Layer'.
     */
    odataType: "#Microsoft.Media.H264Layer";
    /**
     * Which profile of the H.264 standard should be used when encoding this layer. Default is Auto.
     */
    profile?: string;
    /**
     * The number of reference frames to be used when encoding this layer. If not specified, the encoder determines an appropriate number based on the encoder complexity setting.
     */
    referenceFrames?: number;
    /**
     * The number of slices to be used when encoding this layer. If not specified, default is zero, which means that encoder will use a single slice for each frame.
     */
    slices?: number;
    /**
     * The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
     */
    width?: string;
}

/**
 * Describes all the properties for encoding a video with the H.264 codec.
 */
export interface H264VideoResponse {
    /**
     * Tells the encoder how to choose its encoding settings. The default value is Balanced.
     */
    complexity?: string;
    /**
     * The distance between two key frames, thereby defining a group of pictures (GOP). The value should be a non-zero integer in the range [1, 30] seconds, specified in ISO 8601 format. The default is 2 seconds (PT2S).
     */
    keyFrameInterval?: string;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The collection of output H.264 layers to be produced by the encoder.
     */
    layers?: outputs.media.v20180601preview.H264LayerResponse[];
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.H264Video'.
     */
    odataType: "#Microsoft.Media.H264Video";
    /**
     * Whether or not the encoder should insert key frames at scene changes. If not specified, the default is false. This flag should be set to true only when the encoder is being configured to produce a single output video.
     */
    sceneChangeDetection?: boolean;
    /**
     * The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
     */
    stretchMode?: string;
}

/**
 * The HLS configuration.
 */
export interface HlsResponse {
    /**
     * The amount of fragments per HTTP Live Streaming (HLS) segment.
     */
    fragmentsPerTsSegment?: number;
}

/**
 * The IP access control.
 */
export interface IPAccessControlResponse {
    /**
     * The IP allow list.
     */
    allow?: outputs.media.v20180601preview.IPRangeResponse[];
}

/**
 * The IP address range in the CIDR scheme.
 */
export interface IPRangeResponse {
    /**
     * The IP address.
     */
    address?: string;
    /**
     * The friendly name for the IP address range.
     */
    name?: string;
    /**
     * The subnet mask prefix length (see CIDR notation).
     */
    subnetPrefixLength?: number;
}

/**
 * Describes the properties for an output image file.
 */
export interface ImageFormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.ImageFormat'.
     */
    odataType: "#Microsoft.Media.ImageFormat";
}

/**
 * Describes the basic properties for generating thumbnails from the input video
 */
export interface ImageResponse {
    /**
     * The distance between two key frames, thereby defining a group of pictures (GOP). The value should be a non-zero integer in the range [1, 30] seconds, specified in ISO 8601 format. The default is 2 seconds (PT2S).
     */
    keyFrameInterval?: string;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.Image'.
     */
    odataType: "#Microsoft.Media.Image";
    /**
     * The position in the input video at which to stop generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT5M30S to stop at 5 minutes and 30 seconds), or a frame count (For example, 300 to stop at the 300th frame), or a relative value (For example, 100%).
     */
    range?: string;
    /**
     * The position in the input video from where to start generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT05S), or a frame count (For example, 10 for the 10th frame), or a relative value (For example, 1%). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video.
     */
    start?: string;
    /**
     * The intervals at which thumbnails are generated. The value can be in absolute timestamp (ISO 8601, e.g: PT05S for one image every 5 seconds), or a frame count (For example, 30 for every 30 frames), or a relative value (For example, 1%).
     */
    step?: string;
    /**
     * The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
     */
    stretchMode?: string;
}

/**
 * Details of JobOutput errors.
 */
export interface JobErrorDetailResponse {
    /**
     * Code describing the error detail.
     */
    code: string;
    /**
     * A human-readable representation of the error.
     */
    message: string;
}

/**
 * Details of JobOutput errors.
 */
export interface JobErrorResponse {
    /**
     * Helps with categorization of errors.
     */
    category: string;
    /**
     * Error code describing the error.
     */
    code: string;
    /**
     * An array of details about specific errors that led to this reported error.
     */
    details: outputs.media.v20180601preview.JobErrorDetailResponse[];
    /**
     * A human-readable language-dependent representation of the error.
     */
    message: string;
    /**
     * Indicates that it may be possible to retry the Job. If retry is unsuccessful, please contact Azure support via Azure Portal.
     */
    retry: string;
}

/**
 * Represents an Asset for input into a Job.
 */
export interface JobInputAssetResponse {
    /**
     * The name of the input Asset.
     */
    assetName: string;
    /**
     * List of files. Required for JobInputHttp.
     */
    files?: string[];
    /**
     * A label that is assigned to a JobInput, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JobInputAsset'.
     */
    odataType: "#Microsoft.Media.JobInputAsset";
}

/**
 * Represents input files for a Job.
 */
export interface JobInputClipResponse {
    /**
     * List of files. Required for JobInputHttp.
     */
    files?: string[];
    /**
     * A label that is assigned to a JobInput, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JobInputClip'.
     */
    odataType: "#Microsoft.Media.JobInputClip";
}

/**
 * Represents HTTPS job input.
 */
export interface JobInputHttpResponse {
    /**
     * Base URI for HTTPS job input. It will be concatenated with provided file names.   If no base uri is given, then the provided file list is assumed to be fully qualified uris.
     */
    baseUri?: string;
    /**
     * List of files. Required for JobInputHttp.
     */
    files?: string[];
    /**
     * A label that is assigned to a JobInput, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JobInputHttp'.
     */
    odataType: "#Microsoft.Media.JobInputHttp";
}

/**
 * Describes a list of inputs to a Job.
 */
export interface JobInputsResponse {
    /**
     * List of inputs to a Job.
     */
    inputs?: (outputs.media.v20180601preview.JobInputAssetResponse | outputs.media.v20180601preview.JobInputClipResponse | outputs.media.v20180601preview.JobInputHttpResponse | outputs.media.v20180601preview.JobInputsResponse)[];
    /**
     * A label that is assigned to a JobInput, that is used to satisfy a reference used in the Transform. For example, a Transform can be authored so as to take an image file with the label 'xyz' and apply it as an overlay onto the input video before it is encoded. When submitting a Job, exactly one of the JobInputs should be the image file, and it should have the label 'xyz'.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JobInputs'.
     */
    odataType: "#Microsoft.Media.JobInputs";
}

/**
 * Represents an Asset used as a JobOutput.
 */
export interface JobOutputAssetResponse {
    /**
     * The name of the output Asset.
     */
    assetName: string;
    /**
     * If the JobOutput is in the Error state, it contains the details of the error.
     */
    error: outputs.media.v20180601preview.JobErrorResponse;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JobOutputAsset'.
     */
    odataType: "#Microsoft.Media.JobOutputAsset";
    /**
     * If the JobOutput is in a Processing state, this contains the job completion percentage.  The value is an estimate and not intended to be used to predict job completion times. To determine if the JobOutput is complete, use the State property.
     */
    progress: number;
    /**
     * Describes the state of the JobOutput.
     */
    state: string;
}

/**
 * Describes the settings for producing JPEG thumbnails.
 */
export interface JpgFormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JpgFormat'.
     */
    odataType: "#Microsoft.Media.JpgFormat";
}

/**
 * Describes the properties for producing a series of JPEG images from the input video.
 */
export interface JpgImageResponse {
    /**
     * The distance between two key frames, thereby defining a group of pictures (GOP). The value should be a non-zero integer in the range [1, 30] seconds, specified in ISO 8601 format. The default is 2 seconds (PT2S).
     */
    keyFrameInterval?: string;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * A collection of output JPEG image layers to be produced by the encoder.
     */
    layers?: outputs.media.v20180601preview.JpgLayerResponse[];
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JpgImage'.
     */
    odataType: "#Microsoft.Media.JpgImage";
    /**
     * The position in the input video at which to stop generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT5M30S to stop at 5 minutes and 30 seconds), or a frame count (For example, 300 to stop at the 300th frame), or a relative value (For example, 100%).
     */
    range?: string;
    /**
     * The position in the input video from where to start generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT05S), or a frame count (For example, 10 for the 10th frame), or a relative value (For example, 1%). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video.
     */
    start?: string;
    /**
     * The intervals at which thumbnails are generated. The value can be in absolute timestamp (ISO 8601, e.g: PT05S for one image every 5 seconds), or a frame count (For example, 30 for every 30 frames), or a relative value (For example, 1%).
     */
    step?: string;
    /**
     * The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
     */
    stretchMode?: string;
}

/**
 * Describes the settings to produce a JPEG image from the input video.
 */
export interface JpgLayerResponse {
    /**
     * The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
     */
    height?: string;
    /**
     * The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.JpgLayer'.
     */
    odataType: "#Microsoft.Media.JpgLayer";
    /**
     * The compression quality of the JPEG output. Range is from 0-100 and the default is 70.
     */
    quality?: number;
    /**
     * The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
     */
    width?: string;
}

/**
 * The Live Event encoding.
 */
export interface LiveEventEncodingResponse {
    /**
     * The encoding type for Live Event.
     */
    encodingType?: string;
    /**
     * The encoding preset name.
     */
    presetName?: string;
}

/**
 * The Live Event endpoint.
 */
export interface LiveEventEndpointResponse {
    /**
     * The endpoint protocol.
     */
    protocol?: string;
    /**
     * The endpoint URL.
     */
    url?: string;
}

/**
 * The Live Event input.
 */
export interface LiveEventInputResponse {
    /**
     * The access token.
     */
    accessToken?: string;
    /**
     * The input endpoints for the Live Event.
     */
    endpoints?: outputs.media.v20180601preview.LiveEventEndpointResponse[];
    /**
     * ISO 8601 timespan duration of the key frame interval duration.
     */
    keyFrameIntervalDuration?: string;
    /**
     * The streaming protocol for the Live Event.
     */
    streamingProtocol: string;
}

/**
 * The IP access control for Live Event preview.
 */
export interface LiveEventPreviewAccessControlResponse {
    /**
     * The IP access control properties.
     */
    ip?: outputs.media.v20180601preview.IPAccessControlResponse;
}

/**
 * The Live Event preview.
 */
export interface LiveEventPreviewResponse {
    /**
     * The access control for LiveEvent preview.
     */
    accessControl?: outputs.media.v20180601preview.LiveEventPreviewAccessControlResponse;
    /**
     * An Alternative Media Identifier associated with the preview url.  This identifier can be used to distinguish the preview of different live events for authorization purposes in the CustomLicenseAcquisitionUrlTemplate or the CustomKeyAcquisitionUrlTemplate of the StreamingPolicy specified in the StreamingPolicyName field.
     */
    alternativeMediaId?: string;
    /**
     * The endpoints for preview.
     */
    endpoints?: outputs.media.v20180601preview.LiveEventEndpointResponse[];
    /**
     * The preview locator Guid.
     */
    previewLocator?: string;
    /**
     * The name of streaming policy used for LiveEvent preview
     */
    streamingPolicyName?: string;
}

/**
 * Describes the properties for an output ISO MP4 file.
 */
export interface Mp4FormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.Mp4Format'.
     */
    odataType: "#Microsoft.Media.Mp4Format";
    /**
     * The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
     */
    outputFiles?: outputs.media.v20180601preview.OutputFileResponse[];
}

/**
 * Describes the properties for producing a collection of GOP aligned multi-bitrate files. The default behavior is to produce one output file for each video layer which is muxed together with all the audios. The exact output files produced can be controlled by specifying the outputFiles collection.
 */
export interface MultiBitrateFormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.MultiBitrateFormat'.
     */
    odataType: "#Microsoft.Media.MultiBitrateFormat";
    /**
     * The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
     */
    outputFiles?: outputs.media.v20180601preview.OutputFileResponse[];
}

/**
 * Class for NoEncryption scheme
 */
export interface NoEncryptionResponse {
    /**
     * Representing supported protocols
     */
    enabledProtocols?: outputs.media.v20180601preview.EnabledProtocolsResponse;
}

/**
 * Represents an output file produced.
 */
export interface OutputFileResponse {
    /**
     * The list of labels that describe how the encoder should multiplex video and audio into an output file. For example, if the encoder is producing two video layers with labels v1 and v2, and one audio layer with label a1, then an array like '[v1, a1]' tells the encoder to produce an output file with the video track represented by v1 and the audio track represented by a1.
     */
    labels?: string[];
}

/**
 * Describes the settings for producing PNG thumbnails.
 */
export interface PngFormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.PngFormat'.
     */
    odataType: "#Microsoft.Media.PngFormat";
}

/**
 * Describes the properties for producing a series of PNG images from the input video.
 */
export interface PngImageResponse {
    /**
     * The distance between two key frames, thereby defining a group of pictures (GOP). The value should be a non-zero integer in the range [1, 30] seconds, specified in ISO 8601 format. The default is 2 seconds (PT2S).
     */
    keyFrameInterval?: string;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * A collection of output PNG image layers to be produced by the encoder.
     */
    layers?: outputs.media.v20180601preview.PngLayerResponse[];
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.PngImage'.
     */
    odataType: "#Microsoft.Media.PngImage";
    /**
     * The position in the input video at which to stop generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT5M30S to stop at 5 minutes and 30 seconds), or a frame count (For example, 300 to stop at the 300th frame), or a relative value (For example, 100%).
     */
    range?: string;
    /**
     * The position in the input video from where to start generating thumbnails. The value can be in absolute timestamp (ISO 8601, e.g: PT05S), or a frame count (For example, 10 for the 10th frame), or a relative value (For example, 1%). Also supports a macro {Best}, which tells the encoder to select the best thumbnail from the first few seconds of the video.
     */
    start?: string;
    /**
     * The intervals at which thumbnails are generated. The value can be in absolute timestamp (ISO 8601, e.g: PT05S for one image every 5 seconds), or a frame count (For example, 30 for every 30 frames), or a relative value (For example, 1%).
     */
    step?: string;
    /**
     * The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
     */
    stretchMode?: string;
}

/**
 * Describes the settings to produce a PNG image from the input video.
 */
export interface PngLayerResponse {
    /**
     * The height of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in height as the input.
     */
    height?: string;
    /**
     * The alphanumeric label for this layer, which can be used in multiplexing different video and audio layers, or in naming the output file.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.PngLayer'.
     */
    odataType: "#Microsoft.Media.PngLayer";
    /**
     * The width of the output video for this layer. The value can be absolute (in pixels) or relative (in percentage). For example 50% means the output video has half as many pixels in width as the input.
     */
    width?: string;
}

/**
 * Describes the properties of a rectangular window applied to the input media before processing it.
 */
export interface RectangleResponse {
    /**
     * The height of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
     */
    height?: string;
    /**
     * The number of pixels from the left-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
     */
    left?: string;
    /**
     * The number of pixels from the top-margin. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
     */
    top?: string;
    /**
     * The width of the rectangular region in pixels. This can be absolute pixel value (e.g 100), or relative to the size of the video (For example, 50%).
     */
    width?: string;
}

/**
 * Describes all the settings to be used when encoding the input video with the Standard Encoder.
 */
export interface StandardEncoderPresetResponse {
    /**
     * The list of codecs to be used when encoding the input video.
     */
    codecs?: (outputs.media.v20180601preview.AacAudioResponse | outputs.media.v20180601preview.AudioResponse | outputs.media.v20180601preview.CopyAudioResponse | outputs.media.v20180601preview.CopyVideoResponse | outputs.media.v20180601preview.H264VideoResponse | outputs.media.v20180601preview.ImageResponse | outputs.media.v20180601preview.JpgImageResponse | outputs.media.v20180601preview.PngImageResponse | outputs.media.v20180601preview.VideoResponse)[];
    /**
     * One or more filtering operations that are applied to the input media before encoding.
     */
    filters?: outputs.media.v20180601preview.FiltersResponse;
    /**
     * The list of outputs to be produced by the encoder.
     */
    formats?: (outputs.media.v20180601preview.ImageFormatResponse | outputs.media.v20180601preview.JpgFormatResponse | outputs.media.v20180601preview.Mp4FormatResponse | outputs.media.v20180601preview.MultiBitrateFormatResponse | outputs.media.v20180601preview.PngFormatResponse | outputs.media.v20180601preview.TransportStreamFormatResponse)[];
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.StandardEncoderPreset'.
     */
    odataType: "#Microsoft.Media.StandardEncoderPreset";
}

/**
 * The storage account details.
 */
export interface StorageAccountResponse {
    /**
     * The ID of the storage account resource. Media Services relies on tables and queues as well as blobs, so the primary storage account must be a Standard Storage account (either Microsoft.ClassicStorage or Microsoft.Storage). Blob only storage accounts can be added as secondary storage accounts.
     */
    id?: string;
    /**
     * The type of the storage account.
     */
    type: string;
}

/**
 * StreamingEndpoint access control definition.
 */
export interface StreamingEndpointAccessControlResponse {
    /**
     * The access control of Akamai
     */
    akamai?: outputs.media.v20180601preview.AkamaiAccessControlResponse;
    /**
     * The IP access control of the StreamingEndpoint.
     */
    ip?: outputs.media.v20180601preview.IPAccessControlResponse;
}

/**
 * Class for content key in Streaming Locator
 */
export interface StreamingLocatorContentKeyResponse {
    /**
     * ID of Content Key
     */
    id: string;
    /**
     * Label of Content Key
     */
    label?: string;
    /**
     * ContentKeyPolicy used by Content Key
     */
    policyName: string;
    /**
     * Tracks which use this Content Key
     */
    tracks?: outputs.media.v20180601preview.TrackSelectionResponse[];
    /**
     * Encryption type of Content Key
     */
    type: string;
    /**
     * Value of Content Key
     */
    value?: string;
}

/**
 * Class of paths for streaming
 */
export interface StreamingPathResponse {
    /**
     * Encryption scheme
     */
    encryptionScheme: string;
    /**
     * Streaming paths for each protocol and encryptionScheme pair
     */
    paths?: string[];
    /**
     * Streaming protocol
     */
    streamingProtocol: string;
}

/**
 * Class to specify properties of content key
 */
export interface StreamingPolicyContentKeyResponse {
    /**
     * Label can be used to specify Content Key when creating a Streaming Locator
     */
    label?: string;
    /**
     * Policy used by Content Key
     */
    policyName?: string;
    /**
     * Tracks which use this content key
     */
    tracks?: outputs.media.v20180601preview.TrackSelectionResponse[];
}

/**
 * Class to specify properties of all content keys in Streaming Policy
 */
export interface StreamingPolicyContentKeysResponse {
    /**
     * Default content key for an encryption scheme
     */
    defaultKey?: outputs.media.v20180601preview.DefaultKeyResponse;
    /**
     * Representing tracks needs separate content key
     */
    keyToTrackMappings?: outputs.media.v20180601preview.StreamingPolicyContentKeyResponse[];
}

/**
 * Class to specify configurations of FairPlay in Streaming Policy
 */
export interface StreamingPolicyFairPlayConfigurationResponse {
    /**
     * All license to be persistent or not
     */
    allowPersistentLicense: boolean;
    /**
     * The template for a customer service to deliver keys to end users.  Not needed when using Azure Media Services for issuing keys.
     */
    customLicenseAcquisitionUrlTemplate?: string;
}

/**
 * Class to specify configurations of PlayReady in Streaming Policy
 */
export interface StreamingPolicyPlayReadyConfigurationResponse {
    /**
     * The template for a customer service to deliver keys to end users.  Not needed when using Azure Media Services for issuing keys.
     */
    customLicenseAcquisitionUrlTemplate?: string;
    /**
     * Custom attributes for PlayReady
     */
    playReadyCustomAttributes?: string;
}

/**
 * Class to specify configurations of Widevine in Streaming Policy
 */
export interface StreamingPolicyWidevineConfigurationResponse {
    /**
     * The template for a customer service to deliver keys to end users.  Not needed when using Azure Media Services for issuing keys.
     */
    customLicenseAcquisitionUrlTemplate?: string;
}

/**
 * Class to specify one track property condition
 */
export interface TrackPropertyConditionResponse {
    /**
     * Track property condition operation
     */
    operation: string;
    /**
     * Track property type
     */
    property: string;
    /**
     * Track property value
     */
    value?: string;
}

/**
 * Class to select a track
 */
export interface TrackSelectionResponse {
    /**
     * TrackSelections is a track property condition list which can specify track(s)
     */
    trackSelections?: outputs.media.v20180601preview.TrackPropertyConditionResponse[];
}

/**
 * Describes the properties of a TransformOutput, which are the rules to be applied while generating the desired output.
 */
export interface TransformOutputResponse {
    /**
     * A Transform can define more than one outputs. This property defines what the service should do when one output fails - either continue to produce other outputs, or, stop the other outputs. The default is stop.
     */
    onError?: string;
    /**
     * Preset that describes the operations that will be used to modify, transcode, or extract insights from the source file to generate the output.
     */
    preset: outputs.media.v20180601preview.AudioAnalyzerPresetResponse | outputs.media.v20180601preview.BuiltInStandardEncoderPresetResponse | outputs.media.v20180601preview.StandardEncoderPresetResponse | outputs.media.v20180601preview.VideoAnalyzerPresetResponse;
    /**
     * Sets the relative priority of the TransformOutputs within a Transform. This sets the priority that the service uses for processing TransformOutputs. The default priority is Normal.
     */
    relativePriority?: string;
}

/**
 * Describes the properties for generating an MPEG-2 Transport Stream (ISO/IEC 13818-1) output video file(s).
 */
export interface TransportStreamFormatResponse {
    /**
     * The pattern of the file names for the generated output files. The following macros are supported in the file name: {Basename} - The base name of the input video {Extension} - The appropriate extension for this format. {Label} - The label assigned to the codec/layer. {Index} - A unique index for thumbnails. Only applicable to thumbnails. {Bitrate} - The audio/video bitrate. Not applicable to thumbnails. {Codec} - The type of the audio/video codec. Any unsubstituted macros will be collapsed and removed from the filename.
     */
    filenamePattern?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.TransportStreamFormat'.
     */
    odataType: "#Microsoft.Media.TransportStreamFormat";
    /**
     * The list of output files to produce.  Each entry in the list is a set of audio and video layer labels to be muxed together .
     */
    outputFiles?: outputs.media.v20180601preview.OutputFileResponse[];
}

/**
 * A video analyzer preset that extracts insights (rich metadata) from both audio and video, and outputs a JSON format file.
 */
export interface VideoAnalyzerPresetResponse {
    /**
     * Whether to only extract audio insights when processing a video file.
     */
    audioInsightsOnly?: boolean;
    /**
     * The language for the audio payload in the input using the BCP-47 format of 'language tag-region' (e.g: 'en-US'). The list of supported languages are, 'en-US', 'en-GB', 'es-ES', 'es-MX', 'fr-FR', 'it-IT', 'ja-JP', 'pt-BR', 'zh-CN'.
     */
    audioLanguage?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.VideoAnalyzerPreset'.
     */
    odataType: "#Microsoft.Media.VideoAnalyzerPreset";
}

/**
 * Describes the properties of a video overlay.
 */
export interface VideoOverlayResponse {
    /**
     * The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0.
     */
    audioGainLevel?: number;
    /**
     * An optional rectangular window used to crop the overlay image or video.
     */
    cropRectangle?: outputs.media.v20180601preview.RectangleResponse;
    /**
     * The position in the input video at which the overlay ends. The value should be in ISO 8601 duration format. For example, PT30S to end the overlay at 30 seconds in to the input video. If not specified the overlay will be applied until the end of the input video if inputLoop is true. Else, if inputLoop is false, then overlay will last as long as the duration of the overlay media.
     */
    end?: string;
    /**
     * The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S).
     */
    fadeInDuration?: string;
    /**
     * The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S).
     */
    fadeOutDuration?: string;
    /**
     * The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG or PNG formats, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats.
     */
    inputLabel?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.VideoOverlay'.
     */
    odataType: "#Microsoft.Media.VideoOverlay";
    /**
     * The opacity of the overlay. This is a value in the range [0 - 1.0]. Default is 1.0 which mean the overlay is opaque.
     */
    opacity?: number;
    /**
     * The location in the input video where the overlay is applied.
     */
    position?: outputs.media.v20180601preview.RectangleResponse;
    /**
     * The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds in to the input video. If not specified the overlay starts from the beginning of the input video.
     */
    start?: string;
}

/**
 * Describes the basic properties for encoding the input video.
 */
export interface VideoResponse {
    /**
     * The distance between two key frames, thereby defining a group of pictures (GOP). The value should be a non-zero integer in the range [1, 30] seconds, specified in ISO 8601 format. The default is 2 seconds (PT2S).
     */
    keyFrameInterval?: string;
    /**
     * An optional label for the codec. The label can be used to control muxing behavior.
     */
    label?: string;
    /**
     * The discriminator for derived types.
     * Expected value is '#Microsoft.Media.Video'.
     */
    odataType: "#Microsoft.Media.Video";
    /**
     * The resizing mode - how the input video will be resized to fit the desired output resolution(s). Default is AutoSize
     */
    stretchMode?: string;
}

